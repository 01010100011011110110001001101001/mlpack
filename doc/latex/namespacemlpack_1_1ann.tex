\section{mlpack\+:\+:ann Namespace Reference}
\label{namespacemlpack_1_1ann}\index{mlpack\+::ann@{mlpack\+::ann}}


Artificial Neural Network.  


\subsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class {\bf Add}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Add}{p.}{classmlpack_1_1ann_1_1Add} module class. \end{DoxyCompactList}\item 
class {\bf Add\+Merge}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} module class. \end{DoxyCompactList}\item 
class {\bf Add\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Add\+Visitor}{p.}{classmlpack_1_1ann_1_1AddVisitor} exposes the Add() method of the given module. \end{DoxyCompactList}\item 
class {\bf Backward\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Backward\+Visitor}{p.}{classmlpack_1_1ann_1_1BackwardVisitor} executes the Backward() function given the input, error and delta parameter. \end{DoxyCompactList}\item 
class {\bf Base\+Layer}
\begin{DoxyCompactList}\small\item\em Implementation of the base layer. \end{DoxyCompactList}\item 
class {\bf Concat}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Concat}{p.}{classmlpack_1_1ann_1_1Concat} class. \end{DoxyCompactList}\item 
class {\bf Concat\+Performance}
\begin{DoxyCompactList}\small\item\em Implementation of the concat performance class. \end{DoxyCompactList}\item 
class {\bf Constant}
\begin{DoxyCompactList}\small\item\em Implementation of the constant layer. \end{DoxyCompactList}\item 
class {\bf Convolution}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Convolution}{p.}{classmlpack_1_1ann_1_1Convolution} class. \end{DoxyCompactList}\item 
class {\bf Delete\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Delete\+Visitor}{p.}{classmlpack_1_1ann_1_1DeleteVisitor} executes the destructor of the instantiated object. \end{DoxyCompactList}\item 
class {\bf Delta\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Delta\+Visitor}{p.}{classmlpack_1_1ann_1_1DeltaVisitor} exposes the delta parameter of the given module. \end{DoxyCompactList}\item 
class {\bf Deterministic\+Set\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Deterministic\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1DeterministicSetVisitor} set the deterministic parameter given the deterministic value. \end{DoxyCompactList}\item 
class {\bf Drop\+Connect}
\begin{DoxyCompactList}\small\item\em The \doxyref{Drop\+Connect}{p.}{classmlpack_1_1ann_1_1DropConnect} layer is a regularizer that randomly with probability ratio sets the connection values to zero and scales the remaining elements by factor 1 /(1 -\/ ratio). \end{DoxyCompactList}\item 
class {\bf Dropout}
\begin{DoxyCompactList}\small\item\em The dropout layer is a regularizer that randomly with probability ratio sets input values to zero and scales the remaining elements by factor 1 / (1 -\/ ratio). \end{DoxyCompactList}\item 
class {\bf E\+LU}
\begin{DoxyCompactList}\small\item\em The \doxyref{E\+LU}{p.}{classmlpack_1_1ann_1_1ELU} activation function, defined by. \end{DoxyCompactList}\item 
class {\bf F\+FN}
\begin{DoxyCompactList}\small\item\em Implementation of a standard feed forward network. \end{DoxyCompactList}\item 
class {\bf F\+F\+T\+Convolution}
\begin{DoxyCompactList}\small\item\em Computes the two-\/dimensional convolution through fft. \end{DoxyCompactList}\item 
class {\bf Forward\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Forward\+Visitor}{p.}{classmlpack_1_1ann_1_1ForwardVisitor} executes the Forward() function given the input and output parameter. \end{DoxyCompactList}\item 
class {\bf Full\+Convolution}
\item 
class {\bf Glimpse}
\begin{DoxyCompactList}\small\item\em The glimpse layer returns a retina-\/like representation (down-\/scaled cropped images) of increasing scale around a given location in a given image. \end{DoxyCompactList}\item 
class {\bf Gradient\+Set\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Gradient\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1GradientSetVisitor} update the gradient parameter given the gradient set. \end{DoxyCompactList}\item 
class {\bf Gradient\+Update\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Gradient\+Update\+Visitor}{p.}{classmlpack_1_1ann_1_1GradientUpdateVisitor} update the gradient parameter given the gradient set. \end{DoxyCompactList}\item 
class {\bf Gradient\+Visitor}
\begin{DoxyCompactList}\small\item\em Search\+Mode\+Visitor executes the Gradient() method of the given module using the input and delta parameter. \end{DoxyCompactList}\item 
class {\bf Gradient\+Zero\+Visitor}
\item 
class {\bf Hard\+TanH}
\begin{DoxyCompactList}\small\item\em The Hard Tanh activation function, defined by. \end{DoxyCompactList}\item 
class {\bf Identity\+Function}
\begin{DoxyCompactList}\small\item\em The identity function, defined by. \end{DoxyCompactList}\item 
class {\bf Join}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Join}{p.}{classmlpack_1_1ann_1_1Join} module class. \end{DoxyCompactList}\item 
class {\bf Kathirvalavakumar\+Subavathi\+Initialization}
\begin{DoxyCompactList}\small\item\em This class is used to initialize the weight matrix with the method proposed by T. \end{DoxyCompactList}\item 
class {\bf Layer\+Traits}
\begin{DoxyCompactList}\small\item\em This is a template class that can provide information about various layers. \end{DoxyCompactList}\item 
class {\bf Leaky\+Re\+LU}
\begin{DoxyCompactList}\small\item\em The \doxyref{Leaky\+Re\+LU}{p.}{classmlpack_1_1ann_1_1LeakyReLU} activation function, defined by. \end{DoxyCompactList}\item 
class {\bf Linear}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} layer class. \end{DoxyCompactList}\item 
class {\bf Linear\+No\+Bias}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Linear\+No\+Bias}{p.}{classmlpack_1_1ann_1_1LinearNoBias} class. \end{DoxyCompactList}\item 
class {\bf Load\+Output\+Parameter\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Load\+Output\+Parameter\+Visitor}{p.}{classmlpack_1_1ann_1_1LoadOutputParameterVisitor} restores the output parameter using the given parameter set. \end{DoxyCompactList}\item 
class {\bf Logistic\+Function}
\begin{DoxyCompactList}\small\item\em The logistic function, defined by. \end{DoxyCompactList}\item 
class {\bf Log\+Soft\+Max}
\begin{DoxyCompactList}\small\item\em Implementation of the log softmax layer. \end{DoxyCompactList}\item 
class {\bf Lookup}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Lookup}{p.}{classmlpack_1_1ann_1_1Lookup} class. \end{DoxyCompactList}\item 
class {\bf L\+S\+TM}
\begin{DoxyCompactList}\small\item\em An implementation of a lstm network layer. \end{DoxyCompactList}\item 
class {\bf Max\+Pooling}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Max\+Pooling}{p.}{classmlpack_1_1ann_1_1MaxPooling} layer. \end{DoxyCompactList}\item 
class {\bf Max\+Pooling\+Rule}
\item 
class {\bf Mean\+Pooling}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Mean\+Pooling}{p.}{classmlpack_1_1ann_1_1MeanPooling}. \end{DoxyCompactList}\item 
class {\bf Mean\+Pooling\+Rule}
\item 
class {\bf Mean\+Squared\+Error}
\begin{DoxyCompactList}\small\item\em The mean squared error performance function measures the network\textquotesingle{}s performance according to the mean of squared errors. \end{DoxyCompactList}\item 
class {\bf Multiply\+Constant}
\begin{DoxyCompactList}\small\item\em Implementation of the multiply constant layer. \end{DoxyCompactList}\item 
class {\bf Naive\+Convolution}
\begin{DoxyCompactList}\small\item\em Computes the two-\/dimensional convolution. \end{DoxyCompactList}\item 
class {\bf Negative\+Log\+Likelihood}
\begin{DoxyCompactList}\small\item\em Implementation of the negative log likelihood layer. \end{DoxyCompactList}\item 
class {\bf Nguyen\+Widrow\+Initialization}
\begin{DoxyCompactList}\small\item\em This class is used to initialize the weight matrix with the Nguyen-\/\+Widrow method. \end{DoxyCompactList}\item 
class {\bf Oivs\+Initialization}
\begin{DoxyCompactList}\small\item\em This class is used to initialize the weight matrix with the oivs method. \end{DoxyCompactList}\item 
class {\bf Orthogonal\+Initialization}
\begin{DoxyCompactList}\small\item\em This class is used to initialize the weight matrix with the orthogonal matrix initialization. \end{DoxyCompactList}\item 
class {\bf Output\+Height\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Output\+Width\+Visitor}{p.}{classmlpack_1_1ann_1_1OutputWidthVisitor} exposes the Output\+Height() method of the given module. \end{DoxyCompactList}\item 
class {\bf Output\+Parameter\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Output\+Parameter\+Visitor}{p.}{classmlpack_1_1ann_1_1OutputParameterVisitor} exposes the output parameter of the given module. \end{DoxyCompactList}\item 
class {\bf Output\+Width\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Output\+Width\+Visitor}{p.}{classmlpack_1_1ann_1_1OutputWidthVisitor} exposes the Output\+Width() method of the given module. \end{DoxyCompactList}\item 
class {\bf Parameters\+Set\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Parameters\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1ParametersSetVisitor} update the parameters set using the given matrix. \end{DoxyCompactList}\item 
class {\bf Parameters\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Parameters\+Visitor}{p.}{classmlpack_1_1ann_1_1ParametersVisitor} exposes the parameters set of the given module and stores the parameters set into the given matrix. \end{DoxyCompactList}\item 
class {\bf P\+Re\+LU}
\begin{DoxyCompactList}\small\item\em The \doxyref{P\+Re\+LU}{p.}{classmlpack_1_1ann_1_1PReLU} activation function, defined by (where alpha is trainable) \end{DoxyCompactList}\item 
class {\bf Random\+Initialization}
\begin{DoxyCompactList}\small\item\em This class is used to initialize randomly the weight matrix. \end{DoxyCompactList}\item 
class {\bf Rectifier\+Function}
\begin{DoxyCompactList}\small\item\em The rectifier function, defined by. \end{DoxyCompactList}\item 
class {\bf Recurrent}
\begin{DoxyCompactList}\small\item\em Implementation of the Recurrent\+Layer class. \end{DoxyCompactList}\item 
class {\bf Recurrent\+Attention}
\begin{DoxyCompactList}\small\item\em This class implements the \doxyref{Recurrent}{p.}{classmlpack_1_1ann_1_1Recurrent} Model for Visual Attention, using a variety of possible layer implementations. \end{DoxyCompactList}\item 
class {\bf Reinforce\+Normal}
\begin{DoxyCompactList}\small\item\em Implementation of the reinforce normal layer. \end{DoxyCompactList}\item 
class {\bf Reset\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Reset\+Visitor}{p.}{classmlpack_1_1ann_1_1ResetVisitor} executes the Reset() function. \end{DoxyCompactList}\item 
class {\bf Reward\+Set\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Reward\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1RewardSetVisitor} set the reward parameter given the reward value. \end{DoxyCompactList}\item 
class {\bf R\+NN}
\begin{DoxyCompactList}\small\item\em Implementation of a standard recurrent neural network container. \end{DoxyCompactList}\item 
class {\bf Save\+Output\+Parameter\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Save\+Output\+Parameter\+Visitor}{p.}{classmlpack_1_1ann_1_1SaveOutputParameterVisitor} saves the output parameter into the given parameter set. \end{DoxyCompactList}\item 
class {\bf Select}
\begin{DoxyCompactList}\small\item\em The select module selects the specified column from a given input matrix. \end{DoxyCompactList}\item 
class {\bf Sequential}
\begin{DoxyCompactList}\small\item\em Implementation of the \doxyref{Sequential}{p.}{classmlpack_1_1ann_1_1Sequential} class. \end{DoxyCompactList}\item 
class {\bf Set\+Input\+Height\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Set\+Input\+Height\+Visitor}{p.}{classmlpack_1_1ann_1_1SetInputHeightVisitor} updates the input height parameter with the given input height. \end{DoxyCompactList}\item 
class {\bf Set\+Input\+Width\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Set\+Input\+Width\+Visitor}{p.}{classmlpack_1_1ann_1_1SetInputWidthVisitor} updates the input width parameter with the given input width. \end{DoxyCompactList}\item 
class {\bf Softplus\+Function}
\begin{DoxyCompactList}\small\item\em The softplus function, defined by. \end{DoxyCompactList}\item 
class {\bf Softsign\+Function}
\begin{DoxyCompactList}\small\item\em The softsign function, defined by. \end{DoxyCompactList}\item 
class {\bf S\+V\+D\+Convolution}
\begin{DoxyCompactList}\small\item\em Computes the two-\/dimensional convolution using singular value decomposition. \end{DoxyCompactList}\item 
class {\bf Tanh\+Function}
\begin{DoxyCompactList}\small\item\em The tanh function, defined by. \end{DoxyCompactList}\item 
class {\bf Valid\+Convolution}
\item 
class {\bf V\+R\+Class\+Reward}
\begin{DoxyCompactList}\small\item\em Implementation of the variance reduced classification reinforcement layer. \end{DoxyCompactList}\item 
class {\bf Weight\+Set\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Weight\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1WeightSetVisitor} update the module parameters given the parameters set. \end{DoxyCompactList}\item 
class {\bf Weight\+Size\+Visitor}
\begin{DoxyCompactList}\small\item\em \doxyref{Weight\+Size\+Visitor}{p.}{classmlpack_1_1ann_1_1WeightSizeVisitor} returns the number of weights of the given module. \end{DoxyCompactList}\item 
class {\bf Zero\+Initialization}
\begin{DoxyCompactList}\small\item\em This class is used to initialize randomly the weight matrix. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Typedefs}
\begin{DoxyCompactItemize}
\item 
{\footnotesize template$<$class Activation\+Function  = Identity\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ }\\using {\bf Identity\+Layer} = {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$
\begin{DoxyCompactList}\small\item\em Standard Identity-\/\+Layer using the identity activation function. \end{DoxyCompactList}\item 
using {\bf Layer\+Types} = boost\+::variant$<$ {\bf Add}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Add\+Merge}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Base\+Layer}$<$ {\bf Logistic\+Function}, arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Base\+Layer}$<$ {\bf Identity\+Function}, arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Base\+Layer}$<$ {\bf Tanh\+Function}, arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Base\+Layer}$<$ {\bf Rectifier\+Function}, arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Concat}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Concat\+Performance}$<$ {\bf Negative\+Log\+Likelihood}$<$ arma\+::mat, arma\+::mat $>$, arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Constant}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Convolution}$<$ {\bf Naive\+Convolution}$<$ {\bf Valid\+Convolution} $>$, {\bf Naive\+Convolution}$<$ {\bf Full\+Convolution} $>$, {\bf Naive\+Convolution}$<$ {\bf Valid\+Convolution} $>$, arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Drop\+Connect}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Dropout}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Glimpse}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Hard\+TanH}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Join}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Leaky\+Re\+LU}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Linear}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Linear\+No\+Bias}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Log\+Soft\+Max}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Lookup}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf L\+S\+TM}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Max\+Pooling}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Mean\+Pooling}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Mean\+Squared\+Error}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Multiply\+Constant}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Negative\+Log\+Likelihood}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf P\+Re\+LU}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Recurrent}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Recurrent\+Attention}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Reinforce\+Normal}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Select}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf Sequential}$<$ arma\+::mat, arma\+::mat $>$ $\ast$, {\bf V\+R\+Class\+Reward}$<$ arma\+::mat, arma\+::mat $>$ $\ast$ $>$
\item 
{\footnotesize template$<$class Activation\+Function  = Rectifier\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ }\\using {\bf Re\+L\+U\+Layer} = {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$
\begin{DoxyCompactList}\small\item\em Standard rectified linear unit non-\/linearity layer. \end{DoxyCompactList}\item 
{\footnotesize template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ }\\using {\bf Sigmoid\+Layer} = {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$
\begin{DoxyCompactList}\small\item\em Standard Sigmoid-\/\+Layer using the logistic activation function. \end{DoxyCompactList}\item 
{\footnotesize template$<$class Activation\+Function  = Tanh\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ }\\using {\bf Tan\+H\+Layer} = {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$
\begin{DoxyCompactList}\small\item\em Standard hyperbolic tangent layer. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Gradient, Has\+Gradient\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Deterministic, Has\+Deterministic\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Parameters, Has\+Parameters\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} ({\bf Add}, Has\+Add\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Model, Has\+Model\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Location, Has\+Location\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Reset, Has\+Reset\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Reward, Has\+Reward\+Check)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Input\+Width, Has\+Input\+Width)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Input\+Height, Has\+Input\+Height)
\item 
{\bf H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC} (Input\+Height, Has\+Rho)
\end{DoxyCompactItemize}


\subsection{Detailed Description}
Artificial Neural Network. 



\subsection{Typedef Documentation}
\index{mlpack\+::ann@{mlpack\+::ann}!Identity\+Layer@{Identity\+Layer}}
\index{Identity\+Layer@{Identity\+Layer}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{Identity\+Layer}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Identity\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ using {\bf mlpack\+::ann\+::\+Identity\+Layer} = typedef {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type$>$}\label{namespacemlpack_1_1ann_a6d2f8fd261b4ea582c21ffa66dce032e}


Standard Identity-\/\+Layer using the identity activation function. 



Definition at line 147 of file base\+\_\+layer.\+hpp.

\index{mlpack\+::ann@{mlpack\+::ann}!Layer\+Types@{Layer\+Types}}
\index{Layer\+Types@{Layer\+Types}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{Layer\+Types}]{\setlength{\rightskip}{0pt plus 5cm}using {\bf mlpack\+::ann\+::\+Layer\+Types} = typedef boost\+::variant$<$ {\bf Add}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Add\+Merge}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Base\+Layer}$<${\bf Logistic\+Function}, arma\+::mat, arma\+::mat$>$$\ast$, {\bf Base\+Layer}$<${\bf Identity\+Function}, arma\+::mat, arma\+::mat$>$$\ast$, {\bf Base\+Layer}$<${\bf Tanh\+Function}, arma\+::mat, arma\+::mat$>$$\ast$, {\bf Base\+Layer}$<${\bf Rectifier\+Function}, arma\+::mat, arma\+::mat$>$$\ast$, {\bf Concat}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Concat\+Performance}$<${\bf Negative\+Log\+Likelihood}$<$arma\+::mat, arma\+::mat$>$, arma\+::mat, arma\+::mat$>$$\ast$, {\bf Constant}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Convolution}$<${\bf Naive\+Convolution}$<${\bf Valid\+Convolution}$>$, {\bf Naive\+Convolution}$<${\bf Full\+Convolution}$>$, {\bf Naive\+Convolution}$<${\bf Valid\+Convolution}$>$, arma\+::mat, arma\+::mat$>$$\ast$, {\bf Drop\+Connect}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Dropout}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Glimpse}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Hard\+TanH}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Join}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Leaky\+Re\+LU}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Linear}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Linear\+No\+Bias}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Log\+Soft\+Max}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Lookup}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf L\+S\+TM}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Max\+Pooling}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Mean\+Pooling}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Mean\+Squared\+Error}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Multiply\+Constant}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Negative\+Log\+Likelihood}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf P\+Re\+LU}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Recurrent}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Recurrent\+Attention}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Reinforce\+Normal}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Select}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf Sequential}$<$arma\+::mat, arma\+::mat$>$$\ast$, {\bf V\+R\+Class\+Reward}$<$arma\+::mat, arma\+::mat$>$$\ast$ $>$}\label{namespacemlpack_1_1ann_ab8d68f366a3cbbbc1f0f4990ec70c645}


Definition at line 115 of file layer\+\_\+types.\+hpp.

\index{mlpack\+::ann@{mlpack\+::ann}!Re\+L\+U\+Layer@{Re\+L\+U\+Layer}}
\index{Re\+L\+U\+Layer@{Re\+L\+U\+Layer}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{Re\+L\+U\+Layer}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Rectifier\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ using {\bf mlpack\+::ann\+::\+Re\+L\+U\+Layer} = typedef {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type$>$}\label{namespacemlpack_1_1ann_aebc137d2d7078f906a4f814434906315}


Standard rectified linear unit non-\/linearity layer. 



Definition at line 158 of file base\+\_\+layer.\+hpp.

\index{mlpack\+::ann@{mlpack\+::ann}!Sigmoid\+Layer@{Sigmoid\+Layer}}
\index{Sigmoid\+Layer@{Sigmoid\+Layer}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{Sigmoid\+Layer}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ using {\bf mlpack\+::ann\+::\+Sigmoid\+Layer} = typedef {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type$>$}\label{namespacemlpack_1_1ann_ab47a1c44ac2f0c6d43b2aae17f59393c}


Standard Sigmoid-\/\+Layer using the logistic activation function. 



Definition at line 136 of file base\+\_\+layer.\+hpp.

\index{mlpack\+::ann@{mlpack\+::ann}!Tan\+H\+Layer@{Tan\+H\+Layer}}
\index{Tan\+H\+Layer@{Tan\+H\+Layer}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{Tan\+H\+Layer}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Tanh\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ using {\bf mlpack\+::ann\+::\+Tan\+H\+Layer} = typedef {\bf Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type$>$}\label{namespacemlpack_1_1ann_aa0d5b56aea3e3e2eb901913aa0f662b6}


Standard hyperbolic tangent layer. 



Definition at line 169 of file base\+\_\+layer.\+hpp.



\subsection{Function Documentation}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Gradient, Has\+Gradient\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Gradient}]{, }
\item[{Has\+Gradient\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_ac1b6745deedbcee048f2387da27389d4}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Deterministic, Has\+Deterministic\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Deterministic}]{, }
\item[{Has\+Deterministic\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_ae95d86bb222cc89639472577da586357}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Parameters, Has\+Parameters\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Parameters}]{, }
\item[{Has\+Parameters\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_add5ad48dbc07b098c8df806a7d100de7}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Add, Has\+Add\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{{\bf Add}}]{, }
\item[{Has\+Add\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_a923497f92d9b28cfe7143d40e00c6bfc}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Model, Has\+Model\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Model}]{, }
\item[{Has\+Model\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_a64c9a13fc37ea5efea67ced87eb979b7}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Location, Has\+Location\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Location}]{, }
\item[{Has\+Location\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_a9ddaef84cd236998b57624b9b4d2eebe}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Reset, Has\+Reset\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Reset}]{, }
\item[{Has\+Reset\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_a7af914cacab417f183e2fc0051a5345a}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Reward, Has\+Reward\+Check)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Reward}]{, }
\item[{Has\+Reward\+Check}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_ad4b16a6a10d1b1d3999d177f03b1f4a0}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Input\+Width, Has\+Input\+Width)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Input\+Width}]{, }
\item[{Has\+Input\+Width}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_a4dfcd41ff0d3c6ea37dda6c9a35c832f}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Input\+Height, Has\+Input\+Height)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Input\+Height}]{, }
\item[{Has\+Input\+Height}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_addfd94f5ac2aa2225484ddddb06b8320}
\index{mlpack\+::ann@{mlpack\+::ann}!H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}}
\index{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC@{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC}!mlpack\+::ann@{mlpack\+::ann}}
\subsubsection[{H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+N\+C(\+Input\+Height, Has\+Rho)}]{\setlength{\rightskip}{0pt plus 5cm}mlpack\+::ann\+::\+H\+A\+S\+\_\+\+M\+E\+M\+\_\+\+F\+U\+NC (
\begin{DoxyParamCaption}
\item[{Input\+Height}]{, }
\item[{Has\+Rho}]{}
\end{DoxyParamCaption}
)}\label{namespacemlpack_1_1ann_ad8eda7b1a9f68f3e79e1205460be9ffa}
