\section{mlpack\+:\+:regression\+:\+:Softmax\+Regression$<$ Optimizer\+Type $>$ Class Template Reference}
\label{classmlpack_1_1regression_1_1SoftmaxRegression}\index{mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$@{mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$}}


Softmax Regression is a classifier which can be used for classification when the data available can take two or more class values.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
{\bf Softmax\+Regression} (const size\+\_\+t input\+Size=0, const size\+\_\+t {\bf num\+Classes}=0, const bool {\bf fit\+Intercept}=false)
\begin{DoxyCompactList}\small\item\em Initialize the \doxyref{Softmax\+Regression}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression} without performing training. \end{DoxyCompactList}\item 
{\bf Softmax\+Regression} (const arma\+::mat \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t {\bf num\+Classes}, const double {\bf lambda}=0.\+0001, const bool {\bf fit\+Intercept}=false)
\begin{DoxyCompactList}\small\item\em Construct the \doxyref{Softmax\+Regression}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression} class with the provided data and labels. \end{DoxyCompactList}\item 
{\bf Softmax\+Regression} (Optimizer\+Type$<$ {\bf Softmax\+Regression\+Function} $>$ \&optimizer)
\begin{DoxyCompactList}\small\item\em Construct the softmax regression model with the given training data. \end{DoxyCompactList}\item 
void {\bf Classify} (const arma\+::mat \&dataset, arma\+::\+Row$<$ size\+\_\+t $>$ \&labels) const 
\begin{DoxyCompactList}\small\item\em Classify the given points, returning the predicted labels for each point. \end{DoxyCompactList}\item 
double {\bf Compute\+Accuracy} (const arma\+::mat \&test\+Data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels) const 
\begin{DoxyCompactList}\small\item\em Computes accuracy of the learned model given the feature data and the labels associated with each data point. \end{DoxyCompactList}\item 
size\+\_\+t {\bf Feature\+Size} () const 
\begin{DoxyCompactList}\small\item\em Gets the features size of the training data. \end{DoxyCompactList}\item 
bool {\bf Fit\+Intercept} () const 
\begin{DoxyCompactList}\small\item\em Gets the intercept term flag. We can\textquotesingle{}t change this after training. \end{DoxyCompactList}\item 
double \& {\bf Lambda} ()
\begin{DoxyCompactList}\small\item\em Sets the regularization parameter. \end{DoxyCompactList}\item 
double {\bf Lambda} () const 
\begin{DoxyCompactList}\small\item\em Gets the regularization parameter. \end{DoxyCompactList}\item 
size\+\_\+t \& {\bf Num\+Classes} ()
\begin{DoxyCompactList}\small\item\em Sets the number of classes. \end{DoxyCompactList}\item 
size\+\_\+t {\bf Num\+Classes} () const 
\begin{DoxyCompactList}\small\item\em Gets the number of classes. \end{DoxyCompactList}\item 
arma\+::mat \& {\bf Parameters} ()
\begin{DoxyCompactList}\small\item\em Get the model parameters. \end{DoxyCompactList}\item 
const arma\+::mat \& {\bf Parameters} () const 
\begin{DoxyCompactList}\small\item\em Get the model parameters. \end{DoxyCompactList}\item 
{\bf mlpack\+\_\+deprecated} void {\bf Predict} (const arma\+::mat \&test\+Data, arma\+::\+Row$<$ size\+\_\+t $>$ \&predictions) const 
\begin{DoxyCompactList}\small\item\em Predict the class labels for the provided feature points. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Archive $>$ }\\void {\bf Serialize} (Archive \&ar, const unsigned int)
\begin{DoxyCompactList}\small\item\em Serialize the \doxyref{Softmax\+Regression}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression} model. \end{DoxyCompactList}\item 
double {\bf Train} (Optimizer\+Type$<$ {\bf Softmax\+Regression\+Function} $>$ \&optimizer)
\begin{DoxyCompactList}\small\item\em Train the softmax regression model with the given optimizer. \end{DoxyCompactList}\item 
double {\bf Train} (const arma\+::mat \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t {\bf num\+Classes})
\begin{DoxyCompactList}\small\item\em Train the softmax regression with the given training data. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Private Attributes}
\begin{DoxyCompactItemize}
\item 
bool {\bf fit\+Intercept}
\begin{DoxyCompactList}\small\item\em Intercept term flag. \end{DoxyCompactList}\item 
double {\bf lambda}
\begin{DoxyCompactList}\small\item\em L2-\/regularization constant. \end{DoxyCompactList}\item 
size\+\_\+t {\bf num\+Classes}
\begin{DoxyCompactList}\small\item\em Number of classes. \end{DoxyCompactList}\item 
arma\+::mat {\bf parameters}
\begin{DoxyCompactList}\small\item\em Parameters after optimization. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$\\*
class mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$}

Softmax Regression is a classifier which can be used for classification when the data available can take two or more class values. 

It is a generalization of Logistic Regression (which is used only for binary classification). The model has a different set of parameters for each class, but can be easily converted into a vectorized implementation as has been done in this module. The model can be used for direct classification of feature data or in conjunction with unsupervised learning methods. More technical details about the model can be found on the following webpage\+:

{\tt http\+://ufldl.\+stanford.\+edu/wiki/index.\+php/\+Softmax\+\_\+\+Regression}

An example on how to use the interface is shown below\+:


\begin{DoxyCode}
arma::mat train\_data; \textcolor{comment}{// Training data matrix.}
arma::vec labels; \textcolor{comment}{// Labels associated with the data.}
\textcolor{keyword}{const} \textcolor{keywordtype}{size\_t} inputSize = 784; \textcolor{comment}{// Size of input feature vector.}
\textcolor{keyword}{const} \textcolor{keywordtype}{size\_t} numClasses = 10; \textcolor{comment}{// Number of classes.}

\textcolor{comment}{// Train the model using default options.}
SoftmaxRegression<> regressor1(train\_data, labels, inputSize, numClasses);

\textcolor{keyword}{const} \textcolor{keywordtype}{size\_t} numBasis = 5; \textcolor{comment}{// Parameter required for L-BFGS algorithm.}
\textcolor{keyword}{const} \textcolor{keywordtype}{size\_t} numIterations = 100; \textcolor{comment}{// Maximum number of iterations.}

\textcolor{comment}{// Use an instantiated optimizer for the training.}
SoftmaxRegressionFunction srf(train\_data, labels, inputSize, numClasses);
L\_BFGS<SoftmaxRegressionFunction> optimizer(srf, numBasis, numIterations);
SoftmaxRegression<L\_BFGS> regressor2(optimizer);

arma::mat test\_data; \textcolor{comment}{// Test data matrix.}
arma::vec predictions1, predictions2; \textcolor{comment}{// Vectors to store predictions in.}

\textcolor{comment}{// Obtain predictions from both the learned models.}
regressor1.Classify(test\_data, predictions1);
regressor2.Classify(test\_data, predictions2);
\end{DoxyCode}
 

Definition at line 65 of file softmax\+\_\+regression.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Softmax\+Regression@{Softmax\+Regression}}
\index{Softmax\+Regression@{Softmax\+Regression}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Softmax\+Regression(const size\+\_\+t input\+Size=0, const size\+\_\+t num\+Classes=0, const bool fit\+Intercept=false)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::{\bf Softmax\+Regression} (
\begin{DoxyParamCaption}
\item[{const size\+\_\+t}]{input\+Size = {\ttfamily 0}, }
\item[{const size\+\_\+t}]{num\+Classes = {\ttfamily 0}, }
\item[{const bool}]{fit\+Intercept = {\ttfamily false}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1regression_1_1SoftmaxRegression_acfda4ac0b9d1c0bce568216082c7cff9}


Initialize the \doxyref{Softmax\+Regression}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression} without performing training. 

Default value of lambda is 0.\+0001. Be sure to use \doxyref{Train()}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression_a845c6e6199bd5d5cf67c4705ee23fe21} before calling \doxyref{Classify()}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression_ae45e4d9839896128f87a19f8185b987c} or \doxyref{Compute\+Accuracy()}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression_a4efe331c20f62c5980144c7e1d79d540}, otherwise the results may be meaningless.


\begin{DoxyParams}{Parameters}
{\em input\+Size} & Size of the input feature vector. \\
\hline
{\em num\+Classes} & Number of classes for classification. \\
\hline
{\em fit\+Intercept} & add intercept term or not. \\
\hline
\end{DoxyParams}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Softmax\+Regression@{Softmax\+Regression}}
\index{Softmax\+Regression@{Softmax\+Regression}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Softmax\+Regression(const arma\+::mat \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const double lambda=0.\+0001, const bool fit\+Intercept=false)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::{\bf Softmax\+Regression} (
\begin{DoxyParamCaption}
\item[{const arma\+::mat \&}]{data, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes, }
\item[{const double}]{lambda = {\ttfamily 0.0001}, }
\item[{const bool}]{fit\+Intercept = {\ttfamily false}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ae8763778d6ad4161ebfd24fbd8ee2c63}


Construct the \doxyref{Softmax\+Regression}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression} class with the provided data and labels. 

This will train the model. Optionally, the parameter \textquotesingle{}lambda\textquotesingle{} can be passed, which controls the amount of L2-\/regularization in the objective function. By default, the model takes a small value.


\begin{DoxyParams}{Parameters}
{\em data} & Input training features. Each column associate with one sample \\
\hline
{\em labels} & Labels associated with the feature data. \\
\hline
{\em input\+Size} & Size of the input feature vector. \\
\hline
{\em num\+Classes} & Number of classes for classification. \\
\hline
{\em lambda} & L2-\/regularization constant. \\
\hline
{\em fit\+Intercept} & add intercept term or not. \\
\hline
\end{DoxyParams}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Softmax\+Regression@{Softmax\+Regression}}
\index{Softmax\+Regression@{Softmax\+Regression}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Softmax\+Regression(\+Optimizer\+Type$<$ Softmax\+Regression\+Function $>$ \&optimizer)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::{\bf Softmax\+Regression} (
\begin{DoxyParamCaption}
\item[{Optimizer\+Type$<$ {\bf Softmax\+Regression\+Function} $>$ \&}]{optimizer}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1regression_1_1SoftmaxRegression_adfef2876f32c0935c2778cd6b2b03c7a}


Construct the softmax regression model with the given training data. 

This will train the model. This overload takes an already instantiated optimizer and uses it to train the model. The optimizer should hold an instantiated \doxyref{Softmax\+Regression\+Function}{p.}{classmlpack_1_1regression_1_1SoftmaxRegressionFunction} object for the function to operate upon. This option should be preferred when the optimizer options are to be changed.


\begin{DoxyParams}{Parameters}
{\em optimizer} & Instantiated optimizer with instantiated error function. \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Classify@{Classify}}
\index{Classify@{Classify}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Classify(const arma\+::mat \&dataset, arma\+::\+Row$<$ size\+\_\+t $>$ \&labels) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ void {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Classify (
\begin{DoxyParamCaption}
\item[{const arma\+::mat \&}]{dataset, }
\item[{arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ae45e4d9839896128f87a19f8185b987c}


Classify the given points, returning the predicted labels for each point. 

The function calculates the probabilities for every class, given a data point. It then chooses the class which has the highest probability among all.


\begin{DoxyParams}{Parameters}
{\em dataset} & Set of points to classify. \\
\hline
{\em labels} & Predicted labels for each point. \\
\hline
\end{DoxyParams}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Compute\+Accuracy@{Compute\+Accuracy}}
\index{Compute\+Accuracy@{Compute\+Accuracy}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Compute\+Accuracy(const arma\+::mat \&test\+Data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ double {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Compute\+Accuracy (
\begin{DoxyParamCaption}
\item[{const arma\+::mat \&}]{test\+Data, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1regression_1_1SoftmaxRegression_a4efe331c20f62c5980144c7e1d79d540}


Computes accuracy of the learned model given the feature data and the labels associated with each data point. 

Predictions are made using the provided data and are compared with the actual labels.


\begin{DoxyParams}{Parameters}
{\em test\+Data} & Matrix of data points using which predictions are made. \\
\hline
{\em labels} & Vector of labels associated with the data. \\
\hline
\end{DoxyParams}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Feature\+Size@{Feature\+Size}}
\index{Feature\+Size@{Feature\+Size}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Feature\+Size() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ size\+\_\+t {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Feature\+Size (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_abb105ab8417e765169e6e58bd1892d95}


Gets the features size of the training data. 



Definition at line 186 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::fit\+Intercept, and mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::parameters.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Fit\+Intercept@{Fit\+Intercept}}
\index{Fit\+Intercept@{Fit\+Intercept}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Fit\+Intercept() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ bool {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Fit\+Intercept (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ae458fe0155bc5bcf7098baba03ad0c5c}


Gets the intercept term flag. We can\textquotesingle{}t change this after training. 



Definition at line 178 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::fit\+Intercept.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Lambda@{Lambda}}
\index{Lambda@{Lambda}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Lambda()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ double\& {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Lambda (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_a05874dd6a0566c6fd98704469eb3c52f}


Sets the regularization parameter. 



Definition at line 173 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::lambda.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Lambda@{Lambda}}
\index{Lambda@{Lambda}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Lambda() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ double {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Lambda (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ab36546ccd6396e56aa98b944a48454f9}


Gets the regularization parameter. 



Definition at line 175 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::lambda.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Num\+Classes@{Num\+Classes}}
\index{Num\+Classes@{Num\+Classes}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Num\+Classes()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ size\+\_\+t\& {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Num\+Classes (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_a8032ac6b0433178822f5c249817064f4}


Sets the number of classes. 



Definition at line 168 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::num\+Classes.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Num\+Classes@{Num\+Classes}}
\index{Num\+Classes@{Num\+Classes}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Num\+Classes() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ size\+\_\+t {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Num\+Classes (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ac7c2654cd2afd45488a73c537aa50438}


Gets the number of classes. 



Definition at line 170 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::num\+Classes.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Parameters()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ arma\+::mat\& {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Parameters (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_abbb2e08416cb7e0d44cc978121159f8f}


Get the model parameters. 



Definition at line 181 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::parameters.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Parameters() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ const arma\+::mat\& {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Parameters (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_a8edc251f8933e00178fc6aef04e75ed6}


Get the model parameters. 



Definition at line 183 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::parameters.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Predict@{Predict}}
\index{Predict@{Predict}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Predict(const arma\+::mat \&test\+Data, arma\+::\+Row$<$ size\+\_\+t $>$ \&predictions) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ {\bf mlpack\+\_\+deprecated} void {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Predict (
\begin{DoxyParamCaption}
\item[{const arma\+::mat \&}]{test\+Data, }
\item[{arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{predictions}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ae7700132c466763bc4adf5d937979876}


Predict the class labels for the provided feature points. 

The function calculates the probabilities for every class, given a data point. It then chooses the class which has the highest probability among all.

This method is deprecated and will be removed in mlpack 3.\+0.\+0. You should use \doxyref{Classify()}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression_ae45e4d9839896128f87a19f8185b987c} instead.


\begin{DoxyParams}{Parameters}
{\em test\+Data} & Matrix of data points for which predictions are to be made. \\
\hline
{\em predictions} & Vector to store the predictions in. \\
\hline
\end{DoxyParams}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Serialize@{Serialize}}
\index{Serialize@{Serialize}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Serialize(\+Archive \&ar, const unsigned int)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ template$<$typename Archive $>$ void {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Serialize (
\begin{DoxyParamCaption}
\item[{Archive \&}]{ar, }
\item[{const unsigned}]{int}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_aa403b4fc83017f8268eee3d68bc3785d}


Serialize the \doxyref{Softmax\+Regression}{p.}{classmlpack_1_1regression_1_1SoftmaxRegression} model. 



Definition at line 194 of file softmax\+\_\+regression.\+hpp.



References mlpack\+::data\+::\+Create\+N\+V\+P(), mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::fit\+Intercept, mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::lambda, and mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::parameters.

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Train@{Train}}
\index{Train@{Train}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Train(\+Optimizer\+Type$<$ Softmax\+Regression\+Function $>$ \&optimizer)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ double {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Train (
\begin{DoxyParamCaption}
\item[{Optimizer\+Type$<$ {\bf Softmax\+Regression\+Function} $>$ \&}]{optimizer}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1regression_1_1SoftmaxRegression_a845c6e6199bd5d5cf67c4705ee23fe21}


Train the softmax regression model with the given optimizer. 

The optimizer should hold an instantiated \doxyref{Softmax\+Regression\+Function}{p.}{classmlpack_1_1regression_1_1SoftmaxRegressionFunction} object for the function to operate upon. This option should be preferred when the optimizer options are to be changed. 
\begin{DoxyParams}{Parameters}
{\em optimizer} & Instantiated optimizer with instantiated error function. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Objective value of the final point. 
\end{DoxyReturn}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!Train@{Train}}
\index{Train@{Train}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{Train(const arma\+::mat \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ double {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::Train (
\begin{DoxyParamCaption}
\item[{const arma\+::mat \&}]{data, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1regression_1_1SoftmaxRegression_a6f2f22e5d6ac416989773000c089eb49}


Train the softmax regression with the given training data. 


\begin{DoxyParams}{Parameters}
{\em data} & Input data with each column as one example. \\
\hline
{\em labels} & Labels associated with the feature data. \\
\hline
{\em num\+Classes} & Number of classes for classification. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Objective value of the final point. 
\end{DoxyReturn}


\subsection{Member Data Documentation}
\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!fit\+Intercept@{fit\+Intercept}}
\index{fit\+Intercept@{fit\+Intercept}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{fit\+Intercept}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ bool {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::fit\+Intercept\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_ae643ea6357151eb09f76e85d2e685f57}


Intercept term flag. 



Definition at line 212 of file softmax\+\_\+regression.\+hpp.



Referenced by mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Feature\+Size(), mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Fit\+Intercept(), and mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Serialize().

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!lambda@{lambda}}
\index{lambda@{lambda}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{lambda}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ double {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::lambda\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_aef8244c429815ff3172bc9adeb8547d4}


L2-\/regularization constant. 



Definition at line 210 of file softmax\+\_\+regression.\+hpp.



Referenced by mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Lambda(), and mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Serialize().

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!num\+Classes@{num\+Classes}}
\index{num\+Classes@{num\+Classes}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{num\+Classes}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ size\+\_\+t {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::num\+Classes\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_aaed8a6bfc7425da155ba44a23e4668f8}


Number of classes. 



Definition at line 208 of file softmax\+\_\+regression.\+hpp.



Referenced by mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Num\+Classes().

\index{mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}!parameters@{parameters}}
\index{parameters@{parameters}!mlpack\+::regression\+::\+Softmax\+Regression@{mlpack\+::regression\+::\+Softmax\+Regression}}
\subsubsection[{parameters}]{\setlength{\rightskip}{0pt plus 5cm}template$<$template$<$ typename $>$ class Optimizer\+Type = mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+GS$>$ arma\+::mat {\bf mlpack\+::regression\+::\+Softmax\+Regression}$<$ Optimizer\+Type $>$\+::parameters\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1regression_1_1SoftmaxRegression_adfea798694e3d7f89a6b19da02f0b44d}


Parameters after optimization. 



Definition at line 206 of file softmax\+\_\+regression.\+hpp.



Referenced by mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Feature\+Size(), mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Parameters(), and mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$\+::\+Serialize().



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/mlpack/methods/softmax\+\_\+regression/{\bf softmax\+\_\+regression.\+hpp}\end{DoxyCompactItemize}
