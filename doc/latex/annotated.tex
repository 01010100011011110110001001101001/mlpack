\section{Class List}
Here are the classes, structs, unions and interfaces with brief descriptions\+:\begin{DoxyCompactList}
\item\contentsline{section}{{\bf Is\+Vector$<$ Vec\+Type $>$} \\*If value == true, then Vec\+Type is some sort of Armadillo vector or subview }{\pageref{structIsVector}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::\+Col$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1Col_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::\+Row$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1Row_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::\+Sp\+Col$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1SpCol_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::\+Sp\+Row$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1SpRow_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::\+Sp\+Subview$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1SpSubview_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::subview\+\_\+col$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1subview__col_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf Is\+Vector$<$ arma\+::subview\+\_\+row$<$ e\+T $>$ $>$} }{\pageref{structIsVector_3_01arma_1_1subview__row_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::adaboost\+::\+Ada\+Boost$<$ Weak\+Learner\+Type, Mat\+Type $>$} \\*The \doxyref{Ada\+Boost}{p.}{classmlpack_1_1adaboost_1_1AdaBoost} class }{\pageref{classmlpack_1_1adaboost_1_1AdaBoost}}{}
\item\contentsline{section}{{\bf mlpack\+::adaboost\+::\+Ada\+Boost\+Model} \\*The model to save to disk }{\pageref{classmlpack_1_1adaboost_1_1AdaBoostModel}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+A\+M\+F$<$ Termination\+Policy\+Type, Initialization\+Rule\+Type, Update\+Rule\+Type $>$} \\*This class implements \doxyref{A\+MF}{p.}{classmlpack_1_1amf_1_1AMF} (alternating matrix factorization) on the given matrix V }{\pageref{classmlpack_1_1amf_1_1AMF}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Average\+Initialization} \\*This initialization rule initializes matrix W and H to root of the average of V, perturbed with uniform noise }{\pageref{classmlpack_1_1amf_1_1AverageInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Complete\+Incremental\+Termination$<$ Termination\+Policy $>$} \\*This class acts as a wrapper for basic termination policies to be used by \doxyref{S\+V\+D\+Complete\+Incremental\+Learning}{p.}{classmlpack_1_1amf_1_1SVDCompleteIncrementalLearning} }{\pageref{classmlpack_1_1amf_1_1CompleteIncrementalTermination}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Given\+Initialization} \\*This initialization rule for \doxyref{A\+MF}{p.}{classmlpack_1_1amf_1_1AMF} simply fills the W and H matrices with the matrices given to the constructor of this object }{\pageref{classmlpack_1_1amf_1_1GivenInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Incomplete\+Incremental\+Termination$<$ Termination\+Policy $>$} \\*This class acts as a wrapper for basic termination policies to be used by \doxyref{S\+V\+D\+Incomplete\+Incremental\+Learning}{p.}{classmlpack_1_1amf_1_1SVDIncompleteIncrementalLearning} }{\pageref{classmlpack_1_1amf_1_1IncompleteIncrementalTermination}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Max\+Iteration\+Termination} \\*This termination policy only terminates when the maximum number of iterations has been reached }{\pageref{classmlpack_1_1amf_1_1MaxIterationTermination}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+N\+M\+F\+A\+L\+S\+Update} \\*This class implements a method titled \textquotesingle{}Alternating Least Squares\textquotesingle{} described in the following paper\+: }{\pageref{classmlpack_1_1amf_1_1NMFALSUpdate}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+N\+M\+F\+Multiplicative\+Distance\+Update} \\*The multiplicative distance update rules for matrices W and H }{\pageref{classmlpack_1_1amf_1_1NMFMultiplicativeDistanceUpdate}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+N\+M\+F\+Multiplicative\+Divergence\+Update} \\*This follows a method described in the paper \textquotesingle{}Algorithms for Non-\/negative }{\pageref{classmlpack_1_1amf_1_1NMFMultiplicativeDivergenceUpdate}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Random\+Acol\+Initialization$<$ columns\+To\+Average $>$} \\*This class initializes the W matrix of the \doxyref{A\+MF}{p.}{classmlpack_1_1amf_1_1AMF} algorithm by averaging p randomly chosen columns of V }{\pageref{classmlpack_1_1amf_1_1RandomAcolInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Random\+Initialization} \\*This initialization rule for \doxyref{A\+MF}{p.}{classmlpack_1_1amf_1_1AMF} simply fills the W and H matrices with uniform random noise in [0, 1] }{\pageref{classmlpack_1_1amf_1_1RandomInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Simple\+Residue\+Termination} \\*This class implements a simple residue-\/based termination policy }{\pageref{classmlpack_1_1amf_1_1SimpleResidueTermination}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Simple\+Tolerance\+Termination$<$ Mat\+Type $>$} \\*This class implements residue tolerance termination policy }{\pageref{classmlpack_1_1amf_1_1SimpleToleranceTermination}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+S\+V\+D\+Batch\+Learning} \\*This class implements S\+VD batch learning with momentum }{\pageref{classmlpack_1_1amf_1_1SVDBatchLearning}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+S\+V\+D\+Complete\+Incremental\+Learning$<$ Mat\+Type $>$} \\*This class computes S\+VD using complete incremental batch learning, as described in the following paper\+: }{\pageref{classmlpack_1_1amf_1_1SVDCompleteIncrementalLearning}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+S\+V\+D\+Complete\+Incremental\+Learning$<$ arma\+::sp\+\_\+mat $>$} \\*T\+O\+DO \+: Merge this template specialized function for sparse matrix using common row\+\_\+col\+\_\+iterator }{\pageref{classmlpack_1_1amf_1_1SVDCompleteIncrementalLearning_3_01arma_1_1sp__mat_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+S\+V\+D\+Incomplete\+Incremental\+Learning} \\*This class computes S\+VD using incomplete incremental batch learning, as described in the following paper\+: }{\pageref{classmlpack_1_1amf_1_1SVDIncompleteIncrementalLearning}}{}
\item\contentsline{section}{{\bf mlpack\+::amf\+::\+Validation\+R\+M\+S\+E\+Termination$<$ Mat\+Type $>$} \\*This class implements validation termination policy based on R\+M\+SE index }{\pageref{classmlpack_1_1amf_1_1ValidationRMSETermination}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Add$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Add}{p.}{classmlpack_1_1ann_1_1Add} module class }{\pageref{classmlpack_1_1ann_1_1Add}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} module class }{\pageref{classmlpack_1_1ann_1_1AddMerge}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Add\+Visitor} \\*\doxyref{Add\+Visitor}{p.}{classmlpack_1_1ann_1_1AddVisitor} exposes the Add() method of the given module }{\pageref{classmlpack_1_1ann_1_1AddVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Backward\+Visitor} \\*\doxyref{Backward\+Visitor}{p.}{classmlpack_1_1ann_1_1BackwardVisitor} executes the Backward() function given the input, error and delta parameter }{\pageref{classmlpack_1_1ann_1_1BackwardVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the base layer }{\pageref{classmlpack_1_1ann_1_1BaseLayer}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Concat$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Concat}{p.}{classmlpack_1_1ann_1_1Concat} class }{\pageref{classmlpack_1_1ann_1_1Concat}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Concat\+Performance$<$ Output\+Layer\+Type, Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the concat performance class }{\pageref{classmlpack_1_1ann_1_1ConcatPerformance}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Constant$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the constant layer }{\pageref{classmlpack_1_1ann_1_1Constant}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Convolution$<$ Forward\+Convolution\+Rule, Backward\+Convolution\+Rule, Gradient\+Convolution\+Rule, Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Convolution}{p.}{classmlpack_1_1ann_1_1Convolution} class }{\pageref{classmlpack_1_1ann_1_1Convolution}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Delete\+Visitor} \\*\doxyref{Delete\+Visitor}{p.}{classmlpack_1_1ann_1_1DeleteVisitor} executes the destructor of the instantiated object }{\pageref{classmlpack_1_1ann_1_1DeleteVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Delta\+Visitor} \\*\doxyref{Delta\+Visitor}{p.}{classmlpack_1_1ann_1_1DeltaVisitor} exposes the delta parameter of the given module }{\pageref{classmlpack_1_1ann_1_1DeltaVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Deterministic\+Set\+Visitor} \\*\doxyref{Deterministic\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1DeterministicSetVisitor} set the deterministic parameter given the deterministic value }{\pageref{classmlpack_1_1ann_1_1DeterministicSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Drop\+Connect$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The \doxyref{Drop\+Connect}{p.}{classmlpack_1_1ann_1_1DropConnect} layer is a regularizer that randomly with probability ratio sets the connection values to zero and scales the remaining elements by factor 1 /(1 -\/ ratio) }{\pageref{classmlpack_1_1ann_1_1DropConnect}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Dropout$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The dropout layer is a regularizer that randomly with probability ratio sets input values to zero and scales the remaining elements by factor 1 / (1 -\/ ratio) }{\pageref{classmlpack_1_1ann_1_1Dropout}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+E\+L\+U$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The \doxyref{E\+LU}{p.}{classmlpack_1_1ann_1_1ELU} activation function, defined by }{\pageref{classmlpack_1_1ann_1_1ELU}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+F\+F\+N$<$ Output\+Layer\+Type, Initialization\+Rule\+Type $>$} \\*Implementation of a standard feed forward network }{\pageref{classmlpack_1_1ann_1_1FFN}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+F\+F\+T\+Convolution$<$ Border\+Mode, pad\+Last\+Dim $>$} \\*Computes the two-\/dimensional convolution through fft }{\pageref{classmlpack_1_1ann_1_1FFTConvolution}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Forward\+Visitor} \\*\doxyref{Forward\+Visitor}{p.}{classmlpack_1_1ann_1_1ForwardVisitor} executes the Forward() function given the input and output parameter }{\pageref{classmlpack_1_1ann_1_1ForwardVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Full\+Convolution} }{\pageref{classmlpack_1_1ann_1_1FullConvolution}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Glimpse$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The glimpse layer returns a retina-\/like representation (down-\/scaled cropped images) of increasing scale around a given location in a given image }{\pageref{classmlpack_1_1ann_1_1Glimpse}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Gradient\+Set\+Visitor} \\*\doxyref{Gradient\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1GradientSetVisitor} update the gradient parameter given the gradient set }{\pageref{classmlpack_1_1ann_1_1GradientSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Gradient\+Update\+Visitor} \\*\doxyref{Gradient\+Update\+Visitor}{p.}{classmlpack_1_1ann_1_1GradientUpdateVisitor} update the gradient parameter given the gradient set }{\pageref{classmlpack_1_1ann_1_1GradientUpdateVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Gradient\+Visitor} \\*Search\+Mode\+Visitor executes the Gradient() method of the given module using the input and delta parameter }{\pageref{classmlpack_1_1ann_1_1GradientVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Gradient\+Zero\+Visitor} }{\pageref{classmlpack_1_1ann_1_1GradientZeroVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Hard\+Tan\+H$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The Hard Tanh activation function, defined by }{\pageref{classmlpack_1_1ann_1_1HardTanH}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Identity\+Function} \\*The identity function, defined by }{\pageref{classmlpack_1_1ann_1_1IdentityFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Join$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Join}{p.}{classmlpack_1_1ann_1_1Join} module class }{\pageref{classmlpack_1_1ann_1_1Join}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Kathirvalavakumar\+Subavathi\+Initialization} \\*This class is used to initialize the weight matrix with the method proposed by T }{\pageref{classmlpack_1_1ann_1_1KathirvalavakumarSubavathiInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Layer\+Traits$<$ Layer\+Type $>$} \\*This is a template class that can provide information about various layers }{\pageref{classmlpack_1_1ann_1_1LayerTraits}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Leaky\+Re\+L\+U$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The \doxyref{Leaky\+Re\+LU}{p.}{classmlpack_1_1ann_1_1LeakyReLU} activation function, defined by }{\pageref{classmlpack_1_1ann_1_1LeakyReLU}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Linear$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} layer class }{\pageref{classmlpack_1_1ann_1_1Linear}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Linear\+No\+Bias$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Linear\+No\+Bias}{p.}{classmlpack_1_1ann_1_1LinearNoBias} class }{\pageref{classmlpack_1_1ann_1_1LinearNoBias}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Load\+Output\+Parameter\+Visitor} \\*\doxyref{Load\+Output\+Parameter\+Visitor}{p.}{classmlpack_1_1ann_1_1LoadOutputParameterVisitor} restores the output parameter using the given parameter set }{\pageref{classmlpack_1_1ann_1_1LoadOutputParameterVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Logistic\+Function} \\*The logistic function, defined by }{\pageref{classmlpack_1_1ann_1_1LogisticFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Log\+Soft\+Max$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the log softmax layer }{\pageref{classmlpack_1_1ann_1_1LogSoftMax}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Lookup$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Lookup}{p.}{classmlpack_1_1ann_1_1Lookup} class }{\pageref{classmlpack_1_1ann_1_1Lookup}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+L\+S\+T\+M$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*An implementation of a lstm network layer }{\pageref{classmlpack_1_1ann_1_1LSTM}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Max\+Pooling$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Max\+Pooling}{p.}{classmlpack_1_1ann_1_1MaxPooling} layer }{\pageref{classmlpack_1_1ann_1_1MaxPooling}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Max\+Pooling\+Rule} }{\pageref{classmlpack_1_1ann_1_1MaxPoolingRule}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Mean\+Pooling$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Mean\+Pooling}{p.}{classmlpack_1_1ann_1_1MeanPooling} }{\pageref{classmlpack_1_1ann_1_1MeanPooling}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Mean\+Pooling\+Rule} }{\pageref{classmlpack_1_1ann_1_1MeanPoolingRule}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Mean\+Squared\+Error$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The mean squared error performance function measures the network\textquotesingle{}s performance according to the mean of squared errors }{\pageref{classmlpack_1_1ann_1_1MeanSquaredError}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Multiply\+Constant$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the multiply constant layer }{\pageref{classmlpack_1_1ann_1_1MultiplyConstant}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Naive\+Convolution$<$ Border\+Mode $>$} \\*Computes the two-\/dimensional convolution }{\pageref{classmlpack_1_1ann_1_1NaiveConvolution}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Negative\+Log\+Likelihood$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the negative log likelihood layer }{\pageref{classmlpack_1_1ann_1_1NegativeLogLikelihood}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Nguyen\+Widrow\+Initialization} \\*This class is used to initialize the weight matrix with the Nguyen-\/\+Widrow method }{\pageref{classmlpack_1_1ann_1_1NguyenWidrowInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Oivs\+Initialization$<$ Activation\+Function $>$} \\*This class is used to initialize the weight matrix with the oivs method }{\pageref{classmlpack_1_1ann_1_1OivsInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Orthogonal\+Initialization} \\*This class is used to initialize the weight matrix with the orthogonal matrix initialization }{\pageref{classmlpack_1_1ann_1_1OrthogonalInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Output\+Height\+Visitor} \\*\doxyref{Output\+Width\+Visitor}{p.}{classmlpack_1_1ann_1_1OutputWidthVisitor} exposes the Output\+Height() method of the given module }{\pageref{classmlpack_1_1ann_1_1OutputHeightVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Output\+Parameter\+Visitor} \\*\doxyref{Output\+Parameter\+Visitor}{p.}{classmlpack_1_1ann_1_1OutputParameterVisitor} exposes the output parameter of the given module }{\pageref{classmlpack_1_1ann_1_1OutputParameterVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Output\+Width\+Visitor} \\*\doxyref{Output\+Width\+Visitor}{p.}{classmlpack_1_1ann_1_1OutputWidthVisitor} exposes the Output\+Width() method of the given module }{\pageref{classmlpack_1_1ann_1_1OutputWidthVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Parameters\+Set\+Visitor} \\*\doxyref{Parameters\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1ParametersSetVisitor} update the parameters set using the given matrix }{\pageref{classmlpack_1_1ann_1_1ParametersSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Parameters\+Visitor} \\*\doxyref{Parameters\+Visitor}{p.}{classmlpack_1_1ann_1_1ParametersVisitor} exposes the parameters set of the given module and stores the parameters set into the given matrix }{\pageref{classmlpack_1_1ann_1_1ParametersVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+P\+Re\+L\+U$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The \doxyref{P\+Re\+LU}{p.}{classmlpack_1_1ann_1_1PReLU} activation function, defined by (where alpha is trainable) }{\pageref{classmlpack_1_1ann_1_1PReLU}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Random\+Initialization} \\*This class is used to initialize randomly the weight matrix }{\pageref{classmlpack_1_1ann_1_1RandomInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Rectifier\+Function} \\*The rectifier function, defined by }{\pageref{classmlpack_1_1ann_1_1RectifierFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Recurrent$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the Recurrent\+Layer class }{\pageref{classmlpack_1_1ann_1_1Recurrent}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Recurrent\+Attention$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*This class implements the \doxyref{Recurrent}{p.}{classmlpack_1_1ann_1_1Recurrent} Model for Visual Attention, using a variety of possible layer implementations }{\pageref{classmlpack_1_1ann_1_1RecurrentAttention}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Reinforce\+Normal$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the reinforce normal layer }{\pageref{classmlpack_1_1ann_1_1ReinforceNormal}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Reset\+Visitor} \\*\doxyref{Reset\+Visitor}{p.}{classmlpack_1_1ann_1_1ResetVisitor} executes the Reset() function }{\pageref{classmlpack_1_1ann_1_1ResetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Reward\+Set\+Visitor} \\*\doxyref{Reward\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1RewardSetVisitor} set the reward parameter given the reward value }{\pageref{classmlpack_1_1ann_1_1RewardSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+R\+N\+N$<$ Output\+Layer\+Type, Initialization\+Rule\+Type $>$} \\*Implementation of a standard recurrent neural network container }{\pageref{classmlpack_1_1ann_1_1RNN}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Save\+Output\+Parameter\+Visitor} \\*\doxyref{Save\+Output\+Parameter\+Visitor}{p.}{classmlpack_1_1ann_1_1SaveOutputParameterVisitor} saves the output parameter into the given parameter set }{\pageref{classmlpack_1_1ann_1_1SaveOutputParameterVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Select$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*The select module selects the specified column from a given input matrix }{\pageref{classmlpack_1_1ann_1_1Select}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Sequential$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the \doxyref{Sequential}{p.}{classmlpack_1_1ann_1_1Sequential} class }{\pageref{classmlpack_1_1ann_1_1Sequential}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Set\+Input\+Height\+Visitor} \\*\doxyref{Set\+Input\+Height\+Visitor}{p.}{classmlpack_1_1ann_1_1SetInputHeightVisitor} updates the input height parameter with the given input height }{\pageref{classmlpack_1_1ann_1_1SetInputHeightVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Set\+Input\+Width\+Visitor} \\*\doxyref{Set\+Input\+Width\+Visitor}{p.}{classmlpack_1_1ann_1_1SetInputWidthVisitor} updates the input width parameter with the given input width }{\pageref{classmlpack_1_1ann_1_1SetInputWidthVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Softplus\+Function} \\*The softplus function, defined by }{\pageref{classmlpack_1_1ann_1_1SoftplusFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Softsign\+Function} \\*The softsign function, defined by }{\pageref{classmlpack_1_1ann_1_1SoftsignFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+S\+V\+D\+Convolution$<$ Border\+Mode $>$} \\*Computes the two-\/dimensional convolution using singular value decomposition }{\pageref{classmlpack_1_1ann_1_1SVDConvolution}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Tanh\+Function} \\*The tanh function, defined by }{\pageref{classmlpack_1_1ann_1_1TanhFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Valid\+Convolution} }{\pageref{classmlpack_1_1ann_1_1ValidConvolution}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+V\+R\+Class\+Reward$<$ Input\+Data\+Type, Output\+Data\+Type $>$} \\*Implementation of the variance reduced classification reinforcement layer }{\pageref{classmlpack_1_1ann_1_1VRClassReward}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Weight\+Set\+Visitor} \\*\doxyref{Weight\+Set\+Visitor}{p.}{classmlpack_1_1ann_1_1WeightSetVisitor} update the module parameters given the parameters set }{\pageref{classmlpack_1_1ann_1_1WeightSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Weight\+Size\+Visitor} \\*\doxyref{Weight\+Size\+Visitor}{p.}{classmlpack_1_1ann_1_1WeightSizeVisitor} returns the number of weights of the given module }{\pageref{classmlpack_1_1ann_1_1WeightSizeVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::ann\+::\+Zero\+Initialization} \\*This class is used to initialize randomly the weight matrix }{\pageref{classmlpack_1_1ann_1_1ZeroInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::\+Backtrace} \\*Provides a backtrace }{\pageref{classmlpack_1_1Backtrace}}{}
\item\contentsline{section}{{\bf mlpack\+::\+Backtrace\+::\+Frames} \\*\doxyref{Backtrace}{p.}{classmlpack_1_1Backtrace} datastructure }{\pageref{structmlpack_1_1Backtrace_1_1Frames}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Ball\+Bound$<$ Metric\+Type, Vec\+Type $>$} \\*Ball bound encloses a set of points at a specific distance (radius) from a specific point (center) }{\pageref{classmlpack_1_1bound_1_1BallBound}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Bound\+Traits$<$ Bound\+Type $>$} \\*A class to obtain compile-\/time traits about Bound\+Type classes }{\pageref{structmlpack_1_1bound_1_1BoundTraits}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Bound\+Traits$<$ Ball\+Bound$<$ Metric\+Type, Vec\+Type $>$ $>$} \\*A specialization of \doxyref{Bound\+Traits}{p.}{structmlpack_1_1bound_1_1BoundTraits} for this bound type }{\pageref{structmlpack_1_1bound_1_1BoundTraits_3_01BallBound_3_01MetricType_00_01VecType_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Bound\+Traits$<$ Cell\+Bound$<$ Metric\+Type, Elem\+Type $>$ $>$} }{\pageref{structmlpack_1_1bound_1_1BoundTraits_3_01CellBound_3_01MetricType_00_01ElemType_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Bound\+Traits$<$ Hollow\+Ball\+Bound$<$ Metric\+Type, Elem\+Type $>$ $>$} \\*A specialization of \doxyref{Bound\+Traits}{p.}{structmlpack_1_1bound_1_1BoundTraits} for this bound type }{\pageref{structmlpack_1_1bound_1_1BoundTraits_3_01HollowBallBound_3_01MetricType_00_01ElemType_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Bound\+Traits$<$ H\+Rect\+Bound$<$ Metric\+Type, Elem\+Type $>$ $>$} }{\pageref{structmlpack_1_1bound_1_1BoundTraits_3_01HRectBound_3_01MetricType_00_01ElemType_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Cell\+Bound$<$ Metric\+Type, Elem\+Type $>$} \\*The \doxyref{Cell\+Bound}{p.}{classmlpack_1_1bound_1_1CellBound} class describes a bound that consists of a number of hyperrectangles }{\pageref{classmlpack_1_1bound_1_1CellBound}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+Hollow\+Ball\+Bound$<$ T\+Metric\+Type, Elem\+Type $>$} \\*Hollow ball bound encloses a set of points at a specific distance (radius) from a specific point (center) except points at a specific distance from another point (the center of the hole) }{\pageref{classmlpack_1_1bound_1_1HollowBallBound}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::\+H\+Rect\+Bound$<$ Metric\+Type, Elem\+Type $>$} \\*Hyper-\/rectangle bound for an L-\/metric }{\pageref{classmlpack_1_1bound_1_1HRectBound}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::meta\+::\+Is\+L\+Metric$<$ Metric\+Type $>$} \\*Utility struct where Value is true if and only if the argument is of type L\+Metric }{\pageref{structmlpack_1_1bound_1_1meta_1_1IsLMetric}}{}
\item\contentsline{section}{{\bf mlpack\+::bound\+::meta\+::\+Is\+L\+Metric$<$ metric\+::\+L\+Metric$<$ Power, Take\+Root $>$ $>$} \\*Specialization for \doxyref{Is\+L\+Metric}{p.}{structmlpack_1_1bound_1_1meta_1_1IsLMetric} when the argument is of type L\+Metric }{\pageref{structmlpack_1_1bound_1_1meta_1_1IsLMetric_3_01metric_1_1LMetric_3_01Power_00_01TakeRoot_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::cf\+::\+CF} \\*This class implements Collaborative Filtering (\doxyref{CF}{p.}{classmlpack_1_1cf_1_1CF}) }{\pageref{classmlpack_1_1cf_1_1CF}}{}
\item\contentsline{section}{{\bf mlpack\+::cf\+::\+C\+F\+::\+Candidate\+Cmp} \\*Compare two candidates based on the value }{\pageref{structmlpack_1_1cf_1_1CF_1_1CandidateCmp}}{}
\item\contentsline{section}{{\bf mlpack\+::cf\+::\+Dummy\+Class} \\*This class acts as a dummy class for passing as template parameter }{\pageref{classmlpack_1_1cf_1_1DummyClass}}{}
\item\contentsline{section}{{\bf mlpack\+::cf\+::\+Factorizer\+Traits$<$ Factorizer\+Type $>$} \\*Template class for factorizer traits }{\pageref{structmlpack_1_1cf_1_1FactorizerTraits}}{}
\item\contentsline{section}{{\bf mlpack\+::cf\+::\+Factorizer\+Traits$<$ mlpack\+::svd\+::\+Regularized\+S\+V\+D$<$$>$ $>$} \\*Factorizer traits of Regularized S\+VD }{\pageref{classmlpack_1_1cf_1_1FactorizerTraits_3_01mlpack_1_1svd_1_1RegularizedSVD_3_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::cf\+::\+S\+V\+D\+Wrapper$<$ Factorizer $>$} \\*This class acts as the wrapper for all S\+VD factorizers which are incompatible with \doxyref{CF}{p.}{classmlpack_1_1cf_1_1CF} module }{\pageref{classmlpack_1_1cf_1_1SVDWrapper}}{}
\item\contentsline{section}{{\bf mlpack\+::\+C\+LI} \\*Parses the command line for parameters and holds user-\/specified parameters }{\pageref{classmlpack_1_1CLI}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Custom\+Imputation$<$ T $>$} \\*A simple custom imputation class }{\pageref{classmlpack_1_1data_1_1CustomImputation}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Dataset\+Mapper$<$ Policy\+Type $>$} \\*Auxiliary information for a dataset, including mappings to/from strings and the datatype of each dimension }{\pageref{classmlpack_1_1data_1_1DatasetMapper}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+First\+Array\+Shim$<$ T $>$} \\*A first shim for arrays }{\pageref{structmlpack_1_1data_1_1FirstArrayShim}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+First\+Normal\+Array\+Shim$<$ T $>$} \\*A first shim for arrays without a Serialize() method }{\pageref{structmlpack_1_1data_1_1FirstNormalArrayShim}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+First\+Shim$<$ T $>$} \\*The first shim\+: simply holds the object and its name }{\pageref{structmlpack_1_1data_1_1FirstShim}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Has\+Serialize$<$ T $>$} }{\pageref{structmlpack_1_1data_1_1HasSerialize}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Has\+Serialize$<$ T $>$\+::check$<$ U, V, W $>$} }{\pageref{structmlpack_1_1data_1_1HasSerialize_1_1check}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Has\+Serialize\+Function$<$ T $>$} }{\pageref{structmlpack_1_1data_1_1HasSerializeFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Imputer$<$ T, Mapper\+Type, Strategy\+Type $>$} \\*Given a dataset of a particular datatype, replace user-\/specified missing value with a variable dependent on the Strategy\+Type and Mapper\+Type }{\pageref{classmlpack_1_1data_1_1Imputer}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Increment\+Policy} \\*\doxyref{Increment\+Policy}{p.}{classmlpack_1_1data_1_1IncrementPolicy} is used as a helper class for \doxyref{Dataset\+Mapper}{p.}{classmlpack_1_1data_1_1DatasetMapper} }{\pageref{classmlpack_1_1data_1_1IncrementPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Listwise\+Deletion$<$ T $>$} \\*A complete-\/case analysis to remove the values containing mapped\+Value }{\pageref{classmlpack_1_1data_1_1ListwiseDeletion}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Load\+C\+SV} \\*Load the csv file.\+This class use boost\+::spirit to implement the parser, please refer to following link {\tt http\+://theboostcpplibraries.\+com/boost.\+spirit} for quick review }{\pageref{classmlpack_1_1data_1_1LoadCSV}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Load\+C\+S\+V\+::\+Elem\+Parser} }{\pageref{structmlpack_1_1data_1_1LoadCSV_1_1ElemParser}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Mean\+Imputation$<$ T $>$} \\*A simple mean imputation class }{\pageref{classmlpack_1_1data_1_1MeanImputation}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Median\+Imputation$<$ T $>$} \\*This is a class implementation of simple median imputation }{\pageref{classmlpack_1_1data_1_1MedianImputation}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Missing\+Policy} \\*\doxyref{Missing\+Policy}{p.}{classmlpack_1_1data_1_1MissingPolicy} is used as a helper class for \doxyref{Dataset\+Mapper}{p.}{classmlpack_1_1data_1_1DatasetMapper} }{\pageref{classmlpack_1_1data_1_1MissingPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Pointer\+Shim$<$ T $>$} \\*A shim for pointers }{\pageref{structmlpack_1_1data_1_1PointerShim}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Second\+Array\+Shim$<$ T $>$} \\*A shim for objects in an array; this is basically like the \doxyref{Second\+Shim}{p.}{structmlpack_1_1data_1_1SecondShim}, but for arrays that hold objects that have Serialize() methods instead of \doxyref{serialize()}{p.}{structmlpack_1_1data_1_1SecondArrayShim_a9b7f34ee88e73a99ced7ca803c6c010d} methods }{\pageref{structmlpack_1_1data_1_1SecondArrayShim}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Second\+Normal\+Array\+Shim$<$ T $>$} \\*A shim for objects in an array which do not have a Serialize() function }{\pageref{structmlpack_1_1data_1_1SecondNormalArrayShim}}{}
\item\contentsline{section}{{\bf mlpack\+::data\+::\+Second\+Shim$<$ T $>$} \\*The second shim\+: wrap the call to Serialize() inside of a \doxyref{serialize()}{p.}{structmlpack_1_1data_1_1SecondShim_af876ca6368e66bbfebbfa8ca25ad3b45} function, so that an archive type can call \doxyref{serialize()}{p.}{structmlpack_1_1data_1_1SecondShim_af876ca6368e66bbfebbfa8ca25ad3b45} on a \doxyref{Second\+Shim}{p.}{structmlpack_1_1data_1_1SecondShim} object and this gets forwarded correctly to our object\textquotesingle{}s Serialize() function }{\pageref{structmlpack_1_1data_1_1SecondShim}}{}
\item\contentsline{section}{{\bf mlpack\+::dbscan\+::\+D\+B\+S\+C\+A\+N$<$ Range\+Search\+Type, Point\+Selection\+Policy $>$} \\*\doxyref{D\+B\+S\+C\+AN}{p.}{classmlpack_1_1dbscan_1_1DBSCAN} (Density-\/\+Based Spatial Clustering of Applications with Noise) is a clustering technique described in the following paper\+: }{\pageref{classmlpack_1_1dbscan_1_1DBSCAN}}{}
\item\contentsline{section}{{\bf mlpack\+::dbscan\+::\+Random\+Point\+Selection} \\*This class can be used to randomly select the next point to use for \doxyref{D\+B\+S\+C\+AN}{p.}{classmlpack_1_1dbscan_1_1DBSCAN} }{\pageref{classmlpack_1_1dbscan_1_1RandomPointSelection}}{}
\item\contentsline{section}{{\bf mlpack\+::decision\+\_\+stump\+::\+Decision\+Stump$<$ Mat\+Type $>$} \\*This class implements a decision stump }{\pageref{classmlpack_1_1decision__stump_1_1DecisionStump}}{}
\item\contentsline{section}{{\bf mlpack\+::det\+::\+D\+Tree$<$ Mat\+Type, Tag\+Type $>$} \\*A density estimation tree is similar to both a decision tree and a space partitioning tree (like a kd-\/tree) }{\pageref{classmlpack_1_1det_1_1DTree}}{}
\item\contentsline{section}{{\bf mlpack\+::distribution\+::\+Discrete\+Distribution} \\*A discrete distribution where the only observations are discrete observations }{\pageref{classmlpack_1_1distribution_1_1DiscreteDistribution}}{}
\item\contentsline{section}{{\bf mlpack\+::distribution\+::\+Gamma\+Distribution} \\*This class represents the Gamma distribution }{\pageref{classmlpack_1_1distribution_1_1GammaDistribution}}{}
\item\contentsline{section}{{\bf mlpack\+::distribution\+::\+Gaussian\+Distribution} \\*A single multivariate Gaussian distribution }{\pageref{classmlpack_1_1distribution_1_1GaussianDistribution}}{}
\item\contentsline{section}{{\bf mlpack\+::distribution\+::\+Laplace\+Distribution} \\*The multivariate Laplace distribution centered at 0 has pdf }{\pageref{classmlpack_1_1distribution_1_1LaplaceDistribution}}{}
\item\contentsline{section}{{\bf mlpack\+::distribution\+::\+Regression\+Distribution} \\*A class that represents a univariate conditionally Gaussian distribution }{\pageref{classmlpack_1_1distribution_1_1RegressionDistribution}}{}
\item\contentsline{section}{{\bf mlpack\+::emst\+::\+D\+T\+B\+Rules$<$ Metric\+Type, Tree\+Type $>$} }{\pageref{classmlpack_1_1emst_1_1DTBRules}}{}
\item\contentsline{section}{{\bf mlpack\+::emst\+::\+D\+T\+B\+Stat} \\*A statistic for use with mlpack trees, which stores the upper bound on distance to nearest neighbors and the component which this node belongs to }{\pageref{classmlpack_1_1emst_1_1DTBStat}}{}
\item\contentsline{section}{{\bf mlpack\+::emst\+::\+Dual\+Tree\+Boruvka$<$ Metric\+Type, Mat\+Type, Tree\+Type $>$} \\*Performs the M\+ST calculation using the Dual-\/\+Tree Boruvka algorithm, using any type of tree }{\pageref{classmlpack_1_1emst_1_1DualTreeBoruvka}}{}
\item\contentsline{section}{{\bf mlpack\+::emst\+::\+Dual\+Tree\+Boruvka$<$ Metric\+Type, Mat\+Type, Tree\+Type $>$\+::\+Sort\+Edges\+Helper} \\*For sorting the edge list after the computation }{\pageref{structmlpack_1_1emst_1_1DualTreeBoruvka_1_1SortEdgesHelper}}{}
\item\contentsline{section}{{\bf mlpack\+::emst\+::\+Edge\+Pair} \\*An edge pair is simply two indices and a distance }{\pageref{classmlpack_1_1emst_1_1EdgePair}}{}
\item\contentsline{section}{{\bf mlpack\+::emst\+::\+Union\+Find} \\*A Union-\/\+Find data structure }{\pageref{classmlpack_1_1emst_1_1UnionFind}}{}
\item\contentsline{section}{{\bf mlpack\+::fastmks\+::\+Fast\+M\+K\+S$<$ Kernel\+Type, Mat\+Type, Tree\+Type $>$} \\*An implementation of fast exact max-\/kernel search }{\pageref{classmlpack_1_1fastmks_1_1FastMKS}}{}
\item\contentsline{section}{{\bf mlpack\+::fastmks\+::\+Fast\+M\+K\+S$<$ Kernel\+Type, Mat\+Type, Tree\+Type $>$\+::\+Candidate\+Cmp} \\*Compare two candidates based on the value }{\pageref{structmlpack_1_1fastmks_1_1FastMKS_1_1CandidateCmp}}{}
\item\contentsline{section}{{\bf mlpack\+::fastmks\+::\+Fast\+M\+K\+S\+Model} \\*A utility struct to contain all the possible \doxyref{Fast\+M\+KS}{p.}{classmlpack_1_1fastmks_1_1FastMKS} models, for use by the mlpack\+\_\+fastmks program }{\pageref{classmlpack_1_1fastmks_1_1FastMKSModel}}{}
\item\contentsline{section}{{\bf mlpack\+::fastmks\+::\+Fast\+M\+K\+S\+Rules$<$ Kernel\+Type, Tree\+Type $>$} \\*The \doxyref{Fast\+M\+K\+S\+Rules}{p.}{classmlpack_1_1fastmks_1_1FastMKSRules} class is a template helper class used by \doxyref{Fast\+M\+KS}{p.}{classmlpack_1_1fastmks_1_1FastMKS} class when performing exact max-\/kernel search }{\pageref{classmlpack_1_1fastmks_1_1FastMKSRules}}{}
\item\contentsline{section}{{\bf mlpack\+::fastmks\+::\+Fast\+M\+K\+S\+Rules$<$ Kernel\+Type, Tree\+Type $>$\+::\+Candidate\+Cmp} \\*Compare two candidates based on the value }{\pageref{structmlpack_1_1fastmks_1_1FastMKSRules_1_1CandidateCmp}}{}
\item\contentsline{section}{{\bf mlpack\+::fastmks\+::\+Fast\+M\+K\+S\+Stat} \\*The statistic used in trees with \doxyref{Fast\+M\+KS}{p.}{classmlpack_1_1fastmks_1_1FastMKS} }{\pageref{classmlpack_1_1fastmks_1_1FastMKSStat}}{}
\item\contentsline{section}{{\bf mlpack\+::gmm\+::\+Diagonal\+Constraint} \\*Force a covariance matrix to be diagonal }{\pageref{classmlpack_1_1gmm_1_1DiagonalConstraint}}{}
\item\contentsline{section}{{\bf mlpack\+::gmm\+::\+Eigenvalue\+Ratio\+Constraint} \\*Given a vector of eigenvalue ratios, ensure that the covariance matrix always has those eigenvalue ratios }{\pageref{classmlpack_1_1gmm_1_1EigenvalueRatioConstraint}}{}
\item\contentsline{section}{{\bf mlpack\+::gmm\+::\+E\+M\+Fit$<$ Initial\+Clustering\+Type, Covariance\+Constraint\+Policy $>$} \\*This class contains methods which can fit a \doxyref{G\+MM}{p.}{classmlpack_1_1gmm_1_1GMM} to observations using the EM algorithm }{\pageref{classmlpack_1_1gmm_1_1EMFit}}{}
\item\contentsline{section}{{\bf mlpack\+::gmm\+::\+G\+MM} \\*A Gaussian Mixture Model (\doxyref{G\+MM}{p.}{classmlpack_1_1gmm_1_1GMM}) }{\pageref{classmlpack_1_1gmm_1_1GMM}}{}
\item\contentsline{section}{{\bf mlpack\+::gmm\+::\+No\+Constraint} \\*This class enforces no constraint on the covariance matrix }{\pageref{classmlpack_1_1gmm_1_1NoConstraint}}{}
\item\contentsline{section}{{\bf mlpack\+::gmm\+::\+Positive\+Definite\+Constraint} \\*Given a covariance matrix, force the matrix to be positive definite }{\pageref{classmlpack_1_1gmm_1_1PositiveDefiniteConstraint}}{}
\item\contentsline{section}{{\bf mlpack\+::hmm\+::\+H\+M\+M$<$ Distribution $>$} \\*A class that represents a Hidden Markov Model with an arbitrary type of emission distribution }{\pageref{classmlpack_1_1hmm_1_1HMM}}{}
\item\contentsline{section}{{\bf mlpack\+::hmm\+::\+H\+M\+M\+Model} \\*A serializable \doxyref{H\+MM}{p.}{classmlpack_1_1hmm_1_1HMM} model that also stores the type }{\pageref{classmlpack_1_1hmm_1_1HMMModel}}{}
\item\contentsline{section}{{\bf mlpack\+::hmm\+::\+H\+M\+M\+Regression} \\*A class that represents a Hidden Markov Model Regression (H\+M\+MR) }{\pageref{classmlpack_1_1hmm_1_1HMMRegression}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Cosine\+Distance} \\*The cosine distance (or cosine similarity) }{\pageref{classmlpack_1_1kernel_1_1CosineDistance}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Epanechnikov\+Kernel} \\*The Epanechnikov kernel, defined as }{\pageref{classmlpack_1_1kernel_1_1EpanechnikovKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Example\+Kernel} \\*An example kernel function }{\pageref{classmlpack_1_1kernel_1_1ExampleKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Gaussian\+Kernel} \\*The standard Gaussian kernel }{\pageref{classmlpack_1_1kernel_1_1GaussianKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Hyperbolic\+Tangent\+Kernel} \\*Hyperbolic tangent kernel }{\pageref{classmlpack_1_1kernel_1_1HyperbolicTangentKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Kernel\+Type $>$} \\*This is a template class that can provide information about various kernels }{\pageref{classmlpack_1_1kernel_1_1KernelTraits}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Cosine\+Distance $>$} \\*Kernel traits for the cosine distance }{\pageref{classmlpack_1_1kernel_1_1KernelTraits_3_01CosineDistance_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Epanechnikov\+Kernel $>$} \\*Kernel traits for the Epanechnikov kernel }{\pageref{classmlpack_1_1kernel_1_1KernelTraits_3_01EpanechnikovKernel_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Gaussian\+Kernel $>$} \\*Kernel traits for the Gaussian kernel }{\pageref{classmlpack_1_1kernel_1_1KernelTraits_3_01GaussianKernel_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Laplacian\+Kernel $>$} \\*Kernel traits of the Laplacian kernel }{\pageref{classmlpack_1_1kernel_1_1KernelTraits_3_01LaplacianKernel_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Spherical\+Kernel $>$} \\*Kernel traits for the spherical kernel }{\pageref{classmlpack_1_1kernel_1_1KernelTraits_3_01SphericalKernel_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Kernel\+Traits$<$ Triangular\+Kernel $>$} \\*Kernel traits for the triangular kernel }{\pageref{classmlpack_1_1kernel_1_1KernelTraits_3_01TriangularKernel_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+K\+Means\+Selection$<$ Clustering\+Type, max\+Iterations $>$} \\*Implementation of the kmeans sampling scheme }{\pageref{classmlpack_1_1kernel_1_1KMeansSelection}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Laplacian\+Kernel} \\*The standard Laplacian kernel }{\pageref{classmlpack_1_1kernel_1_1LaplacianKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Linear\+Kernel} \\*The simple linear kernel (dot product) }{\pageref{classmlpack_1_1kernel_1_1LinearKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Nystroem\+Method$<$ Kernel\+Type, Point\+Selection\+Policy $>$} }{\pageref{classmlpack_1_1kernel_1_1NystroemMethod}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Ordered\+Selection} }{\pageref{classmlpack_1_1kernel_1_1OrderedSelection}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Polynomial\+Kernel} \\*The simple polynomial kernel }{\pageref{classmlpack_1_1kernel_1_1PolynomialKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+P\+Spectrum\+String\+Kernel} \\*The p-\/spectrum string kernel }{\pageref{classmlpack_1_1kernel_1_1PSpectrumStringKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Random\+Selection} }{\pageref{classmlpack_1_1kernel_1_1RandomSelection}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Spherical\+Kernel} \\*The spherical kernel, which is 1 when the distance between the two argument points is less than or equal to the bandwidth, or 0 otherwise }{\pageref{classmlpack_1_1kernel_1_1SphericalKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kernel\+::\+Triangular\+Kernel} \\*The trivially simple triangular kernel, defined by }{\pageref{classmlpack_1_1kernel_1_1TriangularKernel}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Allow\+Empty\+Clusters} \\*Policy which allows K-\/\+Means to create empty clusters without any error being reported }{\pageref{classmlpack_1_1kmeans_1_1AllowEmptyClusters}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Dual\+Tree\+K\+Means$<$ Metric\+Type, Mat\+Type, Tree\+Type $>$} \\*An algorithm for an exact Lloyd iteration which simply uses dual-\/tree nearest-\/neighbor search to find the nearest centroid for each point in the dataset }{\pageref{classmlpack_1_1kmeans_1_1DualTreeKMeans}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Dual\+Tree\+K\+Means\+Rules$<$ Metric\+Type, Tree\+Type $>$} }{\pageref{classmlpack_1_1kmeans_1_1DualTreeKMeansRules}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Dual\+Tree\+K\+Means\+Statistic} }{\pageref{classmlpack_1_1kmeans_1_1DualTreeKMeansStatistic}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Elkan\+K\+Means$<$ Metric\+Type, Mat\+Type $>$} }{\pageref{classmlpack_1_1kmeans_1_1ElkanKMeans}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Hamerly\+K\+Means$<$ Metric\+Type, Mat\+Type $>$} }{\pageref{classmlpack_1_1kmeans_1_1HamerlyKMeans}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Kill\+Empty\+Clusters} \\*Policy which allows K-\/\+Means to \char`\"{}kill\char`\"{} empty clusters without any error being reported }{\pageref{classmlpack_1_1kmeans_1_1KillEmptyClusters}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+K\+Means$<$ Metric\+Type, Initial\+Partition\+Policy, Empty\+Cluster\+Policy, Lloyd\+Step\+Type, Mat\+Type $>$} \\*This class implements K-\/\+Means clustering, using a variety of possible implementations of Lloyd\textquotesingle{}s algorithm }{\pageref{classmlpack_1_1kmeans_1_1KMeans}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Max\+Variance\+New\+Cluster} \\*When an empty cluster is detected, this class takes the point furthest from the centroid of the cluster with maximum variance as a new cluster }{\pageref{classmlpack_1_1kmeans_1_1MaxVarianceNewCluster}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Naive\+K\+Means$<$ Metric\+Type, Mat\+Type $>$} \\*This is an implementation of a single iteration of Lloyd\textquotesingle{}s algorithm for k-\/means }{\pageref{classmlpack_1_1kmeans_1_1NaiveKMeans}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Pelleg\+Moore\+K\+Means$<$ Metric\+Type, Mat\+Type $>$} \\*An implementation of Pelleg-\/\+Moore\textquotesingle{}s \textquotesingle{}blacklist\textquotesingle{} algorithm for k-\/means clustering }{\pageref{classmlpack_1_1kmeans_1_1PellegMooreKMeans}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Pelleg\+Moore\+K\+Means\+Rules$<$ Metric\+Type, Tree\+Type $>$} \\*The rules class for the single-\/tree Pelleg-\/\+Moore kd-\/tree traversal for k-\/means clustering }{\pageref{classmlpack_1_1kmeans_1_1PellegMooreKMeansRules}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Pelleg\+Moore\+K\+Means\+Statistic} \\*A statistic for trees which holds the blacklist for Pelleg-\/\+Moore k-\/means clustering (which represents the clusters that cannot possibly own any points in a node) }{\pageref{classmlpack_1_1kmeans_1_1PellegMooreKMeansStatistic}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Random\+Partition} \\*A very simple partitioner which partitions the data randomly into the number of desired clusters }{\pageref{classmlpack_1_1kmeans_1_1RandomPartition}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Refined\+Start} \\*A refined approach for choosing initial points for k-\/means clustering }{\pageref{classmlpack_1_1kmeans_1_1RefinedStart}}{}
\item\contentsline{section}{{\bf mlpack\+::kmeans\+::\+Sample\+Initialization} }{\pageref{classmlpack_1_1kmeans_1_1SampleInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::kpca\+::\+Kernel\+P\+C\+A$<$ Kernel\+Type, Kernel\+Rule $>$} \\*This class performs kernel principal components analysis (Kernel P\+CA), for a given kernel }{\pageref{classmlpack_1_1kpca_1_1KernelPCA}}{}
\item\contentsline{section}{{\bf mlpack\+::kpca\+::\+Naive\+Kernel\+Rule$<$ Kernel\+Type $>$} }{\pageref{classmlpack_1_1kpca_1_1NaiveKernelRule}}{}
\item\contentsline{section}{{\bf mlpack\+::kpca\+::\+Nystroem\+Kernel\+Rule$<$ Kernel\+Type, Point\+Selection\+Policy $>$} }{\pageref{classmlpack_1_1kpca_1_1NystroemKernelRule}}{}
\item\contentsline{section}{{\bf mlpack\+::lcc\+::\+Local\+Coordinate\+Coding} \\*An implementation of Local Coordinate Coding (L\+CC) that codes data which approximately lives on a manifold using a variation of l1-\/norm regularized sparse coding; in L\+CC, the penalty on the absolute value of each point\textquotesingle{}s coefficient for each atom is weighted by the squared distance of that point to that atom }{\pageref{classmlpack_1_1lcc_1_1LocalCoordinateCoding}}{}
\item\contentsline{section}{{\bf mlpack\+::\+Log} \\*Provides a convenient way to give formatted output }{\pageref{classmlpack_1_1Log}}{}
\item\contentsline{section}{{\bf mlpack\+::math\+::\+Columns\+To\+Blocks} \\*Transform the columns of the given matrix into a block format }{\pageref{classmlpack_1_1math_1_1ColumnsToBlocks}}{}
\item\contentsline{section}{{\bf mlpack\+::math\+::\+Range\+Type$<$ T $>$} \\*Simple real-\/valued range }{\pageref{classmlpack_1_1math_1_1RangeType}}{}
\item\contentsline{section}{{\bf mlpack\+::matrix\+\_\+completion\+::\+Matrix\+Completion} \\*This class implements the popular nuclear norm minimization heuristic for matrix completion problems }{\pageref{classmlpack_1_1matrix__completion_1_1MatrixCompletion}}{}
\item\contentsline{section}{{\bf mlpack\+::meanshift\+::\+Mean\+Shift$<$ Use\+Kernel, Kernel\+Type, Mat\+Type $>$} \\*This class implements mean shift clustering }{\pageref{classmlpack_1_1meanshift_1_1MeanShift}}{}
\item\contentsline{section}{{\bf mlpack\+::metric\+::\+I\+P\+Metric$<$ Kernel\+Type $>$} \\*The inner product metric, \doxyref{I\+P\+Metric}{p.}{classmlpack_1_1metric_1_1IPMetric}, takes a given Mercer kernel (Kernel\+Type), and when \doxyref{Evaluate()}{p.}{classmlpack_1_1metric_1_1IPMetric_aeeaaa6e72c5e9c9c5f43fb66a25c2b04} is called, returns the distance between the two points in kernel space\+: }{\pageref{classmlpack_1_1metric_1_1IPMetric}}{}
\item\contentsline{section}{{\bf mlpack\+::metric\+::\+L\+Metric$<$ T\+Power, T\+Take\+Root $>$} \\*The L\+\_\+p metric for arbitrary integer p, with an option to take the root }{\pageref{classmlpack_1_1metric_1_1LMetric}}{}
\item\contentsline{section}{{\bf mlpack\+::metric\+::\+Mahalanobis\+Distance$<$ Take\+Root $>$} \\*The Mahalanobis distance, which is essentially a stretched Euclidean distance }{\pageref{classmlpack_1_1metric_1_1MahalanobisDistance}}{}
\item\contentsline{section}{{\bf mlpack\+::mvu\+::\+M\+VU} \\*Meant to provide a good abstraction for users }{\pageref{classmlpack_1_1mvu_1_1MVU}}{}
\item\contentsline{section}{{\bf mlpack\+::naive\+\_\+bayes\+::\+Naive\+Bayes\+Classifier$<$ Mat\+Type $>$} \\*The simple Naive Bayes classifier }{\pageref{classmlpack_1_1naive__bayes_1_1NaiveBayesClassifier}}{}
\item\contentsline{section}{{\bf mlpack\+::nca\+::\+N\+C\+A$<$ Metric\+Type, Optimizer\+Type $>$} \\*An implementation of Neighborhood Components Analysis, both a linear dimensionality reduction technique and a distance learning technique }{\pageref{classmlpack_1_1nca_1_1NCA}}{}
\item\contentsline{section}{{\bf mlpack\+::nca\+::\+Softmax\+Error\+Function$<$ Metric\+Type $>$} \\*The \char`\"{}softmax\char`\"{} stochastic neighbor assignment probability function }{\pageref{classmlpack_1_1nca_1_1SoftmaxErrorFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Bi\+Search\+Visitor$<$ Sort\+Policy $>$} \\*\doxyref{Bi\+Search\+Visitor}{p.}{classmlpack_1_1neighbor_1_1BiSearchVisitor} executes a bichromatic neighbor search on the given N\+S\+Type }{\pageref{classmlpack_1_1neighbor_1_1BiSearchVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Delete\+Visitor} \\*\doxyref{Delete\+Visitor}{p.}{classmlpack_1_1neighbor_1_1DeleteVisitor} deletes the given N\+S\+Type instance }{\pageref{classmlpack_1_1neighbor_1_1DeleteVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Drusilla\+Select$<$ Mat\+Type $>$} }{\pageref{classmlpack_1_1neighbor_1_1DrusillaSelect}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Epsilon\+Visitor} \\*\doxyref{Epsilon\+Visitor}{p.}{classmlpack_1_1neighbor_1_1EpsilonVisitor} exposes the Epsilon method of the given N\+S\+Type }{\pageref{classmlpack_1_1neighbor_1_1EpsilonVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Furthest\+Neighbor\+Sort} \\*This class implements the necessary methods for the Sort\+Policy template parameter of the \doxyref{Neighbor\+Search}{p.}{classmlpack_1_1neighbor_1_1NeighborSearch} class }{\pageref{classmlpack_1_1neighbor_1_1FurthestNeighborSort}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+L\+S\+H\+Search$<$ Sort\+Policy $>$} \\*The \doxyref{L\+S\+H\+Search}{p.}{classmlpack_1_1neighbor_1_1LSHSearch} class; this class builds a hash on the reference set and uses this hash to compute the distance-\/approximate nearest-\/neighbors of the given queries }{\pageref{classmlpack_1_1neighbor_1_1LSHSearch}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+L\+S\+H\+Search$<$ Sort\+Policy $>$\+::\+Candidate\+Cmp} \\*Compare two candidates based on the distance }{\pageref{structmlpack_1_1neighbor_1_1LSHSearch_1_1CandidateCmp}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Mono\+Search\+Visitor} \\*\doxyref{Mono\+Search\+Visitor}{p.}{classmlpack_1_1neighbor_1_1MonoSearchVisitor} executes a monochromatic neighbor search on the given N\+S\+Type }{\pageref{classmlpack_1_1neighbor_1_1MonoSearchVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Nearest\+Neighbor\+Sort} \\*This class implements the necessary methods for the Sort\+Policy template parameter of the \doxyref{Neighbor\+Search}{p.}{classmlpack_1_1neighbor_1_1NeighborSearch} class }{\pageref{classmlpack_1_1neighbor_1_1NearestNeighborSort}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Neighbor\+Search$<$ Sort\+Policy, Metric\+Type, Mat\+Type, Tree\+Type, Dual\+Tree\+Traversal\+Type, Single\+Tree\+Traversal\+Type $>$} \\*The \doxyref{Neighbor\+Search}{p.}{classmlpack_1_1neighbor_1_1NeighborSearch} class is a template class for performing distance-\/based neighbor searches }{\pageref{classmlpack_1_1neighbor_1_1NeighborSearch}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Neighbor\+Search\+Rules$<$ Sort\+Policy, Metric\+Type, Tree\+Type $>$} \\*The \doxyref{Neighbor\+Search\+Rules}{p.}{classmlpack_1_1neighbor_1_1NeighborSearchRules} class is a template helper class used by \doxyref{Neighbor\+Search}{p.}{classmlpack_1_1neighbor_1_1NeighborSearch} class when performing distance-\/based neighbor searches }{\pageref{classmlpack_1_1neighbor_1_1NeighborSearchRules}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Neighbor\+Search\+Rules$<$ Sort\+Policy, Metric\+Type, Tree\+Type $>$\+::\+Candidate\+Cmp} \\*Compare two candidates based on the distance }{\pageref{structmlpack_1_1neighbor_1_1NeighborSearchRules_1_1CandidateCmp}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Neighbor\+Search\+Stat$<$ Sort\+Policy $>$} \\*Extra data for each node in the tree }{\pageref{classmlpack_1_1neighbor_1_1NeighborSearchStat}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+N\+S\+Model$<$ Sort\+Policy $>$} \\*The \doxyref{N\+S\+Model}{p.}{classmlpack_1_1neighbor_1_1NSModel} class provides an easy way to serialize a model, abstracts away the different types of trees, and also reflects the \doxyref{Neighbor\+Search}{p.}{classmlpack_1_1neighbor_1_1NeighborSearch} A\+PI }{\pageref{classmlpack_1_1neighbor_1_1NSModel}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+N\+S\+Model\+Name$<$ Sort\+Policy $>$} }{\pageref{structmlpack_1_1neighbor_1_1NSModelName}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+N\+S\+Model\+Name$<$ Furthest\+Neighbor\+Sort $>$} }{\pageref{structmlpack_1_1neighbor_1_1NSModelName_3_01FurthestNeighborSort_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+N\+S\+Model\+Name$<$ Nearest\+Neighbor\+Sort $>$} }{\pageref{structmlpack_1_1neighbor_1_1NSModelName_3_01NearestNeighborSort_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Q\+D\+A\+F\+N$<$ Mat\+Type $>$} }{\pageref{classmlpack_1_1neighbor_1_1QDAFN}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+R\+A\+Model$<$ Sort\+Policy $>$} \\*The \doxyref{R\+A\+Model}{p.}{classmlpack_1_1neighbor_1_1RAModel} class provides an abstraction for the \doxyref{R\+A\+Search}{p.}{classmlpack_1_1neighbor_1_1RASearch} class, abstracting away the Tree\+Type parameter and allowing it to be specified at runtime in this class }{\pageref{classmlpack_1_1neighbor_1_1RAModel}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+R\+A\+Query\+Stat$<$ Sort\+Policy $>$} \\*Extra data for each node in the tree }{\pageref{classmlpack_1_1neighbor_1_1RAQueryStat}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+R\+A\+Search$<$ Sort\+Policy, Metric\+Type, Mat\+Type, Tree\+Type $>$} \\*The \doxyref{R\+A\+Search}{p.}{classmlpack_1_1neighbor_1_1RASearch} class\+: This class provides a generic manner to perform rank-\/approximate search via random-\/sampling }{\pageref{classmlpack_1_1neighbor_1_1RASearch}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+R\+A\+Search\+Rules$<$ Sort\+Policy, Metric\+Type, Tree\+Type $>$} \\*The \doxyref{R\+A\+Search\+Rules}{p.}{classmlpack_1_1neighbor_1_1RASearchRules} class is a template helper class used by \doxyref{R\+A\+Search}{p.}{classmlpack_1_1neighbor_1_1RASearch} class when performing rank-\/approximate search via random-\/sampling }{\pageref{classmlpack_1_1neighbor_1_1RASearchRules}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+R\+A\+Search\+Rules$<$ Sort\+Policy, Metric\+Type, Tree\+Type $>$\+::\+Candidate\+Cmp} \\*Compare two candidates based on the distance }{\pageref{structmlpack_1_1neighbor_1_1RASearchRules_1_1CandidateCmp}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+R\+A\+Util} }{\pageref{classmlpack_1_1neighbor_1_1RAUtil}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Reference\+Set\+Visitor} \\*\doxyref{Reference\+Set\+Visitor}{p.}{classmlpack_1_1neighbor_1_1ReferenceSetVisitor} exposes the reference\+Set of the given N\+S\+Type }{\pageref{classmlpack_1_1neighbor_1_1ReferenceSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Search\+Mode\+Visitor} \\*\doxyref{Search\+Mode\+Visitor}{p.}{classmlpack_1_1neighbor_1_1SearchModeVisitor} exposes the Search\+Mode() method of the given N\+S\+Type }{\pageref{classmlpack_1_1neighbor_1_1SearchModeVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::neighbor\+::\+Train\+Visitor$<$ Sort\+Policy $>$} \\*\doxyref{Train\+Visitor}{p.}{classmlpack_1_1neighbor_1_1TrainVisitor} sets the reference set to a new reference set on the given N\+S\+Type }{\pageref{classmlpack_1_1neighbor_1_1TrainVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::nn\+::\+Sparse\+Autoencoder$<$ Optimizer\+Type $>$} \\*A sparse autoencoder is a neural network whose aim to learn compressed representations of the data, typically for dimensionality reduction, with a constraint on the activity of the neurons in the network }{\pageref{classmlpack_1_1nn_1_1SparseAutoencoder}}{}
\item\contentsline{section}{{\bf mlpack\+::nn\+::\+Sparse\+Autoencoder\+Function} \\*This is a class for the sparse autoencoder objective function }{\pageref{classmlpack_1_1nn_1_1SparseAutoencoderFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Ada\+Delta$<$ Decomposable\+Function\+Type $>$} \\*Adadelta is an optimizer that uses two ideas to improve upon the two main drawbacks of the Adagrad method\+: }{\pageref{classmlpack_1_1optimization_1_1AdaDelta}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Adam$<$ Decomposable\+Function\+Type $>$} \\*\doxyref{Adam}{p.}{classmlpack_1_1optimization_1_1Adam} is an optimizer that computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients }{\pageref{classmlpack_1_1optimization_1_1Adam}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Aug\+Lagrangian$<$ Lagrangian\+Function $>$} \\*The \doxyref{Aug\+Lagrangian}{p.}{classmlpack_1_1optimization_1_1AugLagrangian} class implements the Augmented Lagrangian method of optimization }{\pageref{classmlpack_1_1optimization_1_1AugLagrangian}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Aug\+Lagrangian\+Function$<$ Lagrangian\+Function $>$} \\*This is a utility class used by \doxyref{Aug\+Lagrangian}{p.}{classmlpack_1_1optimization_1_1AugLagrangian}, meant to wrap a Lagrangian\+Function into a function usable by a simple optimizer like L-\/\+B\+F\+GS }{\pageref{classmlpack_1_1optimization_1_1AugLagrangianFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Aug\+Lagrangian\+Test\+Function} \\*This function is taken from \char`\"{}\+Practical Mathematical Optimization\char`\"{} (Snyman), section 5.\+3.\+8 (\char`\"{}\+Application of the Augmented Lagrangian Method\char`\"{}) }{\pageref{classmlpack_1_1optimization_1_1AugLagrangianTestFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Exponential\+Schedule} \\*The exponential cooling schedule cools the temperature T at every step according to the equation }{\pageref{classmlpack_1_1optimization_1_1ExponentialSchedule}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Gockenbach\+Function} \\*This function is taken from M }{\pageref{classmlpack_1_1optimization_1_1GockenbachFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Gradient\+Descent$<$ Function\+Type $>$} \\*Gradient Descent is a technique to minimize a function }{\pageref{classmlpack_1_1optimization_1_1GradientDescent}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+L\+\_\+\+B\+F\+G\+S$<$ Function\+Type $>$} \\*The generic L-\/\+B\+F\+GS optimizer, which uses a back-\/tracking line search algorithm to minimize a function }{\pageref{classmlpack_1_1optimization_1_1L__BFGS}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Lovasz\+Theta\+S\+DP} \\*This function is the Lovasz-\/\+Theta semidefinite program, as implemented in the following paper\+: }{\pageref{classmlpack_1_1optimization_1_1LovaszThetaSDP}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+L\+R\+S\+D\+P$<$ S\+D\+P\+Type $>$} \\*\doxyref{L\+R\+S\+DP}{p.}{classmlpack_1_1optimization_1_1LRSDP} is the implementation of Monteiro and Burer\textquotesingle{}s formulation of low-\/rank semidefinite programs (L\+R-\/\+S\+DP) }{\pageref{classmlpack_1_1optimization_1_1LRSDP}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+L\+R\+S\+D\+P\+Function$<$ S\+D\+P\+Type $>$} \\*The objective function that \doxyref{L\+R\+S\+DP}{p.}{classmlpack_1_1optimization_1_1LRSDP} is trying to optimize }{\pageref{classmlpack_1_1optimization_1_1LRSDPFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Mini\+Batch\+S\+G\+D$<$ Decomposable\+Function\+Type $>$} \\*Mini-\/batch Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions }{\pageref{classmlpack_1_1optimization_1_1MiniBatchSGD}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Primal\+Dual\+Solver$<$ S\+D\+P\+Type $>$} \\*Interface to a primal dual interior point solver }{\pageref{classmlpack_1_1optimization_1_1PrimalDualSolver}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+R\+M\+Sprop$<$ Decomposable\+Function\+Type $>$} \\*\doxyref{R\+M\+Sprop}{p.}{classmlpack_1_1optimization_1_1RMSprop} is an optimizer that utilizes the magnitude of recent gradients to normalize the gradients }{\pageref{classmlpack_1_1optimization_1_1RMSprop}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+S\+A$<$ Function\+Type, Cooling\+Schedule\+Type $>$} \\*Simulated Annealing is an stochastic optimization algorithm which is able to deliver near-\/optimal results quickly without knowing the gradient of the function being optimized }{\pageref{classmlpack_1_1optimization_1_1SA}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+S\+D\+P$<$ Objective\+Matrix\+Type $>$} \\*Specify an \doxyref{S\+DP}{p.}{classmlpack_1_1optimization_1_1SDP} in primal form }{\pageref{classmlpack_1_1optimization_1_1SDP}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$} \\*Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions }{\pageref{classmlpack_1_1optimization_1_1SGD}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::test\+::\+G\+D\+Test\+Function} \\*Very, very simple test function which is the composite of three other functions }{\pageref{classmlpack_1_1optimization_1_1test_1_1GDTestFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::test\+::\+Generalized\+Rosenbrock\+Function} \\*The Generalized Rosenbrock function in n dimensions, defined by f(x) = sum\+\_\+i$^\wedge$\{n -\/ 1\} (f(i)(x)) f\+\_\+i(x) = 100 $\ast$ (x\+\_\+i$^\wedge$2 -\/ x\+\_\+\{i + 1\})$^\wedge$2 + (1 -\/ x\+\_\+i)$^\wedge$2 x\+\_\+0 = [-\/1.\+2, 1, -\/1.\+2, 1, ...] }{\pageref{classmlpack_1_1optimization_1_1test_1_1GeneralizedRosenbrockFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::test\+::\+Rosenbrock\+Function} \\*The Rosenbrock function, defined by f(x) = f1(x) + f2(x) f1(x) = 100 (x2 -\/ x1$^\wedge$2)$^\wedge$2 f2(x) = (1 -\/ x1)$^\wedge$2 x\+\_\+0 = [-\/1.\+2, 1] }{\pageref{classmlpack_1_1optimization_1_1test_1_1RosenbrockFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::test\+::\+Rosenbrock\+Wood\+Function} \\*The Generalized Rosenbrock function in 4 dimensions with the Wood Function in four dimensions }{\pageref{classmlpack_1_1optimization_1_1test_1_1RosenbrockWoodFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::test\+::\+S\+G\+D\+Test\+Function} \\*Very, very simple test function which is the composite of three other functions }{\pageref{classmlpack_1_1optimization_1_1test_1_1SGDTestFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::test\+::\+Wood\+Function} \\*The Wood function, defined by f(x) = f1(x) + f2(x) + f3(x) + f4(x) + f5(x) + f6(x) f1(x) = 100 (x2 -\/ x1$^\wedge$2)$^\wedge$2 f2(x) = (1 -\/ x1)$^\wedge$2 f3(x) = 90 (x4 -\/ x3$^\wedge$2)$^\wedge$2 f4(x) = (1 -\/ x3)$^\wedge$2 f5(x) = 10 (x2 + x4 -\/ 2)$^\wedge$2 f6(x) = (1 / 10) (x2 -\/ x4)$^\wedge$2 x\+\_\+0 = [-\/3, -\/1, -\/3, -\/1] }{\pageref{classmlpack_1_1optimization_1_1test_1_1WoodFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::optimization\+::\+Vanilla\+Update} \\*Vanilla update policy for Stochastic Gradient Descent (\doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD}) }{\pageref{classmlpack_1_1optimization_1_1VanillaUpdate}}{}
\item\contentsline{section}{{\bf mlpack\+::pca\+::\+Exact\+S\+V\+D\+Policy} \\*Implementation of the exact S\+VD policy }{\pageref{classmlpack_1_1pca_1_1ExactSVDPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::pca\+::\+P\+C\+A\+Type$<$ Decomposition\+Policy $>$} \\*This class implements principal components analysis (P\+CA) }{\pageref{classmlpack_1_1pca_1_1PCAType}}{}
\item\contentsline{section}{{\bf mlpack\+::pca\+::\+Q\+U\+I\+C\+S\+V\+D\+Policy} \\*Implementation of the Q\+U\+I\+C-\/\+S\+VD policy }{\pageref{classmlpack_1_1pca_1_1QUICSVDPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::pca\+::\+Randomized\+S\+V\+D\+Policy} \\*Implementation of the randomized S\+VD policy }{\pageref{classmlpack_1_1pca_1_1RandomizedSVDPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::perceptron\+::\+Perceptron$<$ Learn\+Policy, Weight\+Initialization\+Policy, Mat\+Type $>$} \\*This class implements a simple perceptron (i.\+e., a single layer neural network) }{\pageref{classmlpack_1_1perceptron_1_1Perceptron}}{}
\item\contentsline{section}{{\bf mlpack\+::perceptron\+::\+Random\+Initialization} \\*This class is used to initialize weights for the weight\+Vectors matrix in a random manner }{\pageref{classmlpack_1_1perceptron_1_1RandomInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::perceptron\+::\+Simple\+Weight\+Update} }{\pageref{classmlpack_1_1perceptron_1_1SimpleWeightUpdate}}{}
\item\contentsline{section}{{\bf mlpack\+::perceptron\+::\+Zero\+Initialization} \\*This class is used to initialize the matrix weight\+Vectors to zero }{\pageref{classmlpack_1_1perceptron_1_1ZeroInitialization}}{}
\item\contentsline{section}{{\bf mlpack\+::radical\+::\+Radical} \\*An implementation of R\+A\+D\+I\+C\+AL, an algorithm for independent component analysis (I\+CA) }{\pageref{classmlpack_1_1radical_1_1Radical}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Bi\+Search\+Visitor} \\*\doxyref{Bi\+Search\+Visitor}{p.}{classmlpack_1_1range_1_1BiSearchVisitor} executes a bichromatic range search on the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1BiSearchVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Delete\+Visitor} \\*\doxyref{Delete\+Visitor}{p.}{classmlpack_1_1range_1_1DeleteVisitor} deletes the given R\+S\+Type instance }{\pageref{classmlpack_1_1range_1_1DeleteVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Mono\+Search\+Visitor} \\*\doxyref{Mono\+Search\+Visitor}{p.}{classmlpack_1_1range_1_1MonoSearchVisitor} executes a monochromatic range search on the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1MonoSearchVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Naive\+Visitor} \\*\doxyref{Naive\+Visitor}{p.}{classmlpack_1_1range_1_1NaiveVisitor} exposes the Naive() method of the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1NaiveVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Range\+Search$<$ Metric\+Type, Mat\+Type, Tree\+Type $>$} \\*The \doxyref{Range\+Search}{p.}{classmlpack_1_1range_1_1RangeSearch} class is a template class for performing range searches }{\pageref{classmlpack_1_1range_1_1RangeSearch}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Range\+Search\+Rules$<$ Metric\+Type, Tree\+Type $>$} \\*The \doxyref{Range\+Search\+Rules}{p.}{classmlpack_1_1range_1_1RangeSearchRules} class is a template helper class used by \doxyref{Range\+Search}{p.}{classmlpack_1_1range_1_1RangeSearch} class when performing range searches }{\pageref{classmlpack_1_1range_1_1RangeSearchRules}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Range\+Search\+Stat} \\*Statistic class for \doxyref{Range\+Search}{p.}{classmlpack_1_1range_1_1RangeSearch}, to be set to the Statistic\+Type of the tree type that range search is being performed with }{\pageref{classmlpack_1_1range_1_1RangeSearchStat}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Reference\+Set\+Visitor} \\*\doxyref{Reference\+Set\+Visitor}{p.}{classmlpack_1_1range_1_1ReferenceSetVisitor} exposes the reference\+Set of the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1ReferenceSetVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+R\+S\+Model} }{\pageref{classmlpack_1_1range_1_1RSModel}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+R\+S\+Model\+Name} }{\pageref{structmlpack_1_1range_1_1RSModelName}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Serialize\+Visitor$<$ Archive $>$} \\*Exposes the seralize method of the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1SerializeVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Single\+Mode\+Visitor} \\*\doxyref{Single\+Mode\+Visitor}{p.}{classmlpack_1_1range_1_1SingleModeVisitor} exposes the Single\+Mode() method of the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1SingleModeVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::range\+::\+Train\+Visitor} \\*\doxyref{Train\+Visitor}{p.}{classmlpack_1_1range_1_1TrainVisitor} sets the reference set to a new reference set on the given R\+S\+Type }{\pageref{classmlpack_1_1range_1_1TrainVisitor}}{}
\item\contentsline{section}{{\bf mlpack\+::regression\+::\+L\+A\+RS} \\*An implementation of \doxyref{L\+A\+RS}{p.}{classmlpack_1_1regression_1_1LARS}, a stage-\/wise homotopy-\/based algorithm for l1-\/regularized linear regression (L\+A\+S\+SO) and l1+l2 regularized linear regression (Elastic Net) }{\pageref{classmlpack_1_1regression_1_1LARS}}{}
\item\contentsline{section}{{\bf mlpack\+::regression\+::\+Linear\+Regression} \\*A simple linear regression algorithm using ordinary least squares }{\pageref{classmlpack_1_1regression_1_1LinearRegression}}{}
\item\contentsline{section}{{\bf mlpack\+::regression\+::\+Logistic\+Regression$<$ Mat\+Type $>$} \\*The \doxyref{Logistic\+Regression}{p.}{classmlpack_1_1regression_1_1LogisticRegression} class implements an L2-\/regularized logistic regression model, and supports training with multiple optimizers and classification }{\pageref{classmlpack_1_1regression_1_1LogisticRegression}}{}
\item\contentsline{section}{{\bf mlpack\+::regression\+::\+Logistic\+Regression\+Function$<$ Mat\+Type $>$} \\*The log-\/likelihood function for the logistic regression objective function }{\pageref{classmlpack_1_1regression_1_1LogisticRegressionFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::regression\+::\+Softmax\+Regression$<$ Optimizer\+Type $>$} \\*Softmax Regression is a classifier which can be used for classification when the data available can take two or more class values }{\pageref{classmlpack_1_1regression_1_1SoftmaxRegression}}{}
\item\contentsline{section}{{\bf mlpack\+::regression\+::\+Softmax\+Regression\+Function} }{\pageref{classmlpack_1_1regression_1_1SoftmaxRegressionFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::sparse\+\_\+coding\+::\+Data\+Dependent\+Random\+Initializer} \\*A data-\/dependent random dictionary initializer for \doxyref{Sparse\+Coding}{p.}{classmlpack_1_1sparse__coding_1_1SparseCoding} }{\pageref{classmlpack_1_1sparse__coding_1_1DataDependentRandomInitializer}}{}
\item\contentsline{section}{{\bf mlpack\+::sparse\+\_\+coding\+::\+Nothing\+Initializer} \\*A Dictionary\+Initializer for \doxyref{Sparse\+Coding}{p.}{classmlpack_1_1sparse__coding_1_1SparseCoding} which does not initialize anything; it is useful for when the dictionary is already known and will be set with \doxyref{Sparse\+Coding\+::\+Dictionary()}{p.}{classmlpack_1_1sparse__coding_1_1SparseCoding_ab069f805f1db24a672b6f38a6d9cf755} }{\pageref{classmlpack_1_1sparse__coding_1_1NothingInitializer}}{}
\item\contentsline{section}{{\bf mlpack\+::sparse\+\_\+coding\+::\+Random\+Initializer} \\*A Dictionary\+Initializer for use with the \doxyref{Sparse\+Coding}{p.}{classmlpack_1_1sparse__coding_1_1SparseCoding} class }{\pageref{classmlpack_1_1sparse__coding_1_1RandomInitializer}}{}
\item\contentsline{section}{{\bf mlpack\+::sparse\+\_\+coding\+::\+Sparse\+Coding} \\*An implementation of Sparse Coding with Dictionary Learning that achieves sparsity via an l1-\/norm regularizer on the codes (L\+A\+S\+SO) or an (l1+l2)-\/norm regularizer on the codes (the Elastic Net) }{\pageref{classmlpack_1_1sparse__coding_1_1SparseCoding}}{}
\item\contentsline{section}{{\bf mlpack\+::svd\+::\+Q\+U\+I\+C\+\_\+\+S\+VD} \\*Q\+U\+I\+C-\/\+S\+VD is a matrix factorization technique, which operates in a subspace such that A\textquotesingle{}s approximation in that subspace has minimum error(A being the data matrix) }{\pageref{classmlpack_1_1svd_1_1QUIC__SVD}}{}
\item\contentsline{section}{{\bf mlpack\+::svd\+::\+Randomized\+S\+VD} \\*Randomized S\+VD is a matrix factorization that is based on randomized matrix approximation techniques, developed in in \char`\"{}\+Finding structure with randomness\+:
\+Probabilistic algorithms for constructing approximate matrix decompositions\char`\"{} }{\pageref{classmlpack_1_1svd_1_1RandomizedSVD}}{}
\item\contentsline{section}{{\bf mlpack\+::svd\+::\+Regularized\+S\+V\+D$<$ Optimizer\+Type $>$} \\*Regularized S\+VD is a matrix factorization technique that seeks to reduce the error on the training set, that is on the examples for which the ratings have been provided by the users }{\pageref{classmlpack_1_1svd_1_1RegularizedSVD}}{}
\item\contentsline{section}{{\bf mlpack\+::svd\+::\+Regularized\+S\+V\+D\+Function} }{\pageref{classmlpack_1_1svd_1_1RegularizedSVDFunction}}{}
\item\contentsline{section}{{\bf mlpack\+::\+Timer} \\*The timer class provides a way for mlpack methods to be timed }{\pageref{classmlpack_1_1Timer}}{}
\item\contentsline{section}{{\bf mlpack\+::\+Timers} }{\pageref{classmlpack_1_1Timers}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+All\+Categorical\+Split$<$ Fitness\+Function $>$} \\*The \doxyref{All\+Categorical\+Split}{p.}{classmlpack_1_1tree_1_1AllCategoricalSplit} is a splitting function that will split categorical features into many children\+: one child for each category }{\pageref{classmlpack_1_1tree_1_1AllCategoricalSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+All\+Categorical\+Split$<$ Fitness\+Function $>$\+::\+Auxiliary\+Split\+Info$<$ Elem\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1AllCategoricalSplit_1_1AuxiliarySplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Axis\+Parallel\+Proj\+Vector} \\*\doxyref{Axis\+Parallel\+Proj\+Vector}{p.}{classmlpack_1_1tree_1_1AxisParallelProjVector} defines an axis-\/parallel projection vector }{\pageref{classmlpack_1_1tree_1_1AxisParallelProjVector}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Best\+Binary\+Numeric\+Split$<$ Fitness\+Function $>$} \\*The \doxyref{Best\+Binary\+Numeric\+Split}{p.}{classmlpack_1_1tree_1_1BestBinaryNumericSplit} is a splitting function for decision trees that will exhaustively search a numeric dimension for the best binary split }{\pageref{classmlpack_1_1tree_1_1BestBinaryNumericSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Best\+Binary\+Numeric\+Split$<$ Fitness\+Function $>$\+::\+Auxiliary\+Split\+Info$<$ Elem\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1BestBinaryNumericSplit_1_1AuxiliarySplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Binary\+Numeric\+Split$<$ Fitness\+Function, Observation\+Type $>$} \\*The \doxyref{Binary\+Numeric\+Split}{p.}{classmlpack_1_1tree_1_1BinaryNumericSplit} class implements the numeric feature splitting strategy devised by Gama, Rocha, and Medas in the following paper\+: }{\pageref{classmlpack_1_1tree_1_1BinaryNumericSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Binary\+Numeric\+Split\+Info$<$ Observation\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1BinaryNumericSplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, Split\+Type $>$} \\*A binary space partitioning tree, such as a K\+D-\/tree or a ball tree }{\pageref{classmlpack_1_1tree_1_1BinarySpaceTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, Split\+Type $>$\+::\+Breadth\+First\+Dual\+Tree\+Traverser$<$ Rule\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1BinarySpaceTree_1_1BreadthFirstDualTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, Split\+Type $>$\+::\+Dual\+Tree\+Traverser$<$ Rule\+Type $>$} \\*A dual-\/tree traverser for binary space trees; see dual\+\_\+tree\+\_\+traverser.\+hpp }{\pageref{classmlpack_1_1tree_1_1BinarySpaceTree_1_1DualTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, Split\+Type $>$\+::\+Single\+Tree\+Traverser$<$ Rule\+Type $>$} \\*A single-\/tree traverser for binary space trees; see single\+\_\+tree\+\_\+traverser.\+hpp for implementation }{\pageref{classmlpack_1_1tree_1_1BinarySpaceTree_1_1SingleTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Categorical\+Split\+Info} }{\pageref{classmlpack_1_1tree_1_1CategoricalSplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Compare\+Cosine\+Node} }{\pageref{classmlpack_1_1tree_1_1CompareCosineNode}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Cosine\+Tree} }{\pageref{classmlpack_1_1tree_1_1CosineTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Cover\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Root\+Point\+Policy $>$} \\*A cover tree is a tree specifically designed to speed up nearest-\/neighbor computation in high-\/dimensional spaces }{\pageref{classmlpack_1_1tree_1_1CoverTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Cover\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Root\+Point\+Policy $>$\+::\+Dual\+Tree\+Traverser$<$ Rule\+Type $>$} \\*A dual-\/tree cover tree traverser; see dual\+\_\+tree\+\_\+traverser.\+hpp }{\pageref{classmlpack_1_1tree_1_1CoverTree_1_1DualTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Cover\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Root\+Point\+Policy $>$\+::\+Dual\+Tree\+Traverser$<$ Rule\+Type $>$\+::\+Dual\+Cover\+Tree\+Map\+Entry} \\*Struct used for traversal }{\pageref{structmlpack_1_1tree_1_1CoverTree_1_1DualTreeTraverser_1_1DualCoverTreeMapEntry}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Cover\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Root\+Point\+Policy $>$\+::\+Single\+Tree\+Traverser$<$ Rule\+Type $>$} \\*A single-\/tree cover tree traverser; see single\+\_\+tree\+\_\+traverser.\+hpp for implementation }{\pageref{classmlpack_1_1tree_1_1CoverTree_1_1SingleTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$} \\*This class implements a generic decision tree learner }{\pageref{classmlpack_1_1tree_1_1DecisionTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Discrete\+Hilbert\+Value$<$ Tree\+Elem\+Type $>$} \\*The \doxyref{Discrete\+Hilbert\+Value}{p.}{classmlpack_1_1tree_1_1DiscreteHilbertValue} class stores Hilbert values for all of the points in a \doxyref{Rectangle\+Tree}{p.}{classmlpack_1_1tree_1_1RectangleTree} node, and calculates Hilbert values for new points }{\pageref{classmlpack_1_1tree_1_1DiscreteHilbertValue}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Empty\+Statistic} \\*Empty statistic if you are not interested in storing statistics in your tree }{\pageref{classmlpack_1_1tree_1_1EmptyStatistic}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Example\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$} \\*This is not an actual space tree but instead an example tree that exists to show and document all the functions that mlpack trees must implement }{\pageref{classmlpack_1_1tree_1_1ExampleTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+First\+Point\+Is\+Root} \\*This class is meant to be used as a choice for the policy class Root\+Point\+Policy of the \doxyref{Cover\+Tree}{p.}{classmlpack_1_1tree_1_1CoverTree} class }{\pageref{classmlpack_1_1tree_1_1FirstPointIsRoot}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Gini\+Gain} \\*The Gini gain, a measure of set purity usable as a fitness function (Fitness\+Function) for decision trees }{\pageref{classmlpack_1_1tree_1_1GiniGain}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Gini\+Impurity} }{\pageref{classmlpack_1_1tree_1_1GiniImpurity}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Greedy\+Single\+Tree\+Traverser$<$ Tree\+Type, Rule\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1GreedySingleTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hilbert\+R\+Tree\+Auxiliary\+Information$<$ Tree\+Type, Hilbert\+Value\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1HilbertRTreeAuxiliaryInformation}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hilbert\+R\+Tree\+Descent\+Heuristic} \\*This class chooses the best child of a node in a Hilbert R tree when inserting a new point }{\pageref{classmlpack_1_1tree_1_1HilbertRTreeDescentHeuristic}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hilbert\+R\+Tree\+Split$<$ split\+Order $>$} \\*The splitting procedure for the Hilbert R tree }{\pageref{classmlpack_1_1tree_1_1HilbertRTreeSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hoeffding\+Categorical\+Split$<$ Fitness\+Function $>$} \\*This is the standard Hoeffding-\/bound categorical feature proposed in the paper below\+: }{\pageref{classmlpack_1_1tree_1_1HoeffdingCategoricalSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hoeffding\+Numeric\+Split$<$ Fitness\+Function, Observation\+Type $>$} \\*The \doxyref{Hoeffding\+Numeric\+Split}{p.}{classmlpack_1_1tree_1_1HoeffdingNumericSplit} class implements the numeric feature splitting strategy alluded to by Domingos and Hulten in the following paper\+: }{\pageref{classmlpack_1_1tree_1_1HoeffdingNumericSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hoeffding\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type $>$} \\*The \doxyref{Hoeffding\+Tree}{p.}{classmlpack_1_1tree_1_1HoeffdingTree} object represents all of the necessary information for a Hoeffding-\/bound-\/based decision tree }{\pageref{classmlpack_1_1tree_1_1HoeffdingTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hoeffding\+Tree\+Model} \\*This class is a serializable Hoeffding tree model that can hold four different types of Hoeffding trees }{\pageref{classmlpack_1_1tree_1_1HoeffdingTreeModel}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Hyperplane\+Base$<$ Bound\+T, Proj\+Vector\+T $>$} \\*\doxyref{Hyperplane\+Base}{p.}{classmlpack_1_1tree_1_1HyperplaneBase} defines a splitting hyperplane based on a projection vector and projection value }{\pageref{classmlpack_1_1tree_1_1HyperplaneBase}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Information\+Gain} \\*The standard information gain criterion, used for calculating gain in decision trees }{\pageref{classmlpack_1_1tree_1_1InformationGain}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Is\+Spill\+Tree$<$ Tree\+Type $>$} }{\pageref{structmlpack_1_1tree_1_1IsSpillTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Is\+Spill\+Tree$<$ tree\+::\+Spill\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$ $>$} }{\pageref{structmlpack_1_1tree_1_1IsSpillTree_3_01tree_1_1SpillTree_3_01MetricType_00_01StatisticType_00_0d41f2b10e451850b8eb14d3156c51340}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Mean\+Space\+Split$<$ Metric\+Type, Mat\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1MeanSpaceSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Mean\+Split$<$ Bound\+Type, Mat\+Type $>$} \\*A binary space partitioning tree node is split into its left and right child }{\pageref{classmlpack_1_1tree_1_1MeanSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Mean\+Split$<$ Bound\+Type, Mat\+Type $>$\+::\+Split\+Info} \\*An information about the partition }{\pageref{structmlpack_1_1tree_1_1MeanSplit_1_1SplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Midpoint\+Space\+Split$<$ Metric\+Type, Mat\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1MidpointSpaceSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Midpoint\+Split$<$ Bound\+Type, Mat\+Type $>$} \\*A binary space partitioning tree node is split into its left and right child }{\pageref{classmlpack_1_1tree_1_1MidpointSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Midpoint\+Split$<$ Bound\+Type, Mat\+Type $>$\+::\+Split\+Info} \\*A struct that contains an information about the split }{\pageref{structmlpack_1_1tree_1_1MidpointSplit_1_1SplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Minimal\+Coverage\+Sweep$<$ Split\+Policy $>$} \\*The \doxyref{Minimal\+Coverage\+Sweep}{p.}{classmlpack_1_1tree_1_1MinimalCoverageSweep} class finds a partition along which we can split a node according to the coverage of two resulting nodes }{\pageref{classmlpack_1_1tree_1_1MinimalCoverageSweep}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Minimal\+Coverage\+Sweep$<$ Split\+Policy $>$\+::\+Sweep\+Cost$<$ Tree\+Type $>$} \\*A struct that provides the type of the sweep cost }{\pageref{structmlpack_1_1tree_1_1MinimalCoverageSweep_1_1SweepCost}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Minimal\+Splits\+Number\+Sweep$<$ Split\+Policy $>$} \\*The \doxyref{Minimal\+Splits\+Number\+Sweep}{p.}{classmlpack_1_1tree_1_1MinimalSplitsNumberSweep} class finds a partition along which we can split a node according to the number of required splits of the node }{\pageref{classmlpack_1_1tree_1_1MinimalSplitsNumberSweep}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Minimal\+Splits\+Number\+Sweep$<$ Split\+Policy $>$\+::\+Sweep\+Cost$<$ typename $>$} \\*A struct that provides the type of the sweep cost }{\pageref{structmlpack_1_1tree_1_1MinimalSplitsNumberSweep_1_1SweepCost}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+No\+Auxiliary\+Information$<$ Tree\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1NoAuxiliaryInformation}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Numeric\+Split\+Info$<$ Observation\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1NumericSplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Octree$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1Octree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Octree$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$\+::\+Dual\+Tree\+Traverser$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$} \\*A dual-\/tree traverser; see dual\+\_\+tree\+\_\+traverser.\+hpp }{\pageref{classmlpack_1_1tree_1_1Octree_1_1DualTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Octree$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$\+::\+Single\+Tree\+Traverser$<$ Rule\+Type $>$} \\*A single-\/tree traverser; see single\+\_\+tree\+\_\+traverser.\+hpp }{\pageref{classmlpack_1_1tree_1_1Octree_1_1SingleTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Octree$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$\+::\+Split\+Info} \\*This is used for sorting points while splitting }{\pageref{structmlpack_1_1tree_1_1Octree_1_1SplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Proj\+Vector} \\*\doxyref{Proj\+Vector}{p.}{classmlpack_1_1tree_1_1ProjVector} defines a general projection vector (not necessarily axis-\/parallel) }{\pageref{classmlpack_1_1tree_1_1ProjVector}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Queue\+Frame$<$ Tree\+Type, Traversal\+Info\+Type $>$} }{\pageref{structmlpack_1_1tree_1_1QueueFrame}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$} \\*A rectangle type tree tree, such as an R-\/tree or X-\/tree }{\pageref{classmlpack_1_1tree_1_1RectangleTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$\+::\+Dual\+Tree\+Traverser$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$} \\*A dual tree traverser for rectangle type trees }{\pageref{classmlpack_1_1tree_1_1RectangleTree_1_1DualTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$\+::\+Dual\+Tree\+Traverser$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$\+::\+Node\+And\+Score$<$ Rule\+Type $>$} }{\pageref{structmlpack_1_1tree_1_1RectangleTree_1_1DualTreeTraverser_1_1NodeAndScore}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$\+::\+Single\+Tree\+Traverser$<$ Rule\+Type $>$} \\*A single traverser for rectangle type trees }{\pageref{classmlpack_1_1tree_1_1RectangleTree_1_1SingleTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$\+::\+Single\+Tree\+Traverser$<$ Rule\+Type $>$\+::\+Node\+And\+Score} }{\pageref{structmlpack_1_1tree_1_1RectangleTree_1_1SingleTreeTraverser_1_1NodeAndScore}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Plus\+Plus\+Tree\+Auxiliary\+Information$<$ Tree\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1RPlusPlusTreeAuxiliaryInformation}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Plus\+Plus\+Tree\+Descent\+Heuristic} }{\pageref{classmlpack_1_1tree_1_1RPlusPlusTreeDescentHeuristic}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Plus\+Plus\+Tree\+Split\+Policy} \\*The \doxyref{R\+Plus\+Plus\+Tree\+Split\+Policy}{p.}{classmlpack_1_1tree_1_1RPlusPlusTreeSplitPolicy} helps to determine the subtree into which we should insert a child of an intermediate node that is being split }{\pageref{classmlpack_1_1tree_1_1RPlusPlusTreeSplitPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Plus\+Tree\+Descent\+Heuristic} }{\pageref{classmlpack_1_1tree_1_1RPlusTreeDescentHeuristic}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Plus\+Tree\+Split$<$ Split\+Policy\+Type, Sweep\+Type $>$} \\*The \doxyref{R\+Plus\+Tree\+Split}{p.}{classmlpack_1_1tree_1_1RPlusTreeSplit} class performs the split process of a node on overflow }{\pageref{classmlpack_1_1tree_1_1RPlusTreeSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Plus\+Tree\+Split\+Policy} \\*The \doxyref{R\+Plus\+Plus\+Tree\+Split\+Policy}{p.}{classmlpack_1_1tree_1_1RPlusPlusTreeSplitPolicy} helps to determine the subtree into which we should insert a child of an intermediate node that is being split }{\pageref{classmlpack_1_1tree_1_1RPlusTreeSplitPolicy}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+P\+Tree\+Max\+Split$<$ Bound\+Type, Mat\+Type $>$} \\*This class splits a node by a random hyperplane }{\pageref{classmlpack_1_1tree_1_1RPTreeMaxSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+P\+Tree\+Max\+Split$<$ Bound\+Type, Mat\+Type $>$\+::\+Split\+Info} \\*An information about the partition }{\pageref{structmlpack_1_1tree_1_1RPTreeMaxSplit_1_1SplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+P\+Tree\+Mean\+Split$<$ Bound\+Type, Mat\+Type $>$} \\*This class splits a binary space tree }{\pageref{classmlpack_1_1tree_1_1RPTreeMeanSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+P\+Tree\+Mean\+Split$<$ Bound\+Type, Mat\+Type $>$\+::\+Split\+Info} \\*An information about the partition }{\pageref{structmlpack_1_1tree_1_1RPTreeMeanSplit_1_1SplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Star\+Tree\+Descent\+Heuristic} \\*When descending a \doxyref{Rectangle\+Tree}{p.}{classmlpack_1_1tree_1_1RectangleTree} to insert a point, we need to have a way to choose a child node when the point isn\textquotesingle{}t enclosed by any of them }{\pageref{classmlpack_1_1tree_1_1RStarTreeDescentHeuristic}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Star\+Tree\+Split} \\*A Rectangle Tree has new points inserted at the bottom }{\pageref{classmlpack_1_1tree_1_1RStarTreeSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Tree\+Descent\+Heuristic} \\*When descending a \doxyref{Rectangle\+Tree}{p.}{classmlpack_1_1tree_1_1RectangleTree} to insert a point, we need to have a way to choose a child node when the point isn\textquotesingle{}t enclosed by any of them }{\pageref{classmlpack_1_1tree_1_1RTreeDescentHeuristic}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+R\+Tree\+Split} \\*A Rectangle Tree has new points inserted at the bottom }{\pageref{classmlpack_1_1tree_1_1RTreeSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Space\+Split$<$ Metric\+Type, Mat\+Type $>$} }{\pageref{classmlpack_1_1tree_1_1SpaceSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Spill\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$} \\*A hybrid spill tree is a variant of binary space trees in which the children of a node can \char`\"{}spill over\char`\"{} each other, and contain shared datapoints }{\pageref{classmlpack_1_1tree_1_1SpillTree}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Spill\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$\+::\+Spill\+Dual\+Tree\+Traverser$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$} \\*A generic dual-\/tree traverser for hybrid spill trees; see \doxyref{spill\+\_\+dual\+\_\+tree\+\_\+traverser.\+hpp}{p.}{spill__dual__tree__traverser_8hpp} for implementation }{\pageref{classmlpack_1_1tree_1_1SpillTree_1_1SpillDualTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Spill\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$\+::\+Spill\+Single\+Tree\+Traverser$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$} \\*A generic single-\/tree traverser for hybrid spill trees; see \doxyref{spill\+\_\+single\+\_\+tree\+\_\+traverser.\+hpp}{p.}{spill__single__tree__traverser_8hpp} for implementation }{\pageref{classmlpack_1_1tree_1_1SpillTree_1_1SpillSingleTreeTraverser}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Traversal\+Info$<$ Tree\+Type $>$} \\*The \doxyref{Traversal\+Info}{p.}{classmlpack_1_1tree_1_1TraversalInfo} class holds traversal information which is used in dual-\/tree (and single-\/tree) traversals }{\pageref{classmlpack_1_1tree_1_1TraversalInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Tree\+Type $>$} \\*The \doxyref{Tree\+Traits}{p.}{classmlpack_1_1tree_1_1TreeTraits} class provides compile-\/time information on the characteristics of a given tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, bound\+::\+Ball\+Bound, Split\+Type $>$ $>$} \\*This is a specialization of the Tree\+Type class to the Ball\+Tree tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01BinarySpaceTree_3_01MetricType_00_01StatisticType_00_01Mat267d3b8606ae92840ddcba6834055254}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, bound\+::\+Cell\+Bound, Split\+Type $>$ $>$} \\*This is a specialization of the Tree\+Type class to the U\+B\+Tree tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01BinarySpaceTree_3_01MetricType_00_01StatisticType_00_01Mat224e09bac64c8e2ee29120d72866c234}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, bound\+::\+Hollow\+Ball\+Bound, Split\+Type $>$ $>$} \\*This is a specialization of the Tree\+Type class to an arbitrary tree with Hollow\+Ball\+Bound (currently only the vantage point tree is supported) }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01BinarySpaceTree_3_01MetricType_00_01StatisticType_00_01Mat5e47ac61d347b64f5768de253cdf2773}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, R\+P\+Tree\+Max\+Split $>$ $>$} \\*This is a specialization of the Tree\+Type class to the max-\/split random projection tree }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01BinarySpaceTree_3_01MetricType_00_01StatisticType_00_01Mat455d0165b2c85743977ec4c0a5dd95ca}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, R\+P\+Tree\+Mean\+Split $>$ $>$} \\*This is a specialization of the Tree\+Type class to the mean-\/split random projection tree }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01BinarySpaceTree_3_01MetricType_00_01StatisticType_00_01Mat83fa92e671856c0b52f8456f1beaf6c5}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Binary\+Space\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Bound\+Type, Split\+Type $>$ $>$} \\*This is a specialization of the \doxyref{Tree\+Traits}{p.}{classmlpack_1_1tree_1_1TreeTraits} class to the \doxyref{Binary\+Space\+Tree}{p.}{classmlpack_1_1tree_1_1BinarySpaceTree} tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01BinarySpaceTree_3_01MetricType_00_01StatisticType_00_01Matc82955fcc5e17376c7ac825c22d34930}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Cover\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Root\+Point\+Policy $>$ $>$} \\*The specialization of the \doxyref{Tree\+Traits}{p.}{classmlpack_1_1tree_1_1TreeTraits} class for the \doxyref{Cover\+Tree}{p.}{classmlpack_1_1tree_1_1CoverTree} tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01CoverTree_3_01MetricType_00_01StatisticType_00_01MatType_00_01RootPointPolicy_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Octree$<$ Metric\+Type, Statistic\+Type, Mat\+Type $>$ $>$} \\*This is a specialization of the \doxyref{Tree\+Traits}{p.}{classmlpack_1_1tree_1_1TreeTraits} class to the \doxyref{Octree}{p.}{classmlpack_1_1tree_1_1Octree} tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01Octree_3_01MetricType_00_01StatisticType_00_01MatType_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, R\+Plus\+Tree\+Split$<$ Split\+Policy\+Type, Sweep\+Type $>$, Descent\+Type, Auxiliary\+Information\+Type $>$ $>$} \\*Since the R+/\+R++ tree can not have overlapping children, we should define traits for the R+/\+R++ tree }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01RectangleTree_3_01MetricType_00_01StatisticType_00_01MatTyd3300c6b7e2f56d4c1027298545eb7bf}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Rectangle\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Split\+Type, Descent\+Type, Auxiliary\+Information\+Type $>$ $>$} \\*This is a specialization of the Tree\+Type class to the \doxyref{Rectangle\+Tree}{p.}{classmlpack_1_1tree_1_1RectangleTree} tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01RectangleTree_3_01MetricType_00_01StatisticType_00_01MatTy0686cbbcde9440cadacd80904499ea50}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Tree\+Traits$<$ Spill\+Tree$<$ Metric\+Type, Statistic\+Type, Mat\+Type, Hyperplane\+Type, Split\+Type $>$ $>$} \\*This is a specialization of the Tree\+Type class to the \doxyref{Spill\+Tree}{p.}{classmlpack_1_1tree_1_1SpillTree} tree type }{\pageref{classmlpack_1_1tree_1_1TreeTraits_3_01SpillTree_3_01MetricType_00_01StatisticType_00_01MatType_03c639ada9e7ec3c7879b4d5a2cf50982}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+U\+B\+Tree\+Split$<$ Bound\+Type, Mat\+Type $>$} \\*Split a node into two parts according to the median address of points contained in the node }{\pageref{classmlpack_1_1tree_1_1UBTreeSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Vantage\+Point\+Split$<$ Bound\+Type, Mat\+Type, Max\+Num\+Samples $>$} \\*The class splits a binary space partitioning tree node according to the median distance to the vantage point }{\pageref{classmlpack_1_1tree_1_1VantagePointSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+Vantage\+Point\+Split$<$ Bound\+Type, Mat\+Type, Max\+Num\+Samples $>$\+::\+Split\+Info} \\*A struct that contains an information about the split }{\pageref{structmlpack_1_1tree_1_1VantagePointSplit_1_1SplitInfo}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+X\+Tree\+Auxiliary\+Information$<$ Tree\+Type $>$} \\*The \doxyref{X\+Tree\+Auxiliary\+Information}{p.}{classmlpack_1_1tree_1_1XTreeAuxiliaryInformation} class provides information specific to X trees for each node in a \doxyref{Rectangle\+Tree}{p.}{classmlpack_1_1tree_1_1RectangleTree} }{\pageref{classmlpack_1_1tree_1_1XTreeAuxiliaryInformation}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+X\+Tree\+Auxiliary\+Information$<$ Tree\+Type $>$\+::\+Split\+History\+Struct} \\*The X tree requires that the tree records it\textquotesingle{}s \char`\"{}split history\char`\"{} }{\pageref{structmlpack_1_1tree_1_1XTreeAuxiliaryInformation_1_1SplitHistoryStruct}}{}
\item\contentsline{section}{{\bf mlpack\+::tree\+::\+X\+Tree\+Split} \\*A Rectangle Tree has new points inserted at the bottom }{\pageref{classmlpack_1_1tree_1_1XTreeSplit}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+C\+L\+I\+Deleter} \\*Extremely simple class whose only job is to delete the existing \doxyref{C\+LI}{p.}{classmlpack_1_1CLI} object at the end of execution }{\pageref{classmlpack_1_1util_1_1CLIDeleter}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Is\+Std\+Vector$<$ T $>$} \\*Metaprogramming structure for vector detection }{\pageref{structmlpack_1_1util_1_1IsStdVector}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Is\+Std\+Vector$<$ std\+::vector$<$ T, A $>$ $>$} \\*Metaprogramming structure for vector detection }{\pageref{structmlpack_1_1util_1_1IsStdVector_3_01std_1_1vector_3_01T_00_01A_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Null\+Out\+Stream} \\*Used for \doxyref{Log\+::\+Debug}{p.}{classmlpack_1_1Log_a80ba817a1abcf742c7463b1e74bf55da} when not compiled with debugging symbols }{\pageref{classmlpack_1_1util_1_1NullOutStream}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Option$<$ N $>$} \\*A static object whose constructor registers a parameter with the \doxyref{C\+LI}{p.}{classmlpack_1_1CLI} class }{\pageref{classmlpack_1_1util_1_1Option}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Param\+Data} \\*This structure holds all of the information about a single parameter, including its value (which is set when Parse\+Command\+Line() is called) }{\pageref{structmlpack_1_1util_1_1ParamData}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type$<$ T $>$} \\*Utility struct to return the type that boost\+::program\+\_\+options should accept for a given input type }{\pageref{structmlpack_1_1util_1_1ParameterType}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type$<$ arma\+::\+Col$<$ e\+T $>$ $>$} \\*For vector types, boost\+::program\+\_\+options will accept a std\+::string, not an arma\+::\+Col$<$e\+T$>$ (since it is not clear how to specify a vector on the command-\/line) }{\pageref{structmlpack_1_1util_1_1ParameterType_3_01arma_1_1Col_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type$<$ arma\+::\+Mat$<$ e\+T $>$ $>$} \\*For matrix types, boost\+::program\+\_\+options will accept a std\+::string, not an arma\+::mat (since it is not clear how to specify a matrix on the command-\/line) }{\pageref{structmlpack_1_1util_1_1ParameterType_3_01arma_1_1Mat_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type$<$ arma\+::\+Row$<$ e\+T $>$ $>$} \\*For row vector types, boost\+::program\+\_\+options will accept a std\+::string, not an arma\+::\+Row$<$e\+T$>$ (since it is not clear how to specify a vector on the command-\/line) }{\pageref{structmlpack_1_1util_1_1ParameterType_3_01arma_1_1Row_3_01eT_01_4_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type$<$ std\+::tuple$<$ mlpack\+::data\+::\+Dataset\+Mapper$<$ Policy\+Type $>$, arma\+::\+Mat$<$ e\+T $>$ $>$ $>$} \\*For matrix+dataset info types, we should accept a std\+::string }{\pageref{structmlpack_1_1util_1_1ParameterType_3_01std_1_1tuple_3_01mlpack_1_1data_1_1DatasetMapper_3_01P0117e227090eb0960979e600219ef0b2}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type\+Deducer$<$ Has\+Serialize, T $>$} }{\pageref{structmlpack_1_1util_1_1ParameterTypeDeducer}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Parameter\+Type\+Deducer$<$ true, T $>$} }{\pageref{structmlpack_1_1util_1_1ParameterTypeDeducer_3_01true_00_01T_01_4}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Prefixed\+Out\+Stream} \\*Allows us to output to an ostream with a prefix at the beginning of each line, in the same way we would output to cout or cerr }{\pageref{classmlpack_1_1util_1_1PrefixedOutStream}}{}
\item\contentsline{section}{{\bf mlpack\+::util\+::\+Program\+Doc} \\*A static object whose constructor registers program documentation with the \doxyref{C\+LI}{p.}{classmlpack_1_1CLI} class }{\pageref{classmlpack_1_1util_1_1ProgramDoc}}{}
\end{DoxyCompactList}
