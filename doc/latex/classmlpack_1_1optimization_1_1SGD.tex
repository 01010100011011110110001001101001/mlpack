\section{mlpack\+:\+:optimization\+:\+:S\+GD$<$ Decomposable\+Function\+Type, Update\+Policy $>$ Class Template Reference}
\label{classmlpack_1_1optimization_1_1SGD}\index{mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$@{mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$}}


Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
{\bf S\+GD} (Decomposable\+Function\+Type \&{\bf function}, const double {\bf step\+Size}=0.\+01, const size\+\_\+t {\bf max\+Iterations}=100000, const double {\bf tolerance}=1e-\/5, const bool shuffle=true, const Update\+Policy update\+Policy=\+Update\+Policy())
\begin{DoxyCompactList}\small\item\em Construct the \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} optimizer with the given function and parameters. \end{DoxyCompactList}\item 
const Decomposable\+Function\+Type \& {\bf Function} () const 
\begin{DoxyCompactList}\small\item\em Get the instantiated function to be optimized. \end{DoxyCompactList}\item 
Decomposable\+Function\+Type \& {\bf Function} ()
\begin{DoxyCompactList}\small\item\em Modify the instantiated function. \end{DoxyCompactList}\item 
size\+\_\+t {\bf Max\+Iterations} () const 
\begin{DoxyCompactList}\small\item\em Get the maximum number of iterations (0 indicates no limit). \end{DoxyCompactList}\item 
size\+\_\+t \& {\bf Max\+Iterations} ()
\begin{DoxyCompactList}\small\item\em Modify the maximum number of iterations (0 indicates no limit). \end{DoxyCompactList}\item 
double {\bf Optimize} (arma\+::mat \&iterate)
\begin{DoxyCompactList}\small\item\em Optimize the given function using stochastic gradient descent. \end{DoxyCompactList}\item 
bool {\bf Shuffle} () const 
\begin{DoxyCompactList}\small\item\em Get whether or not the individual functions are shuffled. \end{DoxyCompactList}\item 
bool \& {\bf Shuffle} ()
\begin{DoxyCompactList}\small\item\em Modify whether or not the individual functions are shuffled. \end{DoxyCompactList}\item 
double {\bf Step\+Size} () const 
\begin{DoxyCompactList}\small\item\em Get the step size. \end{DoxyCompactList}\item 
double \& {\bf Step\+Size} ()
\begin{DoxyCompactList}\small\item\em Modify the step size. \end{DoxyCompactList}\item 
double {\bf Tolerance} () const 
\begin{DoxyCompactList}\small\item\em Get the tolerance for termination. \end{DoxyCompactList}\item 
double \& {\bf Tolerance} ()
\begin{DoxyCompactList}\small\item\em Modify the tolerance for termination. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Private Attributes}
\begin{DoxyCompactItemize}
\item 
Decomposable\+Function\+Type \& {\bf function}
\begin{DoxyCompactList}\small\item\em The instantiated function. \end{DoxyCompactList}\item 
size\+\_\+t {\bf max\+Iterations}
\begin{DoxyCompactList}\small\item\em The maximum number of allowed iterations. \end{DoxyCompactList}\item 
bool {\bf shuffle}
\begin{DoxyCompactList}\small\item\em Controls whether or not the individual functions are shuffled when iterating. \end{DoxyCompactList}\item 
double {\bf step\+Size}
\begin{DoxyCompactList}\small\item\em The step size for each example. \end{DoxyCompactList}\item 
double {\bf tolerance}
\begin{DoxyCompactList}\small\item\em The tolerance for termination. \end{DoxyCompactList}\item 
Update\+Policy {\bf update\+Policy}
\begin{DoxyCompactList}\small\item\em The update policy used to update the parameters in each iteration. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Decomposable\+Function\+Type, typename Update\+Policy = Vanilla\+Update$>$\\*
class mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$}

Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions. 

That is, suppose we have

\[ f(A) = \sum_{i = 0}^{n} f_i(A) \]

and our task is to minimize $ A $. Stochastic gradient descent iterates over each function $ f_i(A) $, based on the specified update policy. By default vanilla update policy (see \doxyref{mlpack\+::optimization\+::\+Vanilla\+Update}{p.}{classmlpack_1_1optimization_1_1VanillaUpdate}) is used. The \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} class supports either scanning through each of the $ n $ functions $ f_i(A)$ linearly, or in a random sequence. The algorithm continues until $ j$ reaches the maximum number of iterations---or when a full sequence of updates through each of the $ n $ functions $ f_i(A) $ produces an improvement within a certain tolerance $ \epsilon $. That is,

\[ | f(A_{j + n}) - f(A_j) | < \epsilon. \]

The parameter $\epsilon$ is specified by the tolerance parameter to the constructor; $n$ is specified by the max\+Iterations parameter.

This class is useful for data-\/dependent functions whose objective function can be expressed as a sum of objective functions operating on an individual point. Then, \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} considers the gradient of the objective function operating on an individual point in its update of $ A $.

For \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} to work, a Decomposable\+Function\+Type template parameter is required. This class must implement the following function\+:

size\+\_\+t Num\+Functions(); double Evaluate(const arma\+::mat\& coordinates, const size\+\_\+t i); void Gradient(const arma\+::mat\& coordinates, const size\+\_\+t i, arma\+::mat\& gradient);

Num\+Functions() should return the number of functions ( $n$), and in the other two functions, the parameter i refers to which individual function (or gradient) is being evaluated. So, for the case of a data-\/dependent function, such as N\+CA (see \doxyref{mlpack\+::nca\+::\+N\+CA}{p.}{classmlpack_1_1nca_1_1NCA}), Num\+Functions() should return the number of points in the dataset, and Evaluate(coordinates, 0) will evaluate the objective function on the first point in the dataset (presumably, the dataset is held internally in the Decomposable\+Function\+Type).


\begin{DoxyTemplParams}{Template Parameters}
{\em Decomposable\+Function\+Type} & Decomposable objective function type to be minimized. \\
\hline
{\em Update\+Policy} & update policy used by \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} during the iterative update process. By default vanilla update policy (see \doxyref{mlpack\+::optimization\+::\+Vanilla\+Update}{p.}{classmlpack_1_1optimization_1_1VanillaUpdate}) is used. \\
\hline
\end{DoxyTemplParams}


Definition at line 77 of file sgd.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!S\+GD@{S\+GD}}
\index{S\+GD@{S\+GD}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{S\+G\+D(\+Decomposable\+Function\+Type \&function, const double step\+Size=0.\+01, const size\+\_\+t max\+Iterations=100000, const double tolerance=1e-\/5, const bool shuffle=true, const Update\+Policy update\+Policy=\+Update\+Policy())}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::{\bf S\+GD} (
\begin{DoxyParamCaption}
\item[{Decomposable\+Function\+Type \&}]{function, }
\item[{const double}]{step\+Size = {\ttfamily 0.01}, }
\item[{const size\+\_\+t}]{max\+Iterations = {\ttfamily 100000}, }
\item[{const double}]{tolerance = {\ttfamily 1e-\/5}, }
\item[{const bool}]{shuffle = {\ttfamily true}, }
\item[{const Update\+Policy}]{update\+Policy = {\ttfamily UpdatePolicy()}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1optimization_1_1SGD_afaf353c8c622ac82fe566fef215ccff3}


Construct the \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} optimizer with the given function and parameters. 

The defaults here are not necessarily good for the given problem, so it is suggested that the values used be tailored to the task at hand. The maximum number of iterations refers to the maximum number of points that are processed (i.\+e., one iteration equals one point; one iteration does not equal one pass over the dataset).


\begin{DoxyParams}{Parameters}
{\em function} & Function to be optimized (minimized). \\
\hline
{\em step\+Size} & Step size for each iteration. \\
\hline
{\em max\+Iterations} & Maximum number of iterations allowed (0 means no limit). \\
\hline
{\em tolerance} & Maximum absolute tolerance to terminate algorithm. \\
\hline
{\em shuffle} & If true, the function order is shuffled; otherwise, each function is visited in linear order. \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Function@{Function}}
\index{Function@{Function}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Function() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ const Decomposable\+Function\+Type\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Function (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a4985df646c5e6e765e16a149cb528e48}


Get the instantiated function to be optimized. 



Definition at line 114 of file sgd.\+hpp.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Function@{Function}}
\index{Function@{Function}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Function()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ Decomposable\+Function\+Type\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Function (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a2b3b65b0a14cdc9e7c66355d828f2c3f}


Modify the instantiated function. 



Definition at line 116 of file sgd.\+hpp.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Max\+Iterations@{Max\+Iterations}}
\index{Max\+Iterations@{Max\+Iterations}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Max\+Iterations() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ size\+\_\+t {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Max\+Iterations (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a9acf6ce28d3133336f0e02111394e7df}


Get the maximum number of iterations (0 indicates no limit). 



Definition at line 124 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::max\+Iterations.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Max\+Iterations@{Max\+Iterations}}
\index{Max\+Iterations@{Max\+Iterations}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Max\+Iterations()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ size\+\_\+t\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Max\+Iterations (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a2edf2f5bba45f7b6c7a6beefdf0895dc}


Modify the maximum number of iterations (0 indicates no limit). 



Definition at line 126 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::max\+Iterations.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Optimize@{Optimize}}
\index{Optimize@{Optimize}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Optimize(arma\+::mat \&iterate)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Optimize (
\begin{DoxyParamCaption}
\item[{arma\+::mat \&}]{iterate}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1optimization_1_1SGD_a8d869b2192f3ac51e9ec6dddb9225260}


Optimize the given function using stochastic gradient descent. 

The given starting point will be modified to store the finishing point of the algorithm, and the final objective value is returned.


\begin{DoxyParams}{Parameters}
{\em iterate} & Starting point (will be modified). \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Objective value of the final point. 
\end{DoxyReturn}
\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Shuffle@{Shuffle}}
\index{Shuffle@{Shuffle}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Shuffle() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ bool {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Shuffle (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a548b3b37d879ae799a6b1905a247815d}


Get whether or not the individual functions are shuffled. 



Definition at line 134 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::shuffle.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Shuffle@{Shuffle}}
\index{Shuffle@{Shuffle}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Shuffle()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ bool\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Shuffle (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a2b88013c0ceb4f3e84b5fffad9972bbd}


Modify whether or not the individual functions are shuffled. 



Definition at line 136 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::shuffle.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Step\+Size@{Step\+Size}}
\index{Step\+Size@{Step\+Size}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Step\+Size() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Step\+Size (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a9b5531706e1697df158374fd637e640c}


Get the step size. 



Definition at line 119 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::step\+Size.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Step\+Size@{Step\+Size}}
\index{Step\+Size@{Step\+Size}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Step\+Size()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Step\+Size (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_af334f1bc4b24f95bdbbe99905c0f8fbe}


Modify the step size. 



Definition at line 121 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::step\+Size.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Tolerance@{Tolerance}}
\index{Tolerance@{Tolerance}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Tolerance() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Tolerance (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a92f8504ca7620f044a6c0f303f2558e9}


Get the tolerance for termination. 



Definition at line 129 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::tolerance.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!Tolerance@{Tolerance}}
\index{Tolerance@{Tolerance}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{Tolerance()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::Tolerance (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1SGD_a21ecb74784013a446115428056069674}


Modify the tolerance for termination. 



Definition at line 131 of file sgd.\+hpp.



References mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::tolerance.



\subsection{Member Data Documentation}
\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!function@{function}}
\index{function@{function}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{function}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ Decomposable\+Function\+Type\& {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::function\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1optimization_1_1SGD_aef0f79b5afaa007c4a39eacfaa4a2a86}


The instantiated function. 



Definition at line 140 of file sgd.\+hpp.

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!max\+Iterations@{max\+Iterations}}
\index{max\+Iterations@{max\+Iterations}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{max\+Iterations}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ size\+\_\+t {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::max\+Iterations\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1optimization_1_1SGD_a889407ceed9b4cae88f0d6d668f8c8e4}


The maximum number of allowed iterations. 



Definition at line 146 of file sgd.\+hpp.



Referenced by mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::\+Max\+Iterations().

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!shuffle@{shuffle}}
\index{shuffle@{shuffle}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{shuffle}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ bool {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::shuffle\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1optimization_1_1SGD_a51150863a1388fa8f6c66e811bb17d15}


Controls whether or not the individual functions are shuffled when iterating. 



Definition at line 153 of file sgd.\+hpp.



Referenced by mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::\+Shuffle().

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!step\+Size@{step\+Size}}
\index{step\+Size@{step\+Size}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{step\+Size}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::step\+Size\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1optimization_1_1SGD_a4744d652756e4679c94ffc95e1b1b7e2}


The step size for each example. 



Definition at line 143 of file sgd.\+hpp.



Referenced by mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::\+Step\+Size().

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!tolerance@{tolerance}}
\index{tolerance@{tolerance}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{tolerance}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ double {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::tolerance\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1optimization_1_1SGD_a754ec32abab885aab94d9f600fb1125b}


The tolerance for termination. 



Definition at line 149 of file sgd.\+hpp.



Referenced by mlpack\+::optimization\+::\+S\+G\+D$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::\+Tolerance().

\index{mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}!update\+Policy@{update\+Policy}}
\index{update\+Policy@{update\+Policy}!mlpack\+::optimization\+::\+S\+GD@{mlpack\+::optimization\+::\+S\+GD}}
\subsubsection[{update\+Policy}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Decomposable\+Function\+Type , typename Update\+Policy  = Vanilla\+Update$>$ Update\+Policy {\bf mlpack\+::optimization\+::\+S\+GD}$<$ Decomposable\+Function\+Type, Update\+Policy $>$\+::update\+Policy\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1optimization_1_1SGD_a239f74b09177ef5c731e5cfbcd0ed0a8}


The update policy used to update the parameters in each iteration. 



Definition at line 156 of file sgd.\+hpp.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/mlpack/core/optimizers/sgd/{\bf sgd.\+hpp}\end{DoxyCompactItemize}
