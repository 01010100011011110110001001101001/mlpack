\section{mlpack\+:\+:optimization\+:\+:Vanilla\+Update Class Reference}
\label{classmlpack_1_1optimization_1_1VanillaUpdate}\index{mlpack\+::optimization\+::\+Vanilla\+Update@{mlpack\+::optimization\+::\+Vanilla\+Update}}


Vanilla update policy for Stochastic Gradient Descent (\doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD}).  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
void {\bf Initialize} (const size\+\_\+t, const size\+\_\+t)
\begin{DoxyCompactList}\small\item\em The Initialize method is called by \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} Optimizer method before the start of the iteration update process. \end{DoxyCompactList}\item 
void {\bf Update} (arma\+::mat \&iterate, const double step\+Size, const arma\+::mat \&gradient)
\begin{DoxyCompactList}\small\item\em Update step for \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD}. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
Vanilla update policy for Stochastic Gradient Descent (\doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD}). 

The following update scheme is used to update \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} in every iteration\+:

\[ A_{j + 1} = A_j + \alpha \nabla f_i(A) \]

where $ \alpha $ is a parameter which specifies the step size. $ i $ is chosen according to $ j $ (the iteration number). 

Definition at line 31 of file vanilla\+\_\+update.\+hpp.



\subsection{Member Function Documentation}
\index{mlpack\+::optimization\+::\+Vanilla\+Update@{mlpack\+::optimization\+::\+Vanilla\+Update}!Initialize@{Initialize}}
\index{Initialize@{Initialize}!mlpack\+::optimization\+::\+Vanilla\+Update@{mlpack\+::optimization\+::\+Vanilla\+Update}}
\subsubsection[{Initialize(const size\+\_\+t, const size\+\_\+t)}]{\setlength{\rightskip}{0pt plus 5cm}void mlpack\+::optimization\+::\+Vanilla\+Update\+::\+Initialize (
\begin{DoxyParamCaption}
\item[{const size\+\_\+t}]{, }
\item[{const size\+\_\+t}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1VanillaUpdate_aee41eddf5f7ff96908c05a4c5dc81ea8}


The Initialize method is called by \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD} Optimizer method before the start of the iteration update process. 

The vanilla update doesn\textquotesingle{}t initialize anything.


\begin{DoxyParams}{Parameters}
{\em n\+\_\+rows} & number of rows in the gradient matrix. \\
\hline
{\em n\+\_\+cols} & number of columns in the gradient matrix. \\
\hline
\end{DoxyParams}


Definition at line 42 of file vanilla\+\_\+update.\+hpp.

\index{mlpack\+::optimization\+::\+Vanilla\+Update@{mlpack\+::optimization\+::\+Vanilla\+Update}!Update@{Update}}
\index{Update@{Update}!mlpack\+::optimization\+::\+Vanilla\+Update@{mlpack\+::optimization\+::\+Vanilla\+Update}}
\subsubsection[{Update(arma\+::mat \&iterate, const double step\+Size, const arma\+::mat \&gradient)}]{\setlength{\rightskip}{0pt plus 5cm}void mlpack\+::optimization\+::\+Vanilla\+Update\+::\+Update (
\begin{DoxyParamCaption}
\item[{arma\+::mat \&}]{iterate, }
\item[{const double}]{step\+Size, }
\item[{const arma\+::mat \&}]{gradient}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1optimization_1_1VanillaUpdate_a0f3e3e6344fe02cd021c2d2e88b6179b}


Update step for \doxyref{S\+GD}{p.}{classmlpack_1_1optimization_1_1SGD}. 

The function parameters are updated in the negative direction of the gradient.


\begin{DoxyParams}{Parameters}
{\em iterate} & Parameters that minimize the function. \\
\hline
{\em step\+Size} & Step size to be used for the given iteration. \\
\hline
{\em gradient} & The gradient matrix. \\
\hline
\end{DoxyParams}


Definition at line 53 of file vanilla\+\_\+update.\+hpp.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/mlpack/core/optimizers/sgd/update\+\_\+policies/{\bf vanilla\+\_\+update.\+hpp}\end{DoxyCompactItemize}
