\section{mlpack\+:\+:ann\+:\+:Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$ Class Template Reference}
\label{classmlpack_1_1ann_1_1BaseLayer}\index{mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$@{mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$}}


Implementation of the base layer.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
{\bf Base\+Layer} ()
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Base\+Layer}{p.}{classmlpack_1_1ann_1_1BaseLayer} object. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void {\bf Backward} (const arma\+::\+Mat$<$ eT $>$ \&\&input, arma\+::\+Mat$<$ eT $>$ \&\&gy, arma\+::\+Mat$<$ eT $>$ \&\&g)
\begin{DoxyCompactList}\small\item\em Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. \end{DoxyCompactList}\item 
Output\+Data\+Type const \& {\bf Delta} () const 
\begin{DoxyCompactList}\small\item\em Get the delta. \end{DoxyCompactList}\item 
Output\+Data\+Type \& {\bf Delta} ()
\begin{DoxyCompactList}\small\item\em Modify the delta. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Input\+Type , typename Output\+Type $>$ }\\void {\bf Forward} (const Input\+Type \&\&input, Output\+Type \&\&output)
\begin{DoxyCompactList}\small\item\em Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. \end{DoxyCompactList}\item 
Input\+Data\+Type const \& {\bf Input\+Parameter} () const 
\begin{DoxyCompactList}\small\item\em Get the input parameter. \end{DoxyCompactList}\item 
Input\+Data\+Type \& {\bf Input\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the input parameter. \end{DoxyCompactList}\item 
Output\+Data\+Type const \& {\bf Output\+Parameter} () const 
\begin{DoxyCompactList}\small\item\em Get the output parameter. \end{DoxyCompactList}\item 
Output\+Data\+Type \& {\bf Output\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the output parameter. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Archive $>$ }\\void {\bf Serialize} (Archive \&, const unsigned int)
\begin{DoxyCompactList}\small\item\em Serialize the layer. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Private Attributes}
\begin{DoxyCompactItemize}
\item 
Output\+Data\+Type {\bf delta}
\begin{DoxyCompactList}\small\item\em Locally-\/stored delta object. \end{DoxyCompactList}\item 
Input\+Data\+Type {\bf input\+Parameter}
\begin{DoxyCompactList}\small\item\em Locally-\/stored input parameter object. \end{DoxyCompactList}\item 
Output\+Data\+Type {\bf output\+Parameter}
\begin{DoxyCompactList}\small\item\em Locally-\/stored output parameter object. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$class Activation\+Function = Logistic\+Function, typename Input\+Data\+Type = arma\+::mat, typename Output\+Data\+Type = arma\+::mat$>$\\*
class mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$}

Implementation of the base layer. 

The base layer works as a metaclass which attaches various functions to the embedding layer.

A few convenience typedefs are given\+:


\begin{DoxyItemize}
\item Sigmoid\+Layer
\item Identity\+Layer
\item Re\+L\+U\+Layer
\item Tan\+H\+Layer
\end{DoxyItemize}


\begin{DoxyTemplParams}{Template Parameters}
{\em Activation\+Function} & Activation function used for the embedding layer. \\
\hline
{\em Input\+Data\+Type} & Type of the input data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
{\em Output\+Data\+Type} & Type of the output data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
\end{DoxyTemplParams}


Definition at line 47 of file base\+\_\+layer.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Base\+Layer@{Base\+Layer}}
\index{Base\+Layer@{Base\+Layer}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Base\+Layer()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::{\bf Base\+Layer} (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_af9d7b462abe48c46f687e107b8d13fa4}


Create the \doxyref{Base\+Layer}{p.}{classmlpack_1_1ann_1_1BaseLayer} object. 



Definition at line 53 of file base\+\_\+layer.\+hpp.



\subsection{Member Function Documentation}
\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Backward@{Backward}}
\index{Backward@{Backward}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Backward(const arma\+::\+Mat$<$ e\+T $>$ \&\&input, arma\+::\+Mat$<$ e\+T $>$ \&\&gy, arma\+::\+Mat$<$ e\+T $>$ \&\&g)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ template$<$typename eT $>$ void {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Backward (
\begin{DoxyParamCaption}
\item[{const arma\+::\+Mat$<$ eT $>$ \&\&}]{input, }
\item[{arma\+::\+Mat$<$ eT $>$ \&\&}]{gy, }
\item[{arma\+::\+Mat$<$ eT $>$ \&\&}]{g}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a29193f4b7484f994488b7f678c58904e}


Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. 

Using the results from the feed forward pass.


\begin{DoxyParams}{Parameters}
{\em input} & The propagated input activation. \\
\hline
{\em gy} & The backpropagated error. \\
\hline
{\em g} & The calculated gradient. \\
\hline
\end{DoxyParams}


Definition at line 81 of file base\+\_\+layer.\+hpp.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Delta@{Delta}}
\index{Delta@{Delta}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Delta() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Output\+Data\+Type const\& {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Delta (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_ab2278ee5fe3ec7c1e60a8502fdfe2d66}


Get the delta. 



Definition at line 101 of file base\+\_\+layer.\+hpp.



References mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::delta.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Delta@{Delta}}
\index{Delta@{Delta}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Delta()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Output\+Data\+Type\& {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Delta (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a44155d0c33a62725266a2f5053124ee6}


Modify the delta. 



Definition at line 103 of file base\+\_\+layer.\+hpp.



References mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::delta.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Forward@{Forward}}
\index{Forward@{Forward}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Forward(const Input\+Type \&\&input, Output\+Type \&\&output)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ template$<$typename Input\+Type , typename Output\+Type $>$ void {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Forward (
\begin{DoxyParamCaption}
\item[{const Input\+Type \&\&}]{input, }
\item[{Output\+Type \&\&}]{output}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a15c584d62049dd1c8b07c7d927d20e26}


Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. 


\begin{DoxyParams}{Parameters}
{\em input} & Input data used for evaluating the specified function. \\
\hline
{\em output} & Resulting output activation. \\
\hline
\end{DoxyParams}


Definition at line 66 of file base\+\_\+layer.\+hpp.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Input\+Parameter@{Input\+Parameter}}
\index{Input\+Parameter@{Input\+Parameter}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Input\+Parameter() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Input\+Data\+Type const\& {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Input\+Parameter (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a6e57c5bb23c6b05b8e5c87f231234889}


Get the input parameter. 



Definition at line 91 of file base\+\_\+layer.\+hpp.



References mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::input\+Parameter.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Input\+Parameter@{Input\+Parameter}}
\index{Input\+Parameter@{Input\+Parameter}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Input\+Parameter()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Input\+Data\+Type\& {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Input\+Parameter (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a7916b35740fc0bf0e5114e90bb07e959}


Modify the input parameter. 



Definition at line 93 of file base\+\_\+layer.\+hpp.



References mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::input\+Parameter.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Output\+Parameter@{Output\+Parameter}}
\index{Output\+Parameter@{Output\+Parameter}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Output\+Parameter() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Output\+Data\+Type const\& {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Output\+Parameter (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a3229a40440098704734965336da3cc74}


Get the output parameter. 



Definition at line 96 of file base\+\_\+layer.\+hpp.



References mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::output\+Parameter.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Output\+Parameter@{Output\+Parameter}}
\index{Output\+Parameter@{Output\+Parameter}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Output\+Parameter()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Output\+Data\+Type\& {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Output\+Parameter (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a5b90a0c7f9eaa23a9daa4f39b1c4484b}


Modify the output parameter. 



Definition at line 98 of file base\+\_\+layer.\+hpp.



References mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::output\+Parameter.

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!Serialize@{Serialize}}
\index{Serialize@{Serialize}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{Serialize(\+Archive \&, const unsigned int)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ template$<$typename Archive $>$ void {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::Serialize (
\begin{DoxyParamCaption}
\item[{Archive \&}]{, }
\item[{const unsigned}]{int}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1ann_1_1BaseLayer_a40d6464e126ef8d20e287ebac4113a04}


Serialize the layer. 



Definition at line 109 of file base\+\_\+layer.\+hpp.



\subsection{Member Data Documentation}
\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!delta@{delta}}
\index{delta@{delta}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{delta}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Output\+Data\+Type {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::delta\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1ann_1_1BaseLayer_a4d57e21f235fbbad3d57af44a73b866a}


Locally-\/stored delta object. 



Definition at line 116 of file base\+\_\+layer.\+hpp.



Referenced by mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::\+Delta().

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!input\+Parameter@{input\+Parameter}}
\index{input\+Parameter@{input\+Parameter}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{input\+Parameter}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Input\+Data\+Type {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::input\+Parameter\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1ann_1_1BaseLayer_aacf9b13ac20bb53c5751c2eca82d1f29}


Locally-\/stored input parameter object. 



Definition at line 119 of file base\+\_\+layer.\+hpp.



Referenced by mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::\+Input\+Parameter().

\index{mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}!output\+Parameter@{output\+Parameter}}
\index{output\+Parameter@{output\+Parameter}!mlpack\+::ann\+::\+Base\+Layer@{mlpack\+::ann\+::\+Base\+Layer}}
\subsubsection[{output\+Parameter}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class Activation\+Function  = Logistic\+Function, typename Input\+Data\+Type  = arma\+::mat, typename Output\+Data\+Type  = arma\+::mat$>$ Output\+Data\+Type {\bf mlpack\+::ann\+::\+Base\+Layer}$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::output\+Parameter\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1ann_1_1BaseLayer_ab21d9d1a603d7b6d846f21c7fb6c22ed}


Locally-\/stored output parameter object. 



Definition at line 122 of file base\+\_\+layer.\+hpp.



Referenced by mlpack\+::ann\+::\+Base\+Layer$<$ Activation\+Function, Input\+Data\+Type, Output\+Data\+Type $>$\+::\+Output\+Parameter().



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/mlpack/methods/ann/layer/{\bf base\+\_\+layer.\+hpp}\end{DoxyCompactItemize}
