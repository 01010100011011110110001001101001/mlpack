\section{mlpack\+:\+:tree\+:\+:Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$ Class Template Reference}
\label{classmlpack_1_1tree_1_1DecisionTree}\index{mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$@{mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$}}


This class implements a generic decision tree learner.  




Inheritance diagram for mlpack\+:\+:tree\+:\+:Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classmlpack_1_1tree_1_1DecisionTree__inherit__graph}
\end{center}
\end{figure}
\subsection*{Public Types}
\begin{DoxyCompactItemize}
\item 
typedef Categorical\+Split\+Type$<$ Fitness\+Function $>$ {\bf Categorical\+Split}
\begin{DoxyCompactList}\small\item\em Allow access to the categorical split type. \end{DoxyCompactList}\item 
typedef Numeric\+Split\+Type$<$ Fitness\+Function $>$ {\bf Numeric\+Split}
\begin{DoxyCompactList}\small\item\em Allow access to the numeric split type. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
{\footnotesize template$<$typename Mat\+Type $>$ }\\{\bf Decision\+Tree} (const Mat\+Type \&data, const {\bf data\+::\+Dataset\+Info} \&dataset\+Info, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)
\begin{DoxyCompactList}\small\item\em Construct the decision tree on the given data and labels, where the data can be both numeric and categorical. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Mat\+Type $>$ }\\{\bf Decision\+Tree} (const Mat\+Type \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)
\begin{DoxyCompactList}\small\item\em Construct the decision tree on the given data and labels, assuming that the data is all of the numeric type. \end{DoxyCompactList}\item 
{\bf Decision\+Tree} (const size\+\_\+t num\+Classes=1)
\begin{DoxyCompactList}\small\item\em Construct a decision tree without training it. \end{DoxyCompactList}\item 
{\bf Decision\+Tree} (const {\bf Decision\+Tree} \&other)
\begin{DoxyCompactList}\small\item\em Copy another tree. \end{DoxyCompactList}\item 
{\bf Decision\+Tree} ({\bf Decision\+Tree} \&\&other)
\begin{DoxyCompactList}\small\item\em Take ownership of another tree. \end{DoxyCompactList}\item 
{\bf $\sim$\+Decision\+Tree} ()
\begin{DoxyCompactList}\small\item\em Clean up memory. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Vec\+Type $>$ }\\size\+\_\+t {\bf Calculate\+Direction} (const Vec\+Type \&point) const 
\begin{DoxyCompactList}\small\item\em Given a point and that this node is not a leaf, calculate the index of the child node this point would go towards. \end{DoxyCompactList}\item 
const {\bf Decision\+Tree} \& {\bf Child} (const size\+\_\+t i) const 
\begin{DoxyCompactList}\small\item\em Get the child of the given index. \end{DoxyCompactList}\item 
{\bf Decision\+Tree} \& {\bf Child} (const size\+\_\+t i)
\begin{DoxyCompactList}\small\item\em Modify the child of the given index (be careful!). \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Vec\+Type $>$ }\\size\+\_\+t {\bf Classify} (const Vec\+Type \&point) const 
\begin{DoxyCompactList}\small\item\em Classify the given point, using the entire tree. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Vec\+Type $>$ }\\void {\bf Classify} (const Vec\+Type \&point, size\+\_\+t \&prediction, arma\+::vec \&probabilities) const 
\begin{DoxyCompactList}\small\item\em Classify the given point and also return estimates of the probability for each class in the given vector. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Mat\+Type $>$ }\\void {\bf Classify} (const Mat\+Type \&data, arma\+::\+Row$<$ size\+\_\+t $>$ \&predictions) const 
\begin{DoxyCompactList}\small\item\em Classify the given points, using the entire tree. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Mat\+Type $>$ }\\void {\bf Classify} (const Mat\+Type \&data, arma\+::\+Row$<$ size\+\_\+t $>$ \&predictions, arma\+::mat \&probabilities) const 
\begin{DoxyCompactList}\small\item\em Classify the given points and also return estimates of the probabilities for each class in the given matrix. \end{DoxyCompactList}\item 
size\+\_\+t {\bf Num\+Children} () const 
\begin{DoxyCompactList}\small\item\em Get the number of children. \end{DoxyCompactList}\item 
{\bf Decision\+Tree} \& {\bf operator=} (const {\bf Decision\+Tree} \&other)
\begin{DoxyCompactList}\small\item\em Copy another tree. \end{DoxyCompactList}\item 
{\bf Decision\+Tree} \& {\bf operator=} ({\bf Decision\+Tree} \&\&other)
\begin{DoxyCompactList}\small\item\em Take ownership of another tree. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Archive $>$ }\\void {\bf Serialize} (Archive \&ar, const unsigned int)
\begin{DoxyCompactList}\small\item\em Serialize the tree. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Mat\+Type $>$ }\\void {\bf Train} (const Mat\+Type \&data, const {\bf data\+::\+Dataset\+Info} \&dataset\+Info, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)
\begin{DoxyCompactList}\small\item\em Train the decision tree on the given data. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Mat\+Type $>$ }\\void {\bf Train} (const Mat\+Type \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)
\begin{DoxyCompactList}\small\item\em Train the decision tree on the given data, assuming that all dimensions are numeric. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Private Types}
\begin{DoxyCompactItemize}
\item 
typedef Categorical\+Split\+::template Auxiliary\+Split\+Info$<$ Elem\+Type $>$ {\bf Categorical\+Auxiliary\+Split\+Info}
\item 
typedef Numeric\+Split\+::template Auxiliary\+Split\+Info$<$ Elem\+Type $>$ {\bf Numeric\+Auxiliary\+Split\+Info}
\begin{DoxyCompactList}\small\item\em Note that this class will also hold the members of the Numeric\+Split and Categorical\+Split Auxiliary\+Split\+Info classes, since it inherits from them. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Private Member Functions}
\begin{DoxyCompactItemize}
\item 
{\footnotesize template$<$typename Row\+Type $>$ }\\void {\bf Calculate\+Class\+Probabilities} (const Row\+Type \&labels, const size\+\_\+t num\+Classes)
\begin{DoxyCompactList}\small\item\em Calculate the class probabilities of the given labels. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Private Attributes}
\begin{DoxyCompactItemize}
\item 
std\+::vector$<$ {\bf Decision\+Tree} $\ast$ $>$ {\bf children}
\begin{DoxyCompactList}\small\item\em The vector of children. \end{DoxyCompactList}\item 
arma\+::vec {\bf class\+Probabilities}
\begin{DoxyCompactList}\small\item\em This vector may hold different things. \end{DoxyCompactList}\item 
size\+\_\+t {\bf dimension\+Type\+Or\+Majority\+Class}
\begin{DoxyCompactList}\small\item\em The type of the dimension that we have split on (if we are not a leaf). \end{DoxyCompactList}\item 
size\+\_\+t {\bf split\+Dimension}
\begin{DoxyCompactList}\small\item\em The dimension this node splits on. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Fitness\+Function = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type = double, bool No\+Recursion = false$>$\\*
class mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$}

This class implements a generic decision tree learner. 

Its behavior can be controlled via its template arguments.

The class inherits from the auxiliary split information in order to prevent an empty auxiliary split information struct from taking any extra size. 

Definition at line 31 of file decision\+\_\+tree.\+hpp.



\subsection{Member Typedef Documentation}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Categorical\+Auxiliary\+Split\+Info@{Categorical\+Auxiliary\+Split\+Info}}
\index{Categorical\+Auxiliary\+Split\+Info@{Categorical\+Auxiliary\+Split\+Info}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Categorical\+Auxiliary\+Split\+Info}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ typedef Categorical\+Split\+::template Auxiliary\+Split\+Info$<$Elem\+Type$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Categorical\+Auxiliary\+Split\+Info}\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_a8f71e2e71f5b875fe1b6b6e3b2286358}


Definition at line 254 of file decision\+\_\+tree.\+hpp.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Categorical\+Split@{Categorical\+Split}}
\index{Categorical\+Split@{Categorical\+Split}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Categorical\+Split}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ typedef Categorical\+Split\+Type$<$Fitness\+Function$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Categorical\+Split}}\label{classmlpack_1_1tree_1_1DecisionTree_a47c926608af4037637e7a71b2788c780}


Allow access to the categorical split type. 



Definition at line 41 of file decision\+\_\+tree.\+hpp.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Numeric\+Auxiliary\+Split\+Info@{Numeric\+Auxiliary\+Split\+Info}}
\index{Numeric\+Auxiliary\+Split\+Info@{Numeric\+Auxiliary\+Split\+Info}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Numeric\+Auxiliary\+Split\+Info}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ typedef Numeric\+Split\+::template Auxiliary\+Split\+Info$<$Elem\+Type$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Numeric\+Auxiliary\+Split\+Info}\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_aaa53d2150636d2e7d4dfde8030e7377d}


Note that this class will also hold the members of the Numeric\+Split and Categorical\+Split Auxiliary\+Split\+Info classes, since it inherits from them. 

We\textquotesingle{}ll define some convenience typedefs here. 

Definition at line 252 of file decision\+\_\+tree.\+hpp.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Numeric\+Split@{Numeric\+Split}}
\index{Numeric\+Split@{Numeric\+Split}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Numeric\+Split}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ typedef Numeric\+Split\+Type$<$Fitness\+Function$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Numeric\+Split}}\label{classmlpack_1_1tree_1_1DecisionTree_aaa0076abd32aae8eb6bc04d98b843faf}


Allow access to the numeric split type. 



Definition at line 39 of file decision\+\_\+tree.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Decision\+Tree@{Decision\+Tree}}
\index{Decision\+Tree@{Decision\+Tree}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Decision\+Tree(const Mat\+Type \&data, const data\+::\+Dataset\+Info \&dataset\+Info, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Mat\+Type $>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Decision\+Tree} (
\begin{DoxyParamCaption}
\item[{const Mat\+Type \&}]{data, }
\item[{const {\bf data\+::\+Dataset\+Info} \&}]{dataset\+Info, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes, }
\item[{const size\+\_\+t}]{minimum\+Leaf\+Size = {\ttfamily 10}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a8895e26a965b754ac13b1aee3babfcfc}


Construct the decision tree on the given data and labels, where the data can be both numeric and categorical. 

Setting minimum\+Leaf\+Size too small may cause the tree to overfit, but setting it too large may cause it to underfit.


\begin{DoxyParams}{Parameters}
{\em data} & Dataset to train on. \\
\hline
{\em dataset\+Info} & Type information for each dimension of the dataset. \\
\hline
{\em labels} & Labels for each training point. \\
\hline
{\em num\+Classes} & Number of classes in the dataset. \\
\hline
{\em minimum\+Leaf\+Size} & Minimum number of points in each leaf node. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Decision\+Tree@{Decision\+Tree}}
\index{Decision\+Tree@{Decision\+Tree}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Decision\+Tree(const Mat\+Type \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Mat\+Type $>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Decision\+Tree} (
\begin{DoxyParamCaption}
\item[{const Mat\+Type \&}]{data, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes, }
\item[{const size\+\_\+t}]{minimum\+Leaf\+Size = {\ttfamily 10}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_ab948c4e515d0a7e408a57a619f3e2b30}


Construct the decision tree on the given data and labels, assuming that the data is all of the numeric type. 

Setting minimum\+Leaf\+Size too small may cause the tree to overfit, but setting it too large may cause it to underfit.


\begin{DoxyParams}{Parameters}
{\em data} & Dataset to train on. \\
\hline
{\em labels} & Labels for each training point. \\
\hline
{\em num\+Classes} & Number of classes in the dataset. \\
\hline
{\em minimum\+Leaf\+Size} & Minimum number of points in each leaf node. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Decision\+Tree@{Decision\+Tree}}
\index{Decision\+Tree@{Decision\+Tree}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Decision\+Tree(const size\+\_\+t num\+Classes=1)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Decision\+Tree} (
\begin{DoxyParamCaption}
\item[{const size\+\_\+t}]{num\+Classes = {\ttfamily 1}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a10b09eaa85d0595870a291d435c0786b}


Construct a decision tree without training it. 

It will be a leaf node with equal probabilities for each class.


\begin{DoxyParams}{Parameters}
{\em num\+Classes} & Number of classes in the dataset. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Decision\+Tree@{Decision\+Tree}}
\index{Decision\+Tree@{Decision\+Tree}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Decision\+Tree(const Decision\+Tree \&other)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Decision\+Tree} (
\begin{DoxyParamCaption}
\item[{const {\bf Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$ \&}]{other}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a8499fb249fdc5d2f736a90bf774c6a83}


Copy another tree. 

This may use a lot of memory---be sure that it\textquotesingle{}s what you want to do.


\begin{DoxyParams}{Parameters}
{\em other} & Tree to copy. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Decision\+Tree@{Decision\+Tree}}
\index{Decision\+Tree@{Decision\+Tree}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Decision\+Tree(\+Decision\+Tree \&\&other)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::{\bf Decision\+Tree} (
\begin{DoxyParamCaption}
\item[{{\bf Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$ \&\&}]{other}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a8effda63202a42eb02c59da4f19c4324}


Take ownership of another tree. 


\begin{DoxyParams}{Parameters}
{\em other} & Tree to take ownership of. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!````~Decision\+Tree@{$\sim$\+Decision\+Tree}}
\index{````~Decision\+Tree@{$\sim$\+Decision\+Tree}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{$\sim$\+Decision\+Tree()}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::$\sim${\bf Decision\+Tree} (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a7f944c4f36862ab630f8723c5d3f8ee9}


Clean up memory. 



\subsection{Member Function Documentation}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Calculate\+Class\+Probabilities@{Calculate\+Class\+Probabilities}}
\index{Calculate\+Class\+Probabilities@{Calculate\+Class\+Probabilities}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Calculate\+Class\+Probabilities(const Row\+Type \&labels, const size\+\_\+t num\+Classes)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Row\+Type $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Calculate\+Class\+Probabilities (
\begin{DoxyParamCaption}
\item[{const Row\+Type \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_abaae8925e6735cfeb99a4ab5ebcf4ca3}


Calculate the class probabilities of the given labels. 

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Calculate\+Direction@{Calculate\+Direction}}
\index{Calculate\+Direction@{Calculate\+Direction}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Calculate\+Direction(const Vec\+Type \&point) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Vec\+Type $>$ size\+\_\+t {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Calculate\+Direction (
\begin{DoxyParamCaption}
\item[{const Vec\+Type \&}]{point}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1tree_1_1DecisionTree_a09ecf7d2d8a1ff6e74d634c1153909c7}


Given a point and that this node is not a leaf, calculate the index of the child node this point would go towards. 

This method is primarily used by the \doxyref{Classify()}{p.}{classmlpack_1_1tree_1_1DecisionTree_a81d8d5e76ac1b6c58341a007290847b6} function, but it can be used in a standalone sense too.


\begin{DoxyParams}{Parameters}
{\em point} & Point to classify. \\
\hline
\end{DoxyParams}


Referenced by mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::\+Child().

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Child@{Child}}
\index{Child@{Child}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Child(const size\+\_\+t i) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ const {\bf Decision\+Tree}\& {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Child (
\begin{DoxyParamCaption}
\item[{const size\+\_\+t}]{i}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1tree_1_1DecisionTree_abb477016c1ef13959ab35b025c6fa97c}


Get the child of the given index. 



Definition at line 217 of file decision\+\_\+tree.\+hpp.



References mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::children.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Child@{Child}}
\index{Child@{Child}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Child(const size\+\_\+t i)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf Decision\+Tree}\& {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Child (
\begin{DoxyParamCaption}
\item[{const size\+\_\+t}]{i}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1tree_1_1DecisionTree_a5d24d8ce5ccadbc604f4d1bf41e87449}


Modify the child of the given index (be careful!). 



Definition at line 219 of file decision\+\_\+tree.\+hpp.



References mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::\+Calculate\+Direction(), and mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::children.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Classify@{Classify}}
\index{Classify@{Classify}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Classify(const Vec\+Type \&point) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Vec\+Type $>$ size\+\_\+t {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Classify (
\begin{DoxyParamCaption}
\item[{const Vec\+Type \&}]{point}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1tree_1_1DecisionTree_a81d8d5e76ac1b6c58341a007290847b6}


Classify the given point, using the entire tree. 

The predicted label is returned.


\begin{DoxyParams}{Parameters}
{\em point} & Point to classify. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Classify@{Classify}}
\index{Classify@{Classify}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Classify(const Vec\+Type \&point, size\+\_\+t \&prediction, arma\+::vec \&probabilities) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Vec\+Type $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Classify (
\begin{DoxyParamCaption}
\item[{const Vec\+Type \&}]{point, }
\item[{size\+\_\+t \&}]{prediction, }
\item[{arma\+::vec \&}]{probabilities}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1tree_1_1DecisionTree_a90a8af18c9cc6ef861910e7e4bd72836}


Classify the given point and also return estimates of the probability for each class in the given vector. 


\begin{DoxyParams}{Parameters}
{\em point} & Point to classify. \\
\hline
{\em prediction} & This will be set to the predicted class of the point. \\
\hline
{\em probabilities} & This will be filled with class probabilities for the point. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Classify@{Classify}}
\index{Classify@{Classify}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Classify(const Mat\+Type \&data, arma\+::\+Row$<$ size\+\_\+t $>$ \&predictions) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Mat\+Type $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Classify (
\begin{DoxyParamCaption}
\item[{const Mat\+Type \&}]{data, }
\item[{arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{predictions}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1tree_1_1DecisionTree_ad0cc8eebf3a189c0e3d622b5ebcfb533}


Classify the given points, using the entire tree. 

The predicted labels for each point are stored in the given vector.


\begin{DoxyParams}{Parameters}
{\em data} & Set of points to classify. \\
\hline
{\em predictions} & This will be filled with predictions for each point. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Classify@{Classify}}
\index{Classify@{Classify}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Classify(const Mat\+Type \&data, arma\+::\+Row$<$ size\+\_\+t $>$ \&predictions, arma\+::mat \&probabilities) const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Mat\+Type $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Classify (
\begin{DoxyParamCaption}
\item[{const Mat\+Type \&}]{data, }
\item[{arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{predictions, }
\item[{arma\+::mat \&}]{probabilities}
\end{DoxyParamCaption}
) const}\label{classmlpack_1_1tree_1_1DecisionTree_a38f3c4ec0b12ea08b4e3a4b06fc2ac8e}


Classify the given points and also return estimates of the probabilities for each class in the given matrix. 

The predicted labels for each point are stored in the given vector.


\begin{DoxyParams}{Parameters}
{\em data} & Set of points to classify. \\
\hline
{\em predictions} & This will be filled with predictions for each point. \\
\hline
{\em probabilities} & This will be filled with class probabilities for each point. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Num\+Children@{Num\+Children}}
\index{Num\+Children@{Num\+Children}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Num\+Children() const }]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ size\+\_\+t {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Num\+Children (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\label{classmlpack_1_1tree_1_1DecisionTree_a51b2801e7255ae796517583a04cf41cc}


Get the number of children. 



Definition at line 214 of file decision\+\_\+tree.\+hpp.



References mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::children.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!operator=@{operator=}}
\index{operator=@{operator=}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{operator=(const Decision\+Tree \&other)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf Decision\+Tree}\& {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::operator= (
\begin{DoxyParamCaption}
\item[{const {\bf Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$ \&}]{other}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_af9a0efae345916db75d4de55ee800d0d}


Copy another tree. 

This may use a lot of memory---be sure that it\textquotesingle{}s what you want to do.


\begin{DoxyParams}{Parameters}
{\em other} & Tree to copy. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!operator=@{operator=}}
\index{operator=@{operator=}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{operator=(\+Decision\+Tree \&\&other)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ {\bf Decision\+Tree}\& {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::operator= (
\begin{DoxyParamCaption}
\item[{{\bf Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$ \&\&}]{other}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a532bee1a4131f0a4212737efec22252d}


Take ownership of another tree. 


\begin{DoxyParams}{Parameters}
{\em other} & Tree to take ownership of. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Serialize@{Serialize}}
\index{Serialize@{Serialize}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Serialize(\+Archive \&ar, const unsigned int)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Archive $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Serialize (
\begin{DoxyParamCaption}
\item[{Archive \&}]{ar, }
\item[{const unsigned}]{int}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a4372a14aa83472be410486c299990816}


Serialize the tree. 

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Train@{Train}}
\index{Train@{Train}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Train(const Mat\+Type \&data, const data\+::\+Dataset\+Info \&dataset\+Info, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Mat\+Type $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Train (
\begin{DoxyParamCaption}
\item[{const Mat\+Type \&}]{data, }
\item[{const {\bf data\+::\+Dataset\+Info} \&}]{dataset\+Info, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes, }
\item[{const size\+\_\+t}]{minimum\+Leaf\+Size = {\ttfamily 10}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a9a56744b932b6e6c78b4975c9e355896}


Train the decision tree on the given data. 

This will overwrite the existing model. The data may have numeric and categorical types, specified by the dataset\+Info parameter. Setting minimum\+Leaf\+Size too small may cause the tree to overfit, but setting it too large may cause it to underfit.


\begin{DoxyParams}{Parameters}
{\em data} & Dataset to train on. \\
\hline
{\em dataset\+Info} & Type information for each dimension. \\
\hline
{\em labels} & Labels for each training point. \\
\hline
{\em num\+Classes} & Number of classes in the dataset. \\
\hline
{\em minimum\+Leaf\+Size} & Minimum number of points in each leaf node. \\
\hline
\end{DoxyParams}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!Train@{Train}}
\index{Train@{Train}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{Train(const Mat\+Type \&data, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const size\+\_\+t minimum\+Leaf\+Size=10)}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ template$<$typename Mat\+Type $>$ void {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::Train (
\begin{DoxyParamCaption}
\item[{const Mat\+Type \&}]{data, }
\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels, }
\item[{const size\+\_\+t}]{num\+Classes, }
\item[{const size\+\_\+t}]{minimum\+Leaf\+Size = {\ttfamily 10}}
\end{DoxyParamCaption}
)}\label{classmlpack_1_1tree_1_1DecisionTree_a16dabe71c1e67e98fd44fb5322134deb}


Train the decision tree on the given data, assuming that all dimensions are numeric. 

This will overwrite the given model. Setting minimum\+Leaf\+Size too small may cause the tree to overfit, but setting it too large may cause it to underfit.


\begin{DoxyParams}{Parameters}
{\em data} & Dataset to train on. \\
\hline
{\em labels} & Labels for each training point. \\
\hline
{\em num\+Classes} & Number of classes in the dataset. \\
\hline
{\em minimum\+Leaf\+Size} & Minimum number of points in each leaf node. \\
\hline
\end{DoxyParams}


\subsection{Member Data Documentation}
\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!children@{children}}
\index{children@{children}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{children}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ std\+::vector$<${\bf Decision\+Tree}$\ast$$>$ {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::children\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_a3743ab3245d148f78817f5d1b812f6e8}


The vector of children. 



Definition at line 233 of file decision\+\_\+tree.\+hpp.



Referenced by mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::\+Child(), and mlpack\+::tree\+::\+Decision\+Tree$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::\+Num\+Children().

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!class\+Probabilities@{class\+Probabilities}}
\index{class\+Probabilities@{class\+Probabilities}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{class\+Probabilities}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ arma\+::vec {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::class\+Probabilities\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_a9b014767c5983cc9dcc3564e6167e2d1}


This vector may hold different things. 

If the node has no children, then it is guaranteed to hold the probabilities of each class. If the node has children, then it may be used arbitrarily by the split type\textquotesingle{}s \doxyref{Calculate\+Direction()}{p.}{classmlpack_1_1tree_1_1DecisionTree_a09ecf7d2d8a1ff6e74d634c1153909c7} function and may not necessarily hold class probabilities. 

Definition at line 246 of file decision\+\_\+tree.\+hpp.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!dimension\+Type\+Or\+Majority\+Class@{dimension\+Type\+Or\+Majority\+Class}}
\index{dimension\+Type\+Or\+Majority\+Class@{dimension\+Type\+Or\+Majority\+Class}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{dimension\+Type\+Or\+Majority\+Class}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ size\+\_\+t {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::dimension\+Type\+Or\+Majority\+Class\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_aa8550c35ef6755b61d2467aa1347f4a6}


The type of the dimension that we have split on (if we are not a leaf). 

If we are a leaf, then this is the index of the majority class. 

Definition at line 238 of file decision\+\_\+tree.\+hpp.

\index{mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}!split\+Dimension@{split\+Dimension}}
\index{split\+Dimension@{split\+Dimension}!mlpack\+::tree\+::\+Decision\+Tree@{mlpack\+::tree\+::\+Decision\+Tree}}
\subsubsection[{split\+Dimension}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Fitness\+Function  = Gini\+Gain, template$<$ typename $>$ class Numeric\+Split\+Type = Best\+Binary\+Numeric\+Split, template$<$ typename $>$ class Categorical\+Split\+Type = All\+Categorical\+Split, typename Elem\+Type  = double, bool No\+Recursion = false$>$ size\+\_\+t {\bf mlpack\+::tree\+::\+Decision\+Tree}$<$ Fitness\+Function, Numeric\+Split\+Type, Categorical\+Split\+Type, Elem\+Type, No\+Recursion $>$\+::split\+Dimension\hspace{0.3cm}{\ttfamily [private]}}\label{classmlpack_1_1tree_1_1DecisionTree_acb83dcda9656c66d0bff4f347d5e0a98}


The dimension this node splits on. 



Definition at line 235 of file decision\+\_\+tree.\+hpp.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/mlpack/methods/decision\+\_\+tree/{\bf decision\+\_\+tree.\+hpp}\end{DoxyCompactItemize}
