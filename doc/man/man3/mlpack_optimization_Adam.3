.TH "mlpack::optimization::Adam< DecomposableFunctionType >" 3 "Sat Mar 25 2017" "Version master" "mlpack" \" -*- nroff -*-
.ad l
.nh
.SH NAME
mlpack::optimization::Adam< DecomposableFunctionType > \- \fBAdam\fP is an optimizer that computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients\&.  

.SH SYNOPSIS
.br
.PP
.SS "Public Member Functions"

.in +1c
.ti -1c
.RI "\fBAdam\fP (DecomposableFunctionType &\fBfunction\fP, const double \fBstepSize\fP=0\&.001, const double \fBbeta1\fP=0\&.9, const double \fBbeta2\fP=0\&.999, const double \fBeps\fP=1e\-8, const size_t maxIterations=100000, const double tolerance=1e\-5, const bool shuffle=true, const bool adaMax=false)"
.br
.RI "\fIConstruct the \fBAdam\fP optimizer with the given function and parameters\&. \fP"
.ti -1c
.RI "bool \fBAdaMax\fP () const "
.br
.RI "\fIGet whether or not the AdaMax optimizer is specified\&. \fP"
.ti -1c
.RI "bool & \fBAdaMax\fP ()"
.br
.RI "\fIModify wehther or not the AdaMax optimizer is to be used\&. \fP"
.ti -1c
.RI "double \fBBeta1\fP () const "
.br
.RI "\fIGet the smoothing parameter\&. \fP"
.ti -1c
.RI "double & \fBBeta1\fP ()"
.br
.RI "\fIModify the smoothing parameter\&. \fP"
.ti -1c
.RI "double \fBBeta2\fP () const "
.br
.RI "\fIGet the second moment coefficient\&. \fP"
.ti -1c
.RI "double & \fBBeta2\fP ()"
.br
.RI "\fIModify the second moment coefficient\&. \fP"
.ti -1c
.RI "double \fBEpsilon\fP () const "
.br
.RI "\fIGet the value used to initialise the mean squared gradient parameter\&. \fP"
.ti -1c
.RI "double & \fBEpsilon\fP ()"
.br
.RI "\fIModify the value used to initialise the mean squared gradient parameter\&. \fP"
.ti -1c
.RI "const DecomposableFunctionType & \fBFunction\fP () const "
.br
.RI "\fIGet the instantiated function to be optimized\&. \fP"
.ti -1c
.RI "DecomposableFunctionType & \fBFunction\fP ()"
.br
.RI "\fIModify the instantiated function\&. \fP"
.ti -1c
.RI "size_t \fBMaxIterations\fP () const "
.br
.RI "\fIGet the maximum number of iterations (0 indicates no limit)\&. \fP"
.ti -1c
.RI "size_t & \fBMaxIterations\fP ()"
.br
.RI "\fIModify the maximum number of iterations (0 indicates no limit)\&. \fP"
.ti -1c
.RI "double \fBOptimize\fP (arma::mat &iterate)"
.br
.RI "\fIOptimize the given function using \fBAdam\fP\&. \fP"
.ti -1c
.RI "bool \fBShuffle\fP () const "
.br
.RI "\fIGet whether or not the individual functions are shuffled\&. \fP"
.ti -1c
.RI "bool & \fBShuffle\fP ()"
.br
.RI "\fIModify whether or not the individual functions are shuffled\&. \fP"
.ti -1c
.RI "double \fBStepSize\fP () const "
.br
.RI "\fIGet the step size\&. \fP"
.ti -1c
.RI "double & \fBStepSize\fP ()"
.br
.RI "\fIModify the step size\&. \fP"
.ti -1c
.RI "double \fBTolerance\fP () const "
.br
.RI "\fIGet the tolerance for termination\&. \fP"
.ti -1c
.RI "double & \fBTolerance\fP ()"
.br
.RI "\fIModify the tolerance for termination\&. \fP"
.in -1c
.SS "Private Attributes"

.in +1c
.ti -1c
.RI "bool \fBadaMax\fP"
.br
.RI "\fISpecifies whether or not the AdaMax optimizer is to be used\&. \fP"
.ti -1c
.RI "double \fBbeta1\fP"
.br
.RI "\fIExponential decay rate for the first moment estimates\&. \fP"
.ti -1c
.RI "double \fBbeta2\fP"
.br
.RI "\fIExponential decay rate for the weighted infinity norm estimates\&. \fP"
.ti -1c
.RI "double \fBeps\fP"
.br
.RI "\fIThe value used to initialise the mean squared gradient parameter\&. \fP"
.ti -1c
.RI "DecomposableFunctionType & \fBfunction\fP"
.br
.RI "\fIThe instantiated function\&. \fP"
.ti -1c
.RI "size_t \fBmaxIterations\fP"
.br
.RI "\fIThe maximum number of allowed iterations\&. \fP"
.ti -1c
.RI "bool \fBshuffle\fP"
.br
.RI "\fIControls whether or not the individual functions are shuffled when iterating\&. \fP"
.ti -1c
.RI "double \fBstepSize\fP"
.br
.RI "\fIThe step size for each example\&. \fP"
.ti -1c
.RI "double \fBtolerance\fP"
.br
.RI "\fIThe tolerance for termination\&. \fP"
.in -1c
.SH "Detailed Description"
.PP 

.SS "template<typename DecomposableFunctionType>
.br
class mlpack::optimization::Adam< DecomposableFunctionType >"
\fBAdam\fP is an optimizer that computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients\&. 

AdaMax is a variant of \fBAdam\fP based on the infinity norm as given in the section 7 of the following paper\&.
.PP
For more information, see the following\&.
.PP
.PP
.nf
@article{Kingma2014,
  author    = {Diederik P\&. Kingma and Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {CoRR},
  year      = {2014}
}
.fi
.PP
.PP
For \fBAdam\fP and AdaMax to work, a DecomposableFunctionType template parameter is required\&. This class must implement the following function:
.PP
size_t NumFunctions(); double Evaluate(const arma::mat& coordinates, const size_t i); void Gradient(const arma::mat& coordinates, const size_t i, arma::mat& gradient);
.PP
NumFunctions() should return the number of functions ( $n$), and in the other two functions, the parameter i refers to which individual function (or gradient) is being evaluated\&. So, for the case of a data-dependent function, such as NCA (see \fBmlpack::nca::NCA\fP), NumFunctions() should return the number of points in the dataset, and Evaluate(coordinates, 0) will evaluate the objective function on the first point in the dataset (presumably, the dataset is held internally in the DecomposableFunctionType)\&.
.PP
\fBTemplate Parameters:\fP
.RS 4
\fIDecomposableFunctionType\fP Decomposable objective function type to be minimized\&. 
.RE
.PP

.PP
Definition at line 65 of file adam\&.hpp\&.
.SH "Constructor & Destructor Documentation"
.PP 
.SS "template<typename DecomposableFunctionType > \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::\fBAdam\fP (DecomposableFunctionType & function, const double stepSize = \fC0\&.001\fP, const double beta1 = \fC0\&.9\fP, const double beta2 = \fC0\&.999\fP, const double eps = \fC1e\-8\fP, const size_t maxIterations = \fC100000\fP, const double tolerance = \fC1e\-5\fP, const bool shuffle = \fCtrue\fP, const bool adaMax = \fCfalse\fP)"

.PP
Construct the \fBAdam\fP optimizer with the given function and parameters\&. The defaults here are not necessarily good for the given problem, so it is suggested that the values used be tailored to the task at hand\&. The maximum number of iterations refers to the maximum number of points that are processed (i\&.e\&., one iteration equals one point; one iteration does not equal one pass over the dataset)\&.
.PP
\fBParameters:\fP
.RS 4
\fIfunction\fP Function to be optimized (minimized)\&. 
.br
\fIstepSize\fP Step size for each iteration\&. 
.br
\fIbeta1\fP Exponential decay rate for the first moment estimates\&. 
.br
\fIbeta2\fP Exponential decay rate for the weighted infinity norm estimates\&. 
.br
\fIeps\fP Value used to initialise the mean squared gradient parameter\&. 
.br
\fImaxIterations\fP Maximum number of iterations allowed (0 means no limit)\&. 
.br
\fItolerance\fP Maximum absolute tolerance to terminate algorithm\&. 
.br
\fIshuffle\fP If true, the function order is shuffled; otherwise, each function is visited in linear order\&. 
.br
\fIadaMax\fP If true, then the AdaMax optimizer is used; otherwise, by default the \fBAdam\fP optimizer is used\&. 
.RE
.PP

.SH "Member Function Documentation"
.PP 
.SS "template<typename DecomposableFunctionType > bool \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::AdaMax () const\fC [inline]\fP"

.PP
Get whether or not the AdaMax optimizer is specified\&. 
.PP
Definition at line 151 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::adaMax\&.
.SS "template<typename DecomposableFunctionType > bool& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::AdaMax ()\fC [inline]\fP"

.PP
Modify wehther or not the AdaMax optimizer is to be used\&. 
.PP
Definition at line 153 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::adaMax\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Beta1 () const\fC [inline]\fP"

.PP
Get the smoothing parameter\&. 
.PP
Definition at line 121 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::beta1\&.
.SS "template<typename DecomposableFunctionType > double& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Beta1 ()\fC [inline]\fP"

.PP
Modify the smoothing parameter\&. 
.PP
Definition at line 123 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::beta1\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Beta2 () const\fC [inline]\fP"

.PP
Get the second moment coefficient\&. 
.PP
Definition at line 126 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::beta2\&.
.SS "template<typename DecomposableFunctionType > double& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Beta2 ()\fC [inline]\fP"

.PP
Modify the second moment coefficient\&. 
.PP
Definition at line 128 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::beta2\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Epsilon () const\fC [inline]\fP"

.PP
Get the value used to initialise the mean squared gradient parameter\&. 
.PP
Definition at line 131 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::eps\&.
.SS "template<typename DecomposableFunctionType > double& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Epsilon ()\fC [inline]\fP"

.PP
Modify the value used to initialise the mean squared gradient parameter\&. 
.PP
Definition at line 133 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::eps\&.
.SS "template<typename DecomposableFunctionType > const DecomposableFunctionType& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Function () const\fC [inline]\fP"

.PP
Get the instantiated function to be optimized\&. 
.PP
Definition at line 111 of file adam\&.hpp\&.
.SS "template<typename DecomposableFunctionType > DecomposableFunctionType& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Function ()\fC [inline]\fP"

.PP
Modify the instantiated function\&. 
.PP
Definition at line 113 of file adam\&.hpp\&.
.SS "template<typename DecomposableFunctionType > size_t \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::MaxIterations () const\fC [inline]\fP"

.PP
Get the maximum number of iterations (0 indicates no limit)\&. 
.PP
Definition at line 136 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::maxIterations\&.
.SS "template<typename DecomposableFunctionType > size_t& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::MaxIterations ()\fC [inline]\fP"

.PP
Modify the maximum number of iterations (0 indicates no limit)\&. 
.PP
Definition at line 138 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::maxIterations\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Optimize (arma::mat & iterate)"

.PP
Optimize the given function using \fBAdam\fP\&. The given starting point will be modified to store the finishing point of the algorithm, and the final objective value is returned\&.
.PP
\fBParameters:\fP
.RS 4
\fIiterate\fP Starting point (will be modified)\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
Objective value of the final point\&. 
.RE
.PP

.SS "template<typename DecomposableFunctionType > bool \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Shuffle () const\fC [inline]\fP"

.PP
Get whether or not the individual functions are shuffled\&. 
.PP
Definition at line 146 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::shuffle\&.
.SS "template<typename DecomposableFunctionType > bool& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Shuffle ()\fC [inline]\fP"

.PP
Modify whether or not the individual functions are shuffled\&. 
.PP
Definition at line 148 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::shuffle\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::StepSize () const\fC [inline]\fP"

.PP
Get the step size\&. 
.PP
Definition at line 116 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::stepSize\&.
.SS "template<typename DecomposableFunctionType > double& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::StepSize ()\fC [inline]\fP"

.PP
Modify the step size\&. 
.PP
Definition at line 118 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::stepSize\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Tolerance () const\fC [inline]\fP"

.PP
Get the tolerance for termination\&. 
.PP
Definition at line 141 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::tolerance\&.
.SS "template<typename DecomposableFunctionType > double& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::Tolerance ()\fC [inline]\fP"

.PP
Modify the tolerance for termination\&. 
.PP
Definition at line 143 of file adam\&.hpp\&.
.PP
References mlpack::optimization::Adam< DecomposableFunctionType >::tolerance\&.
.SH "Member Data Documentation"
.PP 
.SS "template<typename DecomposableFunctionType > bool \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::adaMax\fC [private]\fP"

.PP
Specifies whether or not the AdaMax optimizer is to be used\&. 
.PP
Definition at line 182 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::AdaMax()\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::beta1\fC [private]\fP"

.PP
Exponential decay rate for the first moment estimates\&. 
.PP
Definition at line 163 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::Beta1()\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::beta2\fC [private]\fP"

.PP
Exponential decay rate for the weighted infinity norm estimates\&. 
.PP
Definition at line 166 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::Beta2()\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::eps\fC [private]\fP"

.PP
The value used to initialise the mean squared gradient parameter\&. 
.PP
Definition at line 169 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::Epsilon()\&.
.SS "template<typename DecomposableFunctionType > DecomposableFunctionType& \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::function\fC [private]\fP"

.PP
The instantiated function\&. 
.PP
Definition at line 157 of file adam\&.hpp\&.
.SS "template<typename DecomposableFunctionType > size_t \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::maxIterations\fC [private]\fP"

.PP
The maximum number of allowed iterations\&. 
.PP
Definition at line 172 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::MaxIterations()\&.
.SS "template<typename DecomposableFunctionType > bool \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::shuffle\fC [private]\fP"

.PP
Controls whether or not the individual functions are shuffled when iterating\&. 
.PP
Definition at line 179 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::Shuffle()\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::stepSize\fC [private]\fP"

.PP
The step size for each example\&. 
.PP
Definition at line 160 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::StepSize()\&.
.SS "template<typename DecomposableFunctionType > double \fBmlpack::optimization::Adam\fP< DecomposableFunctionType >::tolerance\fC [private]\fP"

.PP
The tolerance for termination\&. 
.PP
Definition at line 175 of file adam\&.hpp\&.
.PP
Referenced by mlpack::optimization::Adam< DecomposableFunctionType >::Tolerance()\&.

.SH "Author"
.PP 
Generated automatically by Doxygen for mlpack from the source code\&.
